{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Evaluation - Experiment 05\n",
    "The objective of this trial is to expand the SCA_index (i.e., Semantic Content Analysis Index) to a full word embedding, setting a subjective or objective load for each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T22:37:14.251208Z",
     "start_time": "2022-11-12T22:37:14.073574Z"
    }
   },
   "outputs": [],
   "source": [
    "## Data analysis packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import isnan  #Verifies if a given value is numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T22:37:15.470110Z",
     "start_time": "2022-11-12T22:37:14.895488Z"
    }
   },
   "outputs": [],
   "source": [
    "## Visualization packages:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T22:15:12.656866Z",
     "start_time": "2022-04-28T22:15:12.612272Z"
    }
   },
   "outputs": [],
   "source": [
    "## Forcing Pandas to display any number of elements\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    "pd.set_option('display.width', 2000)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Based on: https://stackoverflow.com/questions/25351968/how-can-i-display-full-non-truncated-dataframe-information-in-html-when-conver\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 2000)\n",
    "    pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.float_format')\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the SpaCy Word Embeddings: \n",
    "Also using Spacy library: https://spacy.io/\n",
    "> !pip install -U spacy  \n",
    "> !python -m spacy download en_core_web_sm  \n",
    "> !python -m spacy download en_core_web_lg\n",
    "\n",
    "Some instructions on how to use it:  \n",
    "https://spacy.io/usage/spacy-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T22:38:26.997959Z",
     "start_time": "2022-04-28T22:38:25.715707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Importing SpaCy library:\n",
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': 300,\n",
       " 'vectors': 514157,\n",
       " 'keys': 514157,\n",
       " 'name': 'en_vectors',\n",
       " 'mode': 'default'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We check below that this model has 514.157 keys and vectors, respectively.\n",
    "nlp.meta['vectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514157"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Again, checking the number of keys.\n",
    "nlp.vocab.vectors.n_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514157, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting the word embedding: data (i.e., the matrix containing the vector values for each word)\n",
    "word_embedding = nlp.vocab.vectors.data\n",
    "\n",
    "## Verifying the shape of the word embedding matrix:\n",
    "word_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Finding the words associated with the embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting the words associated with each index:\n",
    "index = nlp.vocab.vectors.keys()\n",
    "words_associated = [nlp.vocab[i].text for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lahouaiej'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the word in position 514156, wich is \"Lahouaiej\":\n",
    "words_associated[514156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3201,   1147, 514156], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Finding the respective row (index) for a given word:\n",
    "rows = nlp.vocab.vectors.find(keys=[\"cat\", \"dog\", \"Lahouaiej\"])\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SCA - Glasgow Norms\n",
    "* Read the SCA from Glasgow Norms;  \n",
    "* Import F_s and F_o from the previous study;  \n",
    "* Train the MLP classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>F_Objectivity</th>\n",
       "      <th>F_Subjectivity</th>\n",
       "      <th>F_Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abattoir</td>\n",
       "      <td>0.512527</td>\n",
       "      <td>0.380603</td>\n",
       "      <td>0.960466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abbey</td>\n",
       "      <td>0.714765</td>\n",
       "      <td>0.240456</td>\n",
       "      <td>0.696198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbreviate</td>\n",
       "      <td>0.286952</td>\n",
       "      <td>0.171052</td>\n",
       "      <td>0.767043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdicate</td>\n",
       "      <td>0.144736</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>0.863127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdication</td>\n",
       "      <td>0.167654</td>\n",
       "      <td>0.334086</td>\n",
       "      <td>0.896733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  F_Objectivity  F_Subjectivity  F_Context\n",
       "0    abattoir       0.512527        0.380603   0.960466\n",
       "1       abbey       0.714765        0.240456   0.696198\n",
       "2  abbreviate       0.286952        0.171052   0.767043\n",
       "3    abdicate       0.144736        0.384300   0.863127\n",
       "4  abdication       0.167654        0.334086   0.896733"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_factors = pd.read_csv('../data/df_factors.csv', sep=';')\n",
    "df_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCA_words = [word for word in df_factors.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCA_embedding_rows =  nlp.vocab.vectors.find(keys=SCA_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5553"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SCA_embedding_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Separating the SCA-GlasgowNorms data into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar os dados em conjuntos de treino (70%) e teste (30%)\n",
    "train_df, test_df = train_test_split(df_factors, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar os conjuntos de treino e resposta\n",
    "def create_data(dataframe):\n",
    "    X = {}\n",
    "    Y = {}\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        word = row['words']\n",
    "        f_objectivity = row['F_Objectivity']\n",
    "        f_subjectivity = row['F_Subjectivity']\n",
    "\n",
    "        if word in nlp.vocab:\n",
    "            indice = nlp.vocab.strings[word]\n",
    "            vetor_embedding = word_embedding[index]\n",
    "            X[word] = vetor_embedding\n",
    "            Y[word] = {'F_Objectivity': f_objectivity, 'F_Subjectivity': f_subjectivity}\n",
    "\n",
    "    return pd.DataFrame.from_dict(X, orient='index'), pd.DataFrame.from_dict(Y, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data dimension:\n",
      "X_train: (3288, 300)\n",
      "Y_train: (3288, 2)\n",
      "\n",
      "Test data dimension:\n",
      "X_test: (1392, 300)\n",
      "Y_test: (1392, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating train and test datasets:\n",
    "X_train, Y_train = create_data(train_df)\n",
    "X_test, Y_test = create_data(test_df)\n",
    "\n",
    "# Exibir as dimensões dos conjuntos de treino e teste\n",
    "print(\"Train data dimension:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"Y_train:\", Y_train.shape)\n",
    "\n",
    "print(\"\\nTest data dimension:\")\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"Y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>airplane</th>\n",
       "      <td>-3.900300</td>\n",
       "      <td>3.93430</td>\n",
       "      <td>0.65395</td>\n",
       "      <td>1.29990</td>\n",
       "      <td>2.83170</td>\n",
       "      <td>1.508200</td>\n",
       "      <td>6.75800</td>\n",
       "      <td>5.364900</td>\n",
       "      <td>-2.36660</td>\n",
       "      <td>-3.08060</td>\n",
       "      <td>7.3809</td>\n",
       "      <td>0.22831</td>\n",
       "      <td>-2.47630</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>-0.68943</td>\n",
       "      <td>-2.390400</td>\n",
       "      <td>-0.060711</td>\n",
       "      <td>-3.533500</td>\n",
       "      <td>1.810800</td>\n",
       "      <td>-2.0253</td>\n",
       "      <td>-1.97780</td>\n",
       "      <td>-1.41780</td>\n",
       "      <td>-1.9544</td>\n",
       "      <td>0.10393</td>\n",
       "      <td>-2.83050</td>\n",
       "      <td>-3.57070</td>\n",
       "      <td>-2.80240</td>\n",
       "      <td>-0.88663</td>\n",
       "      <td>-3.289400</td>\n",
       "      <td>1.66370</td>\n",
       "      <td>5.91670</td>\n",
       "      <td>-0.091764</td>\n",
       "      <td>-2.84720</td>\n",
       "      <td>-5.14470</td>\n",
       "      <td>-2.39620</td>\n",
       "      <td>1.18960</td>\n",
       "      <td>-3.490000</td>\n",
       "      <td>1.823300</td>\n",
       "      <td>4.96860</td>\n",
       "      <td>2.07140</td>\n",
       "      <td>-2.244400</td>\n",
       "      <td>5.36050</td>\n",
       "      <td>-0.95761</td>\n",
       "      <td>4.29600</td>\n",
       "      <td>-0.21680</td>\n",
       "      <td>0.62048</td>\n",
       "      <td>1.73920</td>\n",
       "      <td>-5.99340</td>\n",
       "      <td>-2.89730</td>\n",
       "      <td>3.93680</td>\n",
       "      <td>-2.401700</td>\n",
       "      <td>1.49590</td>\n",
       "      <td>-0.054549</td>\n",
       "      <td>-6.26560</td>\n",
       "      <td>-4.5234</td>\n",
       "      <td>0.53169</td>\n",
       "      <td>1.63590</td>\n",
       "      <td>0.89828</td>\n",
       "      <td>1.03740</td>\n",
       "      <td>2.017600</td>\n",
       "      <td>-2.9216</td>\n",
       "      <td>1.64230</td>\n",
       "      <td>-3.3777</td>\n",
       "      <td>-0.49631</td>\n",
       "      <td>3.28690</td>\n",
       "      <td>2.7791</td>\n",
       "      <td>-2.59510</td>\n",
       "      <td>-3.8540</td>\n",
       "      <td>1.46620</td>\n",
       "      <td>2.8515</td>\n",
       "      <td>4.42560</td>\n",
       "      <td>3.98090</td>\n",
       "      <td>-0.73355</td>\n",
       "      <td>-0.119020</td>\n",
       "      <td>0.89358</td>\n",
       "      <td>0.70556</td>\n",
       "      <td>-2.02380</td>\n",
       "      <td>2.77660</td>\n",
       "      <td>0.26854</td>\n",
       "      <td>4.13280</td>\n",
       "      <td>-5.96310</td>\n",
       "      <td>-1.10990</td>\n",
       "      <td>1.34010</td>\n",
       "      <td>-1.51770</td>\n",
       "      <td>0.316740</td>\n",
       "      <td>-3.018500</td>\n",
       "      <td>-5.17970</td>\n",
       "      <td>-3.0217</td>\n",
       "      <td>-0.04403</td>\n",
       "      <td>0.049687</td>\n",
       "      <td>-1.47610</td>\n",
       "      <td>4.24500</td>\n",
       "      <td>3.33700</td>\n",
       "      <td>-1.33770</td>\n",
       "      <td>5.05770</td>\n",
       "      <td>1.07830</td>\n",
       "      <td>-0.016471</td>\n",
       "      <td>-2.56510</td>\n",
       "      <td>-1.393600</td>\n",
       "      <td>0.63940</td>\n",
       "      <td>1.57260</td>\n",
       "      <td>-0.011109</td>\n",
       "      <td>-1.69850</td>\n",
       "      <td>4.3501</td>\n",
       "      <td>-5.49180</td>\n",
       "      <td>5.04830</td>\n",
       "      <td>-2.20180</td>\n",
       "      <td>-0.41809</td>\n",
       "      <td>-0.78404</td>\n",
       "      <td>-0.66416</td>\n",
       "      <td>1.15280</td>\n",
       "      <td>1.23260</td>\n",
       "      <td>-1.30860</td>\n",
       "      <td>0.31578</td>\n",
       "      <td>-1.19400</td>\n",
       "      <td>3.92370</td>\n",
       "      <td>0.46197</td>\n",
       "      <td>1.06130</td>\n",
       "      <td>-0.319790</td>\n",
       "      <td>-2.38780</td>\n",
       "      <td>2.12210</td>\n",
       "      <td>-1.80540</td>\n",
       "      <td>-1.42700</td>\n",
       "      <td>0.53254</td>\n",
       "      <td>-3.0410</td>\n",
       "      <td>-2.34490</td>\n",
       "      <td>-1.62040</td>\n",
       "      <td>-2.96710</td>\n",
       "      <td>4.63050</td>\n",
       "      <td>0.16084</td>\n",
       "      <td>-4.8255</td>\n",
       "      <td>-0.29363</td>\n",
       "      <td>3.13940</td>\n",
       "      <td>-1.95800</td>\n",
       "      <td>-1.29290</td>\n",
       "      <td>4.14060</td>\n",
       "      <td>-0.038602</td>\n",
       "      <td>1.524500</td>\n",
       "      <td>5.9246</td>\n",
       "      <td>-2.75440</td>\n",
       "      <td>-2.19690</td>\n",
       "      <td>-0.31086</td>\n",
       "      <td>4.74790</td>\n",
       "      <td>-1.76610</td>\n",
       "      <td>-0.22267</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-1.75270</td>\n",
       "      <td>-0.050056</td>\n",
       "      <td>-2.55650</td>\n",
       "      <td>1.28360</td>\n",
       "      <td>0.41696</td>\n",
       "      <td>2.88090</td>\n",
       "      <td>0.355010</td>\n",
       "      <td>-0.87239</td>\n",
       "      <td>-1.04280</td>\n",
       "      <td>0.307970</td>\n",
       "      <td>4.1562</td>\n",
       "      <td>-1.008100</td>\n",
       "      <td>-1.14420</td>\n",
       "      <td>-1.09840</td>\n",
       "      <td>-1.91330</td>\n",
       "      <td>-1.54030</td>\n",
       "      <td>-3.62340</td>\n",
       "      <td>0.42826</td>\n",
       "      <td>-5.00650</td>\n",
       "      <td>-0.49866</td>\n",
       "      <td>-4.22030</td>\n",
       "      <td>2.79070</td>\n",
       "      <td>-0.38192</td>\n",
       "      <td>3.9372</td>\n",
       "      <td>-1.97130</td>\n",
       "      <td>3.24010</td>\n",
       "      <td>-0.78560</td>\n",
       "      <td>-0.079338</td>\n",
       "      <td>2.72100</td>\n",
       "      <td>-2.73960</td>\n",
       "      <td>-4.29080</td>\n",
       "      <td>-1.70190</td>\n",
       "      <td>-2.51120</td>\n",
       "      <td>0.14885</td>\n",
       "      <td>-2.91820</td>\n",
       "      <td>-0.40600</td>\n",
       "      <td>6.545700</td>\n",
       "      <td>-3.012900</td>\n",
       "      <td>-0.27173</td>\n",
       "      <td>-0.104410</td>\n",
       "      <td>-5.43240</td>\n",
       "      <td>-1.326000</td>\n",
       "      <td>3.23230</td>\n",
       "      <td>3.2203</td>\n",
       "      <td>1.94580</td>\n",
       "      <td>1.15240</td>\n",
       "      <td>-1.384000</td>\n",
       "      <td>2.16370</td>\n",
       "      <td>-2.54230</td>\n",
       "      <td>2.771200</td>\n",
       "      <td>-0.78878</td>\n",
       "      <td>-3.597100</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>2.14810</td>\n",
       "      <td>-2.43480</td>\n",
       "      <td>-8.08430</td>\n",
       "      <td>-3.99480</td>\n",
       "      <td>-3.24140</td>\n",
       "      <td>0.19680</td>\n",
       "      <td>1.93320</td>\n",
       "      <td>-1.234800</td>\n",
       "      <td>3.02840</td>\n",
       "      <td>-3.30660</td>\n",
       "      <td>0.92006</td>\n",
       "      <td>0.59873</td>\n",
       "      <td>0.294280</td>\n",
       "      <td>-1.83340</td>\n",
       "      <td>1.32660</td>\n",
       "      <td>1.281800</td>\n",
       "      <td>4.80140</td>\n",
       "      <td>0.95566</td>\n",
       "      <td>-2.15410</td>\n",
       "      <td>-1.82020</td>\n",
       "      <td>-0.559350</td>\n",
       "      <td>-2.19780</td>\n",
       "      <td>-1.86960</td>\n",
       "      <td>-0.83113</td>\n",
       "      <td>-0.29340</td>\n",
       "      <td>-3.46630</td>\n",
       "      <td>-3.49460</td>\n",
       "      <td>-1.11120</td>\n",
       "      <td>1.393900</td>\n",
       "      <td>2.5032</td>\n",
       "      <td>1.39520</td>\n",
       "      <td>0.29229</td>\n",
       "      <td>-2.8486</td>\n",
       "      <td>0.038245</td>\n",
       "      <td>2.59330</td>\n",
       "      <td>0.27597</td>\n",
       "      <td>2.113800</td>\n",
       "      <td>1.97000</td>\n",
       "      <td>5.78300</td>\n",
       "      <td>-7.13120</td>\n",
       "      <td>-1.47090</td>\n",
       "      <td>-1.117400</td>\n",
       "      <td>-0.45468</td>\n",
       "      <td>-1.92740</td>\n",
       "      <td>-1.14920</td>\n",
       "      <td>1.184000</td>\n",
       "      <td>-3.34210</td>\n",
       "      <td>-2.28830</td>\n",
       "      <td>1.93360</td>\n",
       "      <td>3.3205</td>\n",
       "      <td>5.47850</td>\n",
       "      <td>1.66630</td>\n",
       "      <td>-2.19340</td>\n",
       "      <td>-7.69760</td>\n",
       "      <td>1.85860</td>\n",
       "      <td>-0.22897</td>\n",
       "      <td>-2.68230</td>\n",
       "      <td>1.09740</td>\n",
       "      <td>0.35450</td>\n",
       "      <td>0.83341</td>\n",
       "      <td>0.53664</td>\n",
       "      <td>-0.57928</td>\n",
       "      <td>5.3247</td>\n",
       "      <td>1.9213</td>\n",
       "      <td>1.56950</td>\n",
       "      <td>-0.74805</td>\n",
       "      <td>-1.08930</td>\n",
       "      <td>3.24310</td>\n",
       "      <td>4.85570</td>\n",
       "      <td>-7.01540</td>\n",
       "      <td>1.43420</td>\n",
       "      <td>5.40910</td>\n",
       "      <td>-4.71290</td>\n",
       "      <td>-0.548970</td>\n",
       "      <td>-0.41088</td>\n",
       "      <td>0.66925</td>\n",
       "      <td>-2.922000</td>\n",
       "      <td>0.54973</td>\n",
       "      <td>-0.66148</td>\n",
       "      <td>-1.50200</td>\n",
       "      <td>1.3905</td>\n",
       "      <td>2.269300</td>\n",
       "      <td>1.57630</td>\n",
       "      <td>-1.49930</td>\n",
       "      <td>1.29760</td>\n",
       "      <td>3.150300</td>\n",
       "      <td>-3.51840</td>\n",
       "      <td>0.673510</td>\n",
       "      <td>3.10910</td>\n",
       "      <td>-6.3776</td>\n",
       "      <td>2.24180</td>\n",
       "      <td>-0.36937</td>\n",
       "      <td>1.10960</td>\n",
       "      <td>4.207400</td>\n",
       "      <td>1.66340</td>\n",
       "      <td>0.52245</td>\n",
       "      <td>3.5314</td>\n",
       "      <td>0.79304</td>\n",
       "      <td>0.11406</td>\n",
       "      <td>-5.10790</td>\n",
       "      <td>1.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coarse</th>\n",
       "      <td>2.042700</td>\n",
       "      <td>-2.06910</td>\n",
       "      <td>-1.59100</td>\n",
       "      <td>0.42295</td>\n",
       "      <td>3.51720</td>\n",
       "      <td>-0.042939</td>\n",
       "      <td>1.57450</td>\n",
       "      <td>5.945900</td>\n",
       "      <td>-7.09320</td>\n",
       "      <td>-3.81480</td>\n",
       "      <td>11.7570</td>\n",
       "      <td>4.35480</td>\n",
       "      <td>-3.72050</td>\n",
       "      <td>4.313600</td>\n",
       "      <td>0.26884</td>\n",
       "      <td>-0.443220</td>\n",
       "      <td>4.132300</td>\n",
       "      <td>1.703300</td>\n",
       "      <td>-3.872900</td>\n",
       "      <td>1.4727</td>\n",
       "      <td>-1.43550</td>\n",
       "      <td>0.94668</td>\n",
       "      <td>-3.8571</td>\n",
       "      <td>1.27040</td>\n",
       "      <td>-4.54170</td>\n",
       "      <td>-2.14030</td>\n",
       "      <td>1.29390</td>\n",
       "      <td>-1.74510</td>\n",
       "      <td>-5.526400</td>\n",
       "      <td>3.00230</td>\n",
       "      <td>2.44820</td>\n",
       "      <td>2.639000</td>\n",
       "      <td>-1.52310</td>\n",
       "      <td>2.31340</td>\n",
       "      <td>1.35940</td>\n",
       "      <td>-0.54864</td>\n",
       "      <td>2.054000</td>\n",
       "      <td>-0.170160</td>\n",
       "      <td>3.40220</td>\n",
       "      <td>-0.78957</td>\n",
       "      <td>-3.454300</td>\n",
       "      <td>0.54014</td>\n",
       "      <td>-0.11914</td>\n",
       "      <td>0.67721</td>\n",
       "      <td>-1.32260</td>\n",
       "      <td>4.33330</td>\n",
       "      <td>6.49880</td>\n",
       "      <td>-1.92460</td>\n",
       "      <td>1.47590</td>\n",
       "      <td>-0.98074</td>\n",
       "      <td>2.269100</td>\n",
       "      <td>2.51920</td>\n",
       "      <td>-0.378430</td>\n",
       "      <td>-6.23930</td>\n",
       "      <td>-1.1834</td>\n",
       "      <td>3.27730</td>\n",
       "      <td>-4.31950</td>\n",
       "      <td>2.05230</td>\n",
       "      <td>0.73059</td>\n",
       "      <td>-4.089200</td>\n",
       "      <td>4.8110</td>\n",
       "      <td>3.82850</td>\n",
       "      <td>-3.8583</td>\n",
       "      <td>0.64311</td>\n",
       "      <td>3.03840</td>\n",
       "      <td>6.5163</td>\n",
       "      <td>-2.40190</td>\n",
       "      <td>-1.0276</td>\n",
       "      <td>0.66792</td>\n",
       "      <td>2.5126</td>\n",
       "      <td>-1.84300</td>\n",
       "      <td>1.45240</td>\n",
       "      <td>-2.50840</td>\n",
       "      <td>-1.587100</td>\n",
       "      <td>-2.47370</td>\n",
       "      <td>1.26340</td>\n",
       "      <td>-2.13820</td>\n",
       "      <td>2.62900</td>\n",
       "      <td>-2.79220</td>\n",
       "      <td>3.31980</td>\n",
       "      <td>-5.65540</td>\n",
       "      <td>-2.47220</td>\n",
       "      <td>2.41710</td>\n",
       "      <td>2.82290</td>\n",
       "      <td>0.674250</td>\n",
       "      <td>1.683500</td>\n",
       "      <td>0.62230</td>\n",
       "      <td>-3.0518</td>\n",
       "      <td>4.01130</td>\n",
       "      <td>3.282600</td>\n",
       "      <td>-4.33350</td>\n",
       "      <td>-0.99384</td>\n",
       "      <td>1.03250</td>\n",
       "      <td>-3.25910</td>\n",
       "      <td>2.63790</td>\n",
       "      <td>-2.88770</td>\n",
       "      <td>4.076400</td>\n",
       "      <td>-1.01440</td>\n",
       "      <td>-3.144600</td>\n",
       "      <td>-2.40730</td>\n",
       "      <td>2.25510</td>\n",
       "      <td>1.203100</td>\n",
       "      <td>1.55070</td>\n",
       "      <td>0.4223</td>\n",
       "      <td>2.40900</td>\n",
       "      <td>8.36280</td>\n",
       "      <td>-2.88400</td>\n",
       "      <td>-6.41140</td>\n",
       "      <td>2.49140</td>\n",
       "      <td>-0.91834</td>\n",
       "      <td>3.68570</td>\n",
       "      <td>-0.40304</td>\n",
       "      <td>0.30373</td>\n",
       "      <td>-1.01040</td>\n",
       "      <td>0.70464</td>\n",
       "      <td>1.45450</td>\n",
       "      <td>-2.50800</td>\n",
       "      <td>-1.52900</td>\n",
       "      <td>-3.525500</td>\n",
       "      <td>-2.80110</td>\n",
       "      <td>-2.42530</td>\n",
       "      <td>-1.66710</td>\n",
       "      <td>0.83456</td>\n",
       "      <td>0.26350</td>\n",
       "      <td>1.4257</td>\n",
       "      <td>-6.30400</td>\n",
       "      <td>2.44460</td>\n",
       "      <td>-5.85960</td>\n",
       "      <td>1.55090</td>\n",
       "      <td>-3.20320</td>\n",
       "      <td>-5.7372</td>\n",
       "      <td>2.77660</td>\n",
       "      <td>2.84770</td>\n",
       "      <td>1.31420</td>\n",
       "      <td>-2.46830</td>\n",
       "      <td>1.96310</td>\n",
       "      <td>-1.667000</td>\n",
       "      <td>-0.841440</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>-3.32250</td>\n",
       "      <td>-2.62450</td>\n",
       "      <td>0.91188</td>\n",
       "      <td>-1.65780</td>\n",
       "      <td>-1.32340</td>\n",
       "      <td>2.59840</td>\n",
       "      <td>-2.458200</td>\n",
       "      <td>-0.38224</td>\n",
       "      <td>1.955800</td>\n",
       "      <td>3.28860</td>\n",
       "      <td>4.03430</td>\n",
       "      <td>-3.19270</td>\n",
       "      <td>3.37620</td>\n",
       "      <td>-1.001400</td>\n",
       "      <td>1.33840</td>\n",
       "      <td>-0.95402</td>\n",
       "      <td>0.051455</td>\n",
       "      <td>4.5192</td>\n",
       "      <td>3.340600</td>\n",
       "      <td>-0.18517</td>\n",
       "      <td>-2.15530</td>\n",
       "      <td>-0.11305</td>\n",
       "      <td>-2.00650</td>\n",
       "      <td>-0.32349</td>\n",
       "      <td>0.58643</td>\n",
       "      <td>-3.69460</td>\n",
       "      <td>-4.56340</td>\n",
       "      <td>-3.93610</td>\n",
       "      <td>0.52761</td>\n",
       "      <td>-1.69340</td>\n",
       "      <td>-4.4783</td>\n",
       "      <td>-4.98760</td>\n",
       "      <td>-5.44350</td>\n",
       "      <td>-0.18109</td>\n",
       "      <td>0.848120</td>\n",
       "      <td>3.82640</td>\n",
       "      <td>1.24350</td>\n",
       "      <td>1.86570</td>\n",
       "      <td>2.38550</td>\n",
       "      <td>-0.98788</td>\n",
       "      <td>-3.53360</td>\n",
       "      <td>-0.92577</td>\n",
       "      <td>-1.11740</td>\n",
       "      <td>-0.008842</td>\n",
       "      <td>-7.676500</td>\n",
       "      <td>-1.09620</td>\n",
       "      <td>0.306180</td>\n",
       "      <td>-2.43420</td>\n",
       "      <td>-2.690900</td>\n",
       "      <td>3.95540</td>\n",
       "      <td>-2.2016</td>\n",
       "      <td>-1.29390</td>\n",
       "      <td>-0.75266</td>\n",
       "      <td>-0.081766</td>\n",
       "      <td>-2.01910</td>\n",
       "      <td>2.97740</td>\n",
       "      <td>-1.234600</td>\n",
       "      <td>-6.57250</td>\n",
       "      <td>-0.105870</td>\n",
       "      <td>0.433400</td>\n",
       "      <td>2.35650</td>\n",
       "      <td>-2.98590</td>\n",
       "      <td>-1.05750</td>\n",
       "      <td>-6.06500</td>\n",
       "      <td>-0.93495</td>\n",
       "      <td>8.60080</td>\n",
       "      <td>0.30004</td>\n",
       "      <td>-3.853300</td>\n",
       "      <td>1.28420</td>\n",
       "      <td>3.86150</td>\n",
       "      <td>0.87080</td>\n",
       "      <td>4.07370</td>\n",
       "      <td>-2.319200</td>\n",
       "      <td>-1.82560</td>\n",
       "      <td>3.78550</td>\n",
       "      <td>0.340980</td>\n",
       "      <td>4.11250</td>\n",
       "      <td>-0.72653</td>\n",
       "      <td>-8.58240</td>\n",
       "      <td>0.36828</td>\n",
       "      <td>-0.344450</td>\n",
       "      <td>-2.75520</td>\n",
       "      <td>2.13960</td>\n",
       "      <td>1.99320</td>\n",
       "      <td>-1.99510</td>\n",
       "      <td>0.66178</td>\n",
       "      <td>-4.08820</td>\n",
       "      <td>2.41980</td>\n",
       "      <td>0.577990</td>\n",
       "      <td>3.0488</td>\n",
       "      <td>-0.76900</td>\n",
       "      <td>-1.28570</td>\n",
       "      <td>-3.7659</td>\n",
       "      <td>-2.280100</td>\n",
       "      <td>-0.36999</td>\n",
       "      <td>7.79510</td>\n",
       "      <td>4.220400</td>\n",
       "      <td>4.64980</td>\n",
       "      <td>3.48220</td>\n",
       "      <td>2.90390</td>\n",
       "      <td>2.24390</td>\n",
       "      <td>-1.837500</td>\n",
       "      <td>-5.10100</td>\n",
       "      <td>-0.34775</td>\n",
       "      <td>2.13040</td>\n",
       "      <td>0.525040</td>\n",
       "      <td>-2.94180</td>\n",
       "      <td>-3.59040</td>\n",
       "      <td>-0.61967</td>\n",
       "      <td>1.1622</td>\n",
       "      <td>0.51956</td>\n",
       "      <td>1.90330</td>\n",
       "      <td>-2.51030</td>\n",
       "      <td>-0.48914</td>\n",
       "      <td>-1.99650</td>\n",
       "      <td>1.75590</td>\n",
       "      <td>-0.97327</td>\n",
       "      <td>-0.97464</td>\n",
       "      <td>0.55097</td>\n",
       "      <td>1.86220</td>\n",
       "      <td>0.92131</td>\n",
       "      <td>3.10860</td>\n",
       "      <td>3.0548</td>\n",
       "      <td>1.6227</td>\n",
       "      <td>1.92500</td>\n",
       "      <td>5.10540</td>\n",
       "      <td>1.39620</td>\n",
       "      <td>0.15861</td>\n",
       "      <td>5.90950</td>\n",
       "      <td>-3.23000</td>\n",
       "      <td>-3.91970</td>\n",
       "      <td>-0.68823</td>\n",
       "      <td>-1.85420</td>\n",
       "      <td>1.997700</td>\n",
       "      <td>-1.28010</td>\n",
       "      <td>-2.55400</td>\n",
       "      <td>-0.792680</td>\n",
       "      <td>3.55030</td>\n",
       "      <td>0.47723</td>\n",
       "      <td>2.05990</td>\n",
       "      <td>2.0810</td>\n",
       "      <td>3.945100</td>\n",
       "      <td>1.27120</td>\n",
       "      <td>1.19940</td>\n",
       "      <td>0.56537</td>\n",
       "      <td>7.962800</td>\n",
       "      <td>0.51540</td>\n",
       "      <td>2.638100</td>\n",
       "      <td>1.52530</td>\n",
       "      <td>-1.4806</td>\n",
       "      <td>2.36910</td>\n",
       "      <td>0.48063</td>\n",
       "      <td>-3.19270</td>\n",
       "      <td>-1.133600</td>\n",
       "      <td>-1.53970</td>\n",
       "      <td>-0.97280</td>\n",
       "      <td>-0.2494</td>\n",
       "      <td>8.29990</td>\n",
       "      <td>-3.88090</td>\n",
       "      <td>-5.23350</td>\n",
       "      <td>3.850200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persecution</th>\n",
       "      <td>0.068316</td>\n",
       "      <td>4.34330</td>\n",
       "      <td>-5.55370</td>\n",
       "      <td>4.75970</td>\n",
       "      <td>2.12330</td>\n",
       "      <td>2.133900</td>\n",
       "      <td>0.55151</td>\n",
       "      <td>-0.290250</td>\n",
       "      <td>-4.60460</td>\n",
       "      <td>-0.51456</td>\n",
       "      <td>-1.3425</td>\n",
       "      <td>2.43150</td>\n",
       "      <td>-4.22010</td>\n",
       "      <td>-2.246000</td>\n",
       "      <td>-2.50050</td>\n",
       "      <td>-0.934730</td>\n",
       "      <td>-2.199000</td>\n",
       "      <td>-2.848000</td>\n",
       "      <td>-3.149100</td>\n",
       "      <td>-3.1937</td>\n",
       "      <td>0.42370</td>\n",
       "      <td>-1.09930</td>\n",
       "      <td>-2.1370</td>\n",
       "      <td>-0.28805</td>\n",
       "      <td>-3.81980</td>\n",
       "      <td>-0.40685</td>\n",
       "      <td>0.65904</td>\n",
       "      <td>-1.16870</td>\n",
       "      <td>-0.849820</td>\n",
       "      <td>-0.84344</td>\n",
       "      <td>5.87940</td>\n",
       "      <td>-4.655900</td>\n",
       "      <td>1.95800</td>\n",
       "      <td>-2.65690</td>\n",
       "      <td>-1.80940</td>\n",
       "      <td>-3.31670</td>\n",
       "      <td>0.962420</td>\n",
       "      <td>-1.334600</td>\n",
       "      <td>1.10600</td>\n",
       "      <td>-2.04600</td>\n",
       "      <td>-2.623400</td>\n",
       "      <td>-5.04220</td>\n",
       "      <td>-5.30670</td>\n",
       "      <td>5.77370</td>\n",
       "      <td>-5.86420</td>\n",
       "      <td>5.34060</td>\n",
       "      <td>1.16000</td>\n",
       "      <td>-7.87760</td>\n",
       "      <td>5.77020</td>\n",
       "      <td>4.13320</td>\n",
       "      <td>1.204400</td>\n",
       "      <td>-4.40440</td>\n",
       "      <td>4.653500</td>\n",
       "      <td>-7.24320</td>\n",
       "      <td>2.7926</td>\n",
       "      <td>4.95930</td>\n",
       "      <td>3.69890</td>\n",
       "      <td>-0.61183</td>\n",
       "      <td>-1.70640</td>\n",
       "      <td>3.727400</td>\n",
       "      <td>-2.3768</td>\n",
       "      <td>2.59290</td>\n",
       "      <td>-1.8523</td>\n",
       "      <td>2.23890</td>\n",
       "      <td>1.48830</td>\n",
       "      <td>-3.0840</td>\n",
       "      <td>-5.29610</td>\n",
       "      <td>1.5135</td>\n",
       "      <td>-2.18440</td>\n",
       "      <td>-1.6817</td>\n",
       "      <td>-1.58140</td>\n",
       "      <td>3.41980</td>\n",
       "      <td>-6.36440</td>\n",
       "      <td>3.120600</td>\n",
       "      <td>-2.55450</td>\n",
       "      <td>4.71060</td>\n",
       "      <td>0.44177</td>\n",
       "      <td>-2.04330</td>\n",
       "      <td>-3.85550</td>\n",
       "      <td>-3.92460</td>\n",
       "      <td>-1.88430</td>\n",
       "      <td>-4.03460</td>\n",
       "      <td>1.80540</td>\n",
       "      <td>0.14297</td>\n",
       "      <td>-3.485000</td>\n",
       "      <td>-0.166340</td>\n",
       "      <td>-1.05400</td>\n",
       "      <td>-3.0761</td>\n",
       "      <td>1.08100</td>\n",
       "      <td>2.862600</td>\n",
       "      <td>-5.40030</td>\n",
       "      <td>1.49940</td>\n",
       "      <td>1.97570</td>\n",
       "      <td>-2.19440</td>\n",
       "      <td>3.90870</td>\n",
       "      <td>-3.35410</td>\n",
       "      <td>1.350700</td>\n",
       "      <td>-7.48700</td>\n",
       "      <td>3.647600</td>\n",
       "      <td>4.34480</td>\n",
       "      <td>-3.60490</td>\n",
       "      <td>0.168820</td>\n",
       "      <td>-0.48981</td>\n",
       "      <td>-6.9565</td>\n",
       "      <td>-3.92430</td>\n",
       "      <td>-0.50639</td>\n",
       "      <td>-5.37260</td>\n",
       "      <td>1.76030</td>\n",
       "      <td>1.07730</td>\n",
       "      <td>-11.20400</td>\n",
       "      <td>0.64015</td>\n",
       "      <td>2.05970</td>\n",
       "      <td>1.30070</td>\n",
       "      <td>0.58045</td>\n",
       "      <td>4.67900</td>\n",
       "      <td>5.39410</td>\n",
       "      <td>-3.78570</td>\n",
       "      <td>-0.56545</td>\n",
       "      <td>0.307490</td>\n",
       "      <td>-2.82010</td>\n",
       "      <td>-6.45040</td>\n",
       "      <td>4.05570</td>\n",
       "      <td>-3.63020</td>\n",
       "      <td>-0.18437</td>\n",
       "      <td>3.5357</td>\n",
       "      <td>-4.07680</td>\n",
       "      <td>-4.38920</td>\n",
       "      <td>2.53090</td>\n",
       "      <td>5.57150</td>\n",
       "      <td>1.08600</td>\n",
       "      <td>-2.9182</td>\n",
       "      <td>-4.27100</td>\n",
       "      <td>0.24768</td>\n",
       "      <td>-3.19250</td>\n",
       "      <td>5.33060</td>\n",
       "      <td>3.33170</td>\n",
       "      <td>-5.574900</td>\n",
       "      <td>-6.309700</td>\n",
       "      <td>1.2430</td>\n",
       "      <td>-3.78240</td>\n",
       "      <td>-3.75980</td>\n",
       "      <td>-6.36870</td>\n",
       "      <td>-0.53144</td>\n",
       "      <td>-3.36840</td>\n",
       "      <td>-0.17049</td>\n",
       "      <td>-2.790100</td>\n",
       "      <td>-1.88460</td>\n",
       "      <td>-2.993200</td>\n",
       "      <td>2.90370</td>\n",
       "      <td>2.04970</td>\n",
       "      <td>-1.10960</td>\n",
       "      <td>-3.32500</td>\n",
       "      <td>-2.308300</td>\n",
       "      <td>-3.02970</td>\n",
       "      <td>5.01520</td>\n",
       "      <td>-2.914600</td>\n",
       "      <td>3.6464</td>\n",
       "      <td>-7.413700</td>\n",
       "      <td>0.99681</td>\n",
       "      <td>-0.11761</td>\n",
       "      <td>0.47407</td>\n",
       "      <td>2.19730</td>\n",
       "      <td>-1.58140</td>\n",
       "      <td>1.71370</td>\n",
       "      <td>-0.44272</td>\n",
       "      <td>-2.57820</td>\n",
       "      <td>-4.72310</td>\n",
       "      <td>1.00800</td>\n",
       "      <td>1.99990</td>\n",
       "      <td>3.8906</td>\n",
       "      <td>-3.29840</td>\n",
       "      <td>0.97767</td>\n",
       "      <td>0.15030</td>\n",
       "      <td>3.272700</td>\n",
       "      <td>-0.83230</td>\n",
       "      <td>4.64120</td>\n",
       "      <td>11.09500</td>\n",
       "      <td>2.71180</td>\n",
       "      <td>-1.70500</td>\n",
       "      <td>-2.94950</td>\n",
       "      <td>-9.65910</td>\n",
       "      <td>-1.84710</td>\n",
       "      <td>-0.169500</td>\n",
       "      <td>-4.341600</td>\n",
       "      <td>0.60770</td>\n",
       "      <td>1.699500</td>\n",
       "      <td>-0.91934</td>\n",
       "      <td>0.583280</td>\n",
       "      <td>-1.21130</td>\n",
       "      <td>4.8081</td>\n",
       "      <td>0.72203</td>\n",
       "      <td>2.58620</td>\n",
       "      <td>-1.344100</td>\n",
       "      <td>2.93530</td>\n",
       "      <td>-4.47850</td>\n",
       "      <td>-3.161000</td>\n",
       "      <td>2.21860</td>\n",
       "      <td>-1.001600</td>\n",
       "      <td>2.202600</td>\n",
       "      <td>7.71550</td>\n",
       "      <td>-7.57370</td>\n",
       "      <td>-4.67440</td>\n",
       "      <td>-0.17288</td>\n",
       "      <td>0.82796</td>\n",
       "      <td>-3.90840</td>\n",
       "      <td>-5.25760</td>\n",
       "      <td>-5.441300</td>\n",
       "      <td>2.54460</td>\n",
       "      <td>-1.38050</td>\n",
       "      <td>0.85349</td>\n",
       "      <td>5.67780</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.73630</td>\n",
       "      <td>2.55540</td>\n",
       "      <td>1.909700</td>\n",
       "      <td>-0.37607</td>\n",
       "      <td>4.09190</td>\n",
       "      <td>-3.40200</td>\n",
       "      <td>-3.55480</td>\n",
       "      <td>-5.484700</td>\n",
       "      <td>2.26840</td>\n",
       "      <td>0.18169</td>\n",
       "      <td>-7.13010</td>\n",
       "      <td>-0.33965</td>\n",
       "      <td>-0.77849</td>\n",
       "      <td>0.25872</td>\n",
       "      <td>-0.85297</td>\n",
       "      <td>0.044621</td>\n",
       "      <td>-1.2597</td>\n",
       "      <td>2.85650</td>\n",
       "      <td>-0.92115</td>\n",
       "      <td>-1.3267</td>\n",
       "      <td>2.274300</td>\n",
       "      <td>-8.91740</td>\n",
       "      <td>2.32480</td>\n",
       "      <td>-4.756500</td>\n",
       "      <td>-0.15451</td>\n",
       "      <td>6.79650</td>\n",
       "      <td>1.67640</td>\n",
       "      <td>-1.32770</td>\n",
       "      <td>-5.398400</td>\n",
       "      <td>2.16090</td>\n",
       "      <td>2.09240</td>\n",
       "      <td>-6.46170</td>\n",
       "      <td>2.970600</td>\n",
       "      <td>-4.02220</td>\n",
       "      <td>3.16400</td>\n",
       "      <td>3.52370</td>\n",
       "      <td>1.8952</td>\n",
       "      <td>4.20700</td>\n",
       "      <td>-4.48830</td>\n",
       "      <td>-0.73258</td>\n",
       "      <td>-9.39030</td>\n",
       "      <td>2.13960</td>\n",
       "      <td>0.69047</td>\n",
       "      <td>-2.87110</td>\n",
       "      <td>0.48702</td>\n",
       "      <td>-1.60770</td>\n",
       "      <td>3.71610</td>\n",
       "      <td>3.44150</td>\n",
       "      <td>-1.35300</td>\n",
       "      <td>6.3550</td>\n",
       "      <td>-3.6564</td>\n",
       "      <td>-2.69790</td>\n",
       "      <td>1.71680</td>\n",
       "      <td>0.37678</td>\n",
       "      <td>1.80010</td>\n",
       "      <td>1.75520</td>\n",
       "      <td>-6.87900</td>\n",
       "      <td>-5.20130</td>\n",
       "      <td>1.84370</td>\n",
       "      <td>-1.49970</td>\n",
       "      <td>0.378760</td>\n",
       "      <td>-8.52430</td>\n",
       "      <td>-3.86360</td>\n",
       "      <td>5.055000</td>\n",
       "      <td>-11.43600</td>\n",
       "      <td>4.33510</td>\n",
       "      <td>2.22680</td>\n",
       "      <td>2.4529</td>\n",
       "      <td>-5.233000</td>\n",
       "      <td>-0.80374</td>\n",
       "      <td>-2.86740</td>\n",
       "      <td>-6.58180</td>\n",
       "      <td>0.022082</td>\n",
       "      <td>-0.13392</td>\n",
       "      <td>0.076618</td>\n",
       "      <td>-5.05190</td>\n",
       "      <td>-5.9940</td>\n",
       "      <td>1.19410</td>\n",
       "      <td>-5.59980</td>\n",
       "      <td>2.51550</td>\n",
       "      <td>1.125900</td>\n",
       "      <td>0.71647</td>\n",
       "      <td>-3.38270</td>\n",
       "      <td>-1.9534</td>\n",
       "      <td>1.18160</td>\n",
       "      <td>2.24510</td>\n",
       "      <td>-1.91380</td>\n",
       "      <td>-0.074928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moment</th>\n",
       "      <td>-7.688900</td>\n",
       "      <td>0.56799</td>\n",
       "      <td>-2.18350</td>\n",
       "      <td>1.66660</td>\n",
       "      <td>3.30210</td>\n",
       "      <td>4.386700</td>\n",
       "      <td>-1.50380</td>\n",
       "      <td>5.213800</td>\n",
       "      <td>-0.37570</td>\n",
       "      <td>-1.74370</td>\n",
       "      <td>10.0440</td>\n",
       "      <td>5.34510</td>\n",
       "      <td>-4.76740</td>\n",
       "      <td>1.262700</td>\n",
       "      <td>-3.43640</td>\n",
       "      <td>1.718900</td>\n",
       "      <td>-6.290400</td>\n",
       "      <td>-1.052600</td>\n",
       "      <td>0.017089</td>\n",
       "      <td>-4.5076</td>\n",
       "      <td>-6.07950</td>\n",
       "      <td>-0.40140</td>\n",
       "      <td>-3.2510</td>\n",
       "      <td>-1.12350</td>\n",
       "      <td>-0.60938</td>\n",
       "      <td>3.05790</td>\n",
       "      <td>4.26910</td>\n",
       "      <td>2.16110</td>\n",
       "      <td>-0.095159</td>\n",
       "      <td>5.94480</td>\n",
       "      <td>-0.15644</td>\n",
       "      <td>-4.450900</td>\n",
       "      <td>1.51900</td>\n",
       "      <td>-3.21020</td>\n",
       "      <td>0.57536</td>\n",
       "      <td>-0.63007</td>\n",
       "      <td>-0.539930</td>\n",
       "      <td>-3.611300</td>\n",
       "      <td>1.08430</td>\n",
       "      <td>5.00290</td>\n",
       "      <td>-0.922590</td>\n",
       "      <td>-1.74930</td>\n",
       "      <td>-1.78280</td>\n",
       "      <td>2.38270</td>\n",
       "      <td>-2.00990</td>\n",
       "      <td>4.25600</td>\n",
       "      <td>0.96042</td>\n",
       "      <td>2.10830</td>\n",
       "      <td>0.68934</td>\n",
       "      <td>3.80630</td>\n",
       "      <td>0.015108</td>\n",
       "      <td>0.68857</td>\n",
       "      <td>-0.059503</td>\n",
       "      <td>-1.35980</td>\n",
       "      <td>-4.8023</td>\n",
       "      <td>5.69050</td>\n",
       "      <td>-0.26204</td>\n",
       "      <td>2.19090</td>\n",
       "      <td>-4.95260</td>\n",
       "      <td>5.182500</td>\n",
       "      <td>1.4434</td>\n",
       "      <td>1.42350</td>\n",
       "      <td>-3.4782</td>\n",
       "      <td>-4.96180</td>\n",
       "      <td>4.54700</td>\n",
       "      <td>2.3776</td>\n",
       "      <td>-0.75467</td>\n",
       "      <td>-5.8222</td>\n",
       "      <td>2.41730</td>\n",
       "      <td>2.7640</td>\n",
       "      <td>0.95128</td>\n",
       "      <td>1.17240</td>\n",
       "      <td>-2.86990</td>\n",
       "      <td>-1.333300</td>\n",
       "      <td>-1.73670</td>\n",
       "      <td>2.04840</td>\n",
       "      <td>-3.41090</td>\n",
       "      <td>2.23210</td>\n",
       "      <td>0.13952</td>\n",
       "      <td>3.92540</td>\n",
       "      <td>-3.27930</td>\n",
       "      <td>-1.77760</td>\n",
       "      <td>1.81430</td>\n",
       "      <td>3.91730</td>\n",
       "      <td>1.009300</td>\n",
       "      <td>4.215100</td>\n",
       "      <td>-3.18600</td>\n",
       "      <td>-5.0629</td>\n",
       "      <td>0.21069</td>\n",
       "      <td>1.450700</td>\n",
       "      <td>-1.55130</td>\n",
       "      <td>2.18650</td>\n",
       "      <td>0.15176</td>\n",
       "      <td>-4.35780</td>\n",
       "      <td>0.38870</td>\n",
       "      <td>1.04260</td>\n",
       "      <td>-1.201900</td>\n",
       "      <td>-3.75440</td>\n",
       "      <td>-1.983300</td>\n",
       "      <td>4.67910</td>\n",
       "      <td>4.79400</td>\n",
       "      <td>-3.120700</td>\n",
       "      <td>3.17340</td>\n",
       "      <td>4.5507</td>\n",
       "      <td>-4.51150</td>\n",
       "      <td>3.74700</td>\n",
       "      <td>3.84090</td>\n",
       "      <td>0.06178</td>\n",
       "      <td>-1.98630</td>\n",
       "      <td>1.69060</td>\n",
       "      <td>3.45130</td>\n",
       "      <td>1.17290</td>\n",
       "      <td>0.31355</td>\n",
       "      <td>0.77013</td>\n",
       "      <td>-0.25839</td>\n",
       "      <td>1.62780</td>\n",
       "      <td>-2.34050</td>\n",
       "      <td>0.59517</td>\n",
       "      <td>-2.287300</td>\n",
       "      <td>-0.10548</td>\n",
       "      <td>-0.44599</td>\n",
       "      <td>-3.49730</td>\n",
       "      <td>-1.89050</td>\n",
       "      <td>-1.83430</td>\n",
       "      <td>-3.4326</td>\n",
       "      <td>-1.34580</td>\n",
       "      <td>3.00660</td>\n",
       "      <td>2.51650</td>\n",
       "      <td>0.86985</td>\n",
       "      <td>0.53212</td>\n",
       "      <td>-2.3949</td>\n",
       "      <td>-3.80500</td>\n",
       "      <td>5.79310</td>\n",
       "      <td>0.82710</td>\n",
       "      <td>-2.68900</td>\n",
       "      <td>4.96250</td>\n",
       "      <td>-0.829510</td>\n",
       "      <td>3.317300</td>\n",
       "      <td>-4.8832</td>\n",
       "      <td>-1.71710</td>\n",
       "      <td>1.20790</td>\n",
       "      <td>5.58890</td>\n",
       "      <td>5.92850</td>\n",
       "      <td>0.85683</td>\n",
       "      <td>-2.41980</td>\n",
       "      <td>0.036704</td>\n",
       "      <td>-1.18760</td>\n",
       "      <td>1.106500</td>\n",
       "      <td>2.89530</td>\n",
       "      <td>4.41970</td>\n",
       "      <td>0.55039</td>\n",
       "      <td>4.41070</td>\n",
       "      <td>-0.722820</td>\n",
       "      <td>3.24640</td>\n",
       "      <td>2.12640</td>\n",
       "      <td>5.697500</td>\n",
       "      <td>3.6839</td>\n",
       "      <td>0.086178</td>\n",
       "      <td>-4.64510</td>\n",
       "      <td>-5.53280</td>\n",
       "      <td>1.59800</td>\n",
       "      <td>-0.32722</td>\n",
       "      <td>-0.99592</td>\n",
       "      <td>3.54220</td>\n",
       "      <td>-2.15680</td>\n",
       "      <td>-1.35580</td>\n",
       "      <td>0.33573</td>\n",
       "      <td>-1.81460</td>\n",
       "      <td>1.97760</td>\n",
       "      <td>-2.6072</td>\n",
       "      <td>-0.49377</td>\n",
       "      <td>1.00410</td>\n",
       "      <td>1.41860</td>\n",
       "      <td>-1.689600</td>\n",
       "      <td>2.33870</td>\n",
       "      <td>1.64520</td>\n",
       "      <td>-4.03310</td>\n",
       "      <td>2.86770</td>\n",
       "      <td>2.13270</td>\n",
       "      <td>-0.59078</td>\n",
       "      <td>0.11446</td>\n",
       "      <td>1.37830</td>\n",
       "      <td>-1.147000</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>-3.86880</td>\n",
       "      <td>-3.285600</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>3.026800</td>\n",
       "      <td>2.80580</td>\n",
       "      <td>8.1786</td>\n",
       "      <td>1.51190</td>\n",
       "      <td>0.76748</td>\n",
       "      <td>-0.306180</td>\n",
       "      <td>-0.20447</td>\n",
       "      <td>3.19520</td>\n",
       "      <td>0.050764</td>\n",
       "      <td>-3.83280</td>\n",
       "      <td>-4.562900</td>\n",
       "      <td>1.405100</td>\n",
       "      <td>1.20990</td>\n",
       "      <td>-0.46244</td>\n",
       "      <td>0.49520</td>\n",
       "      <td>-2.24960</td>\n",
       "      <td>-2.21270</td>\n",
       "      <td>-2.04830</td>\n",
       "      <td>-0.29449</td>\n",
       "      <td>-2.389000</td>\n",
       "      <td>-0.83991</td>\n",
       "      <td>5.98280</td>\n",
       "      <td>5.04540</td>\n",
       "      <td>0.19258</td>\n",
       "      <td>-0.093833</td>\n",
       "      <td>-5.75530</td>\n",
       "      <td>-3.19570</td>\n",
       "      <td>0.081784</td>\n",
       "      <td>-1.24730</td>\n",
       "      <td>0.89743</td>\n",
       "      <td>-0.77232</td>\n",
       "      <td>-3.86890</td>\n",
       "      <td>2.352800</td>\n",
       "      <td>-1.65810</td>\n",
       "      <td>3.58610</td>\n",
       "      <td>1.35350</td>\n",
       "      <td>-4.08790</td>\n",
       "      <td>-3.17090</td>\n",
       "      <td>-1.04000</td>\n",
       "      <td>-2.95890</td>\n",
       "      <td>4.319500</td>\n",
       "      <td>3.9136</td>\n",
       "      <td>0.66900</td>\n",
       "      <td>0.80280</td>\n",
       "      <td>-2.5065</td>\n",
       "      <td>3.333600</td>\n",
       "      <td>1.61520</td>\n",
       "      <td>-0.39701</td>\n",
       "      <td>2.602600</td>\n",
       "      <td>-0.31418</td>\n",
       "      <td>4.65460</td>\n",
       "      <td>-6.09340</td>\n",
       "      <td>1.37670</td>\n",
       "      <td>3.186300</td>\n",
       "      <td>-4.23590</td>\n",
       "      <td>-4.46750</td>\n",
       "      <td>5.67720</td>\n",
       "      <td>4.627900</td>\n",
       "      <td>0.75198</td>\n",
       "      <td>-2.02250</td>\n",
       "      <td>4.80130</td>\n",
       "      <td>7.6043</td>\n",
       "      <td>-1.32370</td>\n",
       "      <td>4.34110</td>\n",
       "      <td>-0.29942</td>\n",
       "      <td>-1.99690</td>\n",
       "      <td>1.59420</td>\n",
       "      <td>2.89660</td>\n",
       "      <td>-5.32890</td>\n",
       "      <td>-1.05400</td>\n",
       "      <td>1.28050</td>\n",
       "      <td>3.00150</td>\n",
       "      <td>-1.81870</td>\n",
       "      <td>-0.86083</td>\n",
       "      <td>1.6326</td>\n",
       "      <td>1.3456</td>\n",
       "      <td>-1.65490</td>\n",
       "      <td>1.18600</td>\n",
       "      <td>-0.93019</td>\n",
       "      <td>3.51560</td>\n",
       "      <td>-0.65960</td>\n",
       "      <td>-1.04720</td>\n",
       "      <td>-0.15340</td>\n",
       "      <td>4.06750</td>\n",
       "      <td>1.14690</td>\n",
       "      <td>0.058387</td>\n",
       "      <td>-0.20873</td>\n",
       "      <td>-2.66590</td>\n",
       "      <td>-1.395600</td>\n",
       "      <td>2.50070</td>\n",
       "      <td>3.17950</td>\n",
       "      <td>-2.57530</td>\n",
       "      <td>3.2376</td>\n",
       "      <td>4.661600</td>\n",
       "      <td>0.62102</td>\n",
       "      <td>2.00200</td>\n",
       "      <td>1.12280</td>\n",
       "      <td>-0.578350</td>\n",
       "      <td>-3.03170</td>\n",
       "      <td>3.652800</td>\n",
       "      <td>4.18340</td>\n",
       "      <td>-1.7926</td>\n",
       "      <td>-0.54218</td>\n",
       "      <td>-3.34500</td>\n",
       "      <td>1.48080</td>\n",
       "      <td>2.330200</td>\n",
       "      <td>-5.26970</td>\n",
       "      <td>-0.67720</td>\n",
       "      <td>-1.1638</td>\n",
       "      <td>-2.93030</td>\n",
       "      <td>-0.90046</td>\n",
       "      <td>-3.00530</td>\n",
       "      <td>1.682800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responsible</th>\n",
       "      <td>-0.638270</td>\n",
       "      <td>-0.20965</td>\n",
       "      <td>2.43960</td>\n",
       "      <td>-2.95510</td>\n",
       "      <td>8.56760</td>\n",
       "      <td>4.540600</td>\n",
       "      <td>1.55490</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>-4.06440</td>\n",
       "      <td>1.83910</td>\n",
       "      <td>8.6355</td>\n",
       "      <td>4.31000</td>\n",
       "      <td>-2.86120</td>\n",
       "      <td>3.884300</td>\n",
       "      <td>1.95520</td>\n",
       "      <td>0.636720</td>\n",
       "      <td>3.363700</td>\n",
       "      <td>0.241690</td>\n",
       "      <td>-2.137700</td>\n",
       "      <td>-1.2866</td>\n",
       "      <td>-0.29364</td>\n",
       "      <td>1.46590</td>\n",
       "      <td>-6.3379</td>\n",
       "      <td>0.84835</td>\n",
       "      <td>-1.86210</td>\n",
       "      <td>-0.88167</td>\n",
       "      <td>2.04370</td>\n",
       "      <td>-4.66290</td>\n",
       "      <td>-4.722900</td>\n",
       "      <td>0.69482</td>\n",
       "      <td>0.13129</td>\n",
       "      <td>1.476900</td>\n",
       "      <td>-1.69590</td>\n",
       "      <td>-0.66062</td>\n",
       "      <td>-0.18362</td>\n",
       "      <td>3.07470</td>\n",
       "      <td>-3.895000</td>\n",
       "      <td>1.507200</td>\n",
       "      <td>1.97030</td>\n",
       "      <td>2.84680</td>\n",
       "      <td>0.751650</td>\n",
       "      <td>-2.57500</td>\n",
       "      <td>-0.08866</td>\n",
       "      <td>4.10960</td>\n",
       "      <td>-0.57931</td>\n",
       "      <td>0.28668</td>\n",
       "      <td>5.55460</td>\n",
       "      <td>-0.38686</td>\n",
       "      <td>0.33243</td>\n",
       "      <td>-0.70699</td>\n",
       "      <td>-3.365500</td>\n",
       "      <td>5.43010</td>\n",
       "      <td>4.317500</td>\n",
       "      <td>-2.33060</td>\n",
       "      <td>-1.1958</td>\n",
       "      <td>0.72377</td>\n",
       "      <td>-2.97470</td>\n",
       "      <td>4.50990</td>\n",
       "      <td>0.39007</td>\n",
       "      <td>-2.297800</td>\n",
       "      <td>1.7473</td>\n",
       "      <td>0.38184</td>\n",
       "      <td>-1.7837</td>\n",
       "      <td>-1.38820</td>\n",
       "      <td>-1.88730</td>\n",
       "      <td>4.5330</td>\n",
       "      <td>-2.91680</td>\n",
       "      <td>-2.8414</td>\n",
       "      <td>0.28346</td>\n",
       "      <td>6.0842</td>\n",
       "      <td>-1.33780</td>\n",
       "      <td>4.12870</td>\n",
       "      <td>-2.12630</td>\n",
       "      <td>0.218620</td>\n",
       "      <td>-0.47545</td>\n",
       "      <td>-0.28176</td>\n",
       "      <td>0.64357</td>\n",
       "      <td>0.70815</td>\n",
       "      <td>-6.30050</td>\n",
       "      <td>6.88170</td>\n",
       "      <td>-0.81048</td>\n",
       "      <td>-4.49050</td>\n",
       "      <td>-0.05582</td>\n",
       "      <td>5.45360</td>\n",
       "      <td>2.049800</td>\n",
       "      <td>-1.334300</td>\n",
       "      <td>0.39381</td>\n",
       "      <td>1.2033</td>\n",
       "      <td>4.47960</td>\n",
       "      <td>-2.556800</td>\n",
       "      <td>-0.30427</td>\n",
       "      <td>-0.43990</td>\n",
       "      <td>3.43110</td>\n",
       "      <td>-1.51180</td>\n",
       "      <td>-3.44850</td>\n",
       "      <td>-0.14396</td>\n",
       "      <td>0.211030</td>\n",
       "      <td>0.73644</td>\n",
       "      <td>-3.574100</td>\n",
       "      <td>1.00070</td>\n",
       "      <td>0.34926</td>\n",
       "      <td>-0.038084</td>\n",
       "      <td>-0.12147</td>\n",
       "      <td>-1.3263</td>\n",
       "      <td>3.09370</td>\n",
       "      <td>2.05860</td>\n",
       "      <td>-1.07850</td>\n",
       "      <td>-1.44510</td>\n",
       "      <td>1.01360</td>\n",
       "      <td>-2.00260</td>\n",
       "      <td>3.88520</td>\n",
       "      <td>-1.28300</td>\n",
       "      <td>-0.95133</td>\n",
       "      <td>-1.47540</td>\n",
       "      <td>-4.08750</td>\n",
       "      <td>-0.95433</td>\n",
       "      <td>-3.46470</td>\n",
       "      <td>-0.22175</td>\n",
       "      <td>-1.657000</td>\n",
       "      <td>-1.10830</td>\n",
       "      <td>-3.33330</td>\n",
       "      <td>-4.48360</td>\n",
       "      <td>1.83610</td>\n",
       "      <td>3.18210</td>\n",
       "      <td>-4.0156</td>\n",
       "      <td>2.08560</td>\n",
       "      <td>-1.28940</td>\n",
       "      <td>-4.70140</td>\n",
       "      <td>2.06260</td>\n",
       "      <td>0.45006</td>\n",
       "      <td>-2.8907</td>\n",
       "      <td>1.13180</td>\n",
       "      <td>-0.93994</td>\n",
       "      <td>0.73698</td>\n",
       "      <td>1.48790</td>\n",
       "      <td>-2.62120</td>\n",
       "      <td>0.481220</td>\n",
       "      <td>-2.485900</td>\n",
       "      <td>3.8359</td>\n",
       "      <td>-0.87219</td>\n",
       "      <td>-4.23500</td>\n",
       "      <td>0.91940</td>\n",
       "      <td>3.65640</td>\n",
       "      <td>0.15135</td>\n",
       "      <td>-3.91090</td>\n",
       "      <td>-2.474400</td>\n",
       "      <td>1.42920</td>\n",
       "      <td>3.874400</td>\n",
       "      <td>-0.98322</td>\n",
       "      <td>-0.29984</td>\n",
       "      <td>1.44990</td>\n",
       "      <td>2.01320</td>\n",
       "      <td>-0.509520</td>\n",
       "      <td>-3.43370</td>\n",
       "      <td>-0.70837</td>\n",
       "      <td>1.536600</td>\n",
       "      <td>2.8661</td>\n",
       "      <td>4.895800</td>\n",
       "      <td>1.86250</td>\n",
       "      <td>-0.24276</td>\n",
       "      <td>-4.91790</td>\n",
       "      <td>-1.77090</td>\n",
       "      <td>-2.59000</td>\n",
       "      <td>1.83910</td>\n",
       "      <td>-5.19630</td>\n",
       "      <td>-1.25460</td>\n",
       "      <td>-0.20290</td>\n",
       "      <td>4.42930</td>\n",
       "      <td>2.22940</td>\n",
       "      <td>-3.6492</td>\n",
       "      <td>-1.22840</td>\n",
       "      <td>1.29550</td>\n",
       "      <td>-6.56860</td>\n",
       "      <td>4.045000</td>\n",
       "      <td>3.89240</td>\n",
       "      <td>1.56860</td>\n",
       "      <td>1.96810</td>\n",
       "      <td>1.18830</td>\n",
       "      <td>-2.31960</td>\n",
       "      <td>-2.17700</td>\n",
       "      <td>0.13151</td>\n",
       "      <td>1.17640</td>\n",
       "      <td>2.504200</td>\n",
       "      <td>-2.667700</td>\n",
       "      <td>0.87327</td>\n",
       "      <td>-2.128100</td>\n",
       "      <td>-0.63756</td>\n",
       "      <td>-2.291100</td>\n",
       "      <td>-0.18833</td>\n",
       "      <td>2.2716</td>\n",
       "      <td>0.84158</td>\n",
       "      <td>-5.43240</td>\n",
       "      <td>-1.053100</td>\n",
       "      <td>-4.32280</td>\n",
       "      <td>4.74300</td>\n",
       "      <td>-0.157190</td>\n",
       "      <td>-4.26570</td>\n",
       "      <td>-0.702300</td>\n",
       "      <td>3.844900</td>\n",
       "      <td>1.31280</td>\n",
       "      <td>-2.24870</td>\n",
       "      <td>-5.79350</td>\n",
       "      <td>-2.89630</td>\n",
       "      <td>-0.61781</td>\n",
       "      <td>4.56840</td>\n",
       "      <td>-0.97401</td>\n",
       "      <td>-1.033500</td>\n",
       "      <td>0.92388</td>\n",
       "      <td>3.28770</td>\n",
       "      <td>-2.13090</td>\n",
       "      <td>-4.37290</td>\n",
       "      <td>0.651320</td>\n",
       "      <td>-0.22954</td>\n",
       "      <td>6.09210</td>\n",
       "      <td>3.593800</td>\n",
       "      <td>3.10510</td>\n",
       "      <td>2.59140</td>\n",
       "      <td>-5.04660</td>\n",
       "      <td>1.25310</td>\n",
       "      <td>0.035322</td>\n",
       "      <td>-2.16530</td>\n",
       "      <td>3.26240</td>\n",
       "      <td>-1.23440</td>\n",
       "      <td>-0.94035</td>\n",
       "      <td>-0.30661</td>\n",
       "      <td>-3.95170</td>\n",
       "      <td>3.09280</td>\n",
       "      <td>5.530200</td>\n",
       "      <td>2.3109</td>\n",
       "      <td>-1.47430</td>\n",
       "      <td>-1.96780</td>\n",
       "      <td>-3.5667</td>\n",
       "      <td>-3.994300</td>\n",
       "      <td>3.50250</td>\n",
       "      <td>1.05360</td>\n",
       "      <td>0.966360</td>\n",
       "      <td>2.24550</td>\n",
       "      <td>5.06660</td>\n",
       "      <td>-0.11901</td>\n",
       "      <td>4.78090</td>\n",
       "      <td>-3.363300</td>\n",
       "      <td>-3.40330</td>\n",
       "      <td>-2.98510</td>\n",
       "      <td>-0.45114</td>\n",
       "      <td>-0.232280</td>\n",
       "      <td>3.25600</td>\n",
       "      <td>-2.77960</td>\n",
       "      <td>-2.44590</td>\n",
       "      <td>-1.3946</td>\n",
       "      <td>-0.48330</td>\n",
       "      <td>1.62750</td>\n",
       "      <td>-5.84550</td>\n",
       "      <td>-5.06910</td>\n",
       "      <td>-1.66860</td>\n",
       "      <td>0.95694</td>\n",
       "      <td>-0.27934</td>\n",
       "      <td>-1.47030</td>\n",
       "      <td>0.55012</td>\n",
       "      <td>2.37760</td>\n",
       "      <td>0.87968</td>\n",
       "      <td>1.16200</td>\n",
       "      <td>6.4236</td>\n",
       "      <td>-2.1488</td>\n",
       "      <td>0.36583</td>\n",
       "      <td>2.09410</td>\n",
       "      <td>-1.70460</td>\n",
       "      <td>-0.90162</td>\n",
       "      <td>0.94648</td>\n",
       "      <td>-1.56380</td>\n",
       "      <td>-4.08680</td>\n",
       "      <td>0.49151</td>\n",
       "      <td>-1.37700</td>\n",
       "      <td>-1.525300</td>\n",
       "      <td>-1.87430</td>\n",
       "      <td>1.52430</td>\n",
       "      <td>-0.014179</td>\n",
       "      <td>-2.90690</td>\n",
       "      <td>3.91830</td>\n",
       "      <td>-1.21080</td>\n",
       "      <td>4.1508</td>\n",
       "      <td>4.915100</td>\n",
       "      <td>0.21788</td>\n",
       "      <td>-0.49317</td>\n",
       "      <td>-0.51851</td>\n",
       "      <td>3.933100</td>\n",
       "      <td>1.44520</td>\n",
       "      <td>3.884100</td>\n",
       "      <td>4.73100</td>\n",
       "      <td>-3.1003</td>\n",
       "      <td>1.15710</td>\n",
       "      <td>-1.75900</td>\n",
       "      <td>0.41543</td>\n",
       "      <td>0.014483</td>\n",
       "      <td>1.33840</td>\n",
       "      <td>0.57833</td>\n",
       "      <td>2.7432</td>\n",
       "      <td>-0.39032</td>\n",
       "      <td>-2.44960</td>\n",
       "      <td>1.18580</td>\n",
       "      <td>4.603100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prawn</th>\n",
       "      <td>-0.555210</td>\n",
       "      <td>-1.20940</td>\n",
       "      <td>-1.59380</td>\n",
       "      <td>0.85357</td>\n",
       "      <td>0.11995</td>\n",
       "      <td>0.819640</td>\n",
       "      <td>1.38210</td>\n",
       "      <td>2.358900</td>\n",
       "      <td>-0.45013</td>\n",
       "      <td>0.79720</td>\n",
       "      <td>4.4177</td>\n",
       "      <td>1.49190</td>\n",
       "      <td>-1.38680</td>\n",
       "      <td>1.735400</td>\n",
       "      <td>1.59320</td>\n",
       "      <td>-0.007249</td>\n",
       "      <td>1.506900</td>\n",
       "      <td>-0.086719</td>\n",
       "      <td>-1.357800</td>\n",
       "      <td>-1.3076</td>\n",
       "      <td>1.96040</td>\n",
       "      <td>2.54860</td>\n",
       "      <td>-1.3290</td>\n",
       "      <td>-2.80820</td>\n",
       "      <td>0.19496</td>\n",
       "      <td>-3.13150</td>\n",
       "      <td>-2.24660</td>\n",
       "      <td>-2.50650</td>\n",
       "      <td>-2.861500</td>\n",
       "      <td>0.44785</td>\n",
       "      <td>0.80668</td>\n",
       "      <td>-1.417200</td>\n",
       "      <td>-0.85002</td>\n",
       "      <td>1.04690</td>\n",
       "      <td>-1.22520</td>\n",
       "      <td>-0.21808</td>\n",
       "      <td>-1.013900</td>\n",
       "      <td>0.041965</td>\n",
       "      <td>2.60150</td>\n",
       "      <td>1.55600</td>\n",
       "      <td>-0.070996</td>\n",
       "      <td>-0.57363</td>\n",
       "      <td>-0.28696</td>\n",
       "      <td>-0.12214</td>\n",
       "      <td>0.67195</td>\n",
       "      <td>0.60949</td>\n",
       "      <td>0.32463</td>\n",
       "      <td>-2.32220</td>\n",
       "      <td>-2.49200</td>\n",
       "      <td>1.98890</td>\n",
       "      <td>0.433630</td>\n",
       "      <td>1.35570</td>\n",
       "      <td>0.439420</td>\n",
       "      <td>-4.62640</td>\n",
       "      <td>-2.3616</td>\n",
       "      <td>-0.68795</td>\n",
       "      <td>0.96643</td>\n",
       "      <td>0.50996</td>\n",
       "      <td>1.49600</td>\n",
       "      <td>-0.439710</td>\n",
       "      <td>1.6498</td>\n",
       "      <td>1.11770</td>\n",
       "      <td>-1.8202</td>\n",
       "      <td>-0.37879</td>\n",
       "      <td>0.99955</td>\n",
       "      <td>-1.0961</td>\n",
       "      <td>-3.30240</td>\n",
       "      <td>-2.8575</td>\n",
       "      <td>0.28605</td>\n",
       "      <td>2.1055</td>\n",
       "      <td>0.57166</td>\n",
       "      <td>0.73573</td>\n",
       "      <td>-0.52267</td>\n",
       "      <td>1.183200</td>\n",
       "      <td>0.63967</td>\n",
       "      <td>0.15548</td>\n",
       "      <td>-3.99830</td>\n",
       "      <td>1.29710</td>\n",
       "      <td>-1.14900</td>\n",
       "      <td>-0.65285</td>\n",
       "      <td>-3.27830</td>\n",
       "      <td>0.43801</td>\n",
       "      <td>2.63580</td>\n",
       "      <td>0.41438</td>\n",
       "      <td>3.420500</td>\n",
       "      <td>-1.178200</td>\n",
       "      <td>-1.57040</td>\n",
       "      <td>-3.1601</td>\n",
       "      <td>2.18660</td>\n",
       "      <td>-0.830020</td>\n",
       "      <td>-0.25336</td>\n",
       "      <td>1.41320</td>\n",
       "      <td>2.89940</td>\n",
       "      <td>-2.84560</td>\n",
       "      <td>0.48514</td>\n",
       "      <td>-1.58330</td>\n",
       "      <td>2.266300</td>\n",
       "      <td>-2.54060</td>\n",
       "      <td>0.894110</td>\n",
       "      <td>-0.31395</td>\n",
       "      <td>1.43480</td>\n",
       "      <td>1.501900</td>\n",
       "      <td>1.38260</td>\n",
       "      <td>1.8610</td>\n",
       "      <td>-0.50059</td>\n",
       "      <td>4.21610</td>\n",
       "      <td>-0.22724</td>\n",
       "      <td>-0.32698</td>\n",
       "      <td>-0.61409</td>\n",
       "      <td>-1.12580</td>\n",
       "      <td>0.59901</td>\n",
       "      <td>-1.25530</td>\n",
       "      <td>1.20990</td>\n",
       "      <td>-0.30591</td>\n",
       "      <td>0.97642</td>\n",
       "      <td>-0.47297</td>\n",
       "      <td>-1.06940</td>\n",
       "      <td>-2.06600</td>\n",
       "      <td>1.399000</td>\n",
       "      <td>-3.58810</td>\n",
       "      <td>-1.68080</td>\n",
       "      <td>-1.63680</td>\n",
       "      <td>-2.66290</td>\n",
       "      <td>1.94300</td>\n",
       "      <td>-1.5802</td>\n",
       "      <td>-1.59290</td>\n",
       "      <td>1.22260</td>\n",
       "      <td>-2.00820</td>\n",
       "      <td>0.48073</td>\n",
       "      <td>-0.88187</td>\n",
       "      <td>-1.6929</td>\n",
       "      <td>0.62347</td>\n",
       "      <td>1.05970</td>\n",
       "      <td>-0.60525</td>\n",
       "      <td>0.36383</td>\n",
       "      <td>1.00030</td>\n",
       "      <td>-0.355750</td>\n",
       "      <td>-2.145400</td>\n",
       "      <td>3.5754</td>\n",
       "      <td>-2.42000</td>\n",
       "      <td>-1.10320</td>\n",
       "      <td>-0.56871</td>\n",
       "      <td>1.33020</td>\n",
       "      <td>0.38080</td>\n",
       "      <td>-0.77858</td>\n",
       "      <td>-2.356900</td>\n",
       "      <td>-1.01010</td>\n",
       "      <td>-1.456400</td>\n",
       "      <td>-1.41680</td>\n",
       "      <td>-1.41010</td>\n",
       "      <td>-0.91237</td>\n",
       "      <td>1.19580</td>\n",
       "      <td>-1.330800</td>\n",
       "      <td>1.71620</td>\n",
       "      <td>-2.02410</td>\n",
       "      <td>1.289600</td>\n",
       "      <td>4.7248</td>\n",
       "      <td>-0.483540</td>\n",
       "      <td>-2.54350</td>\n",
       "      <td>-0.54130</td>\n",
       "      <td>0.32934</td>\n",
       "      <td>-1.32690</td>\n",
       "      <td>-0.54886</td>\n",
       "      <td>0.42794</td>\n",
       "      <td>-2.72180</td>\n",
       "      <td>-1.29370</td>\n",
       "      <td>-1.82900</td>\n",
       "      <td>0.41575</td>\n",
       "      <td>1.42500</td>\n",
       "      <td>1.6748</td>\n",
       "      <td>2.44250</td>\n",
       "      <td>-1.09810</td>\n",
       "      <td>1.25560</td>\n",
       "      <td>0.503130</td>\n",
       "      <td>2.19230</td>\n",
       "      <td>-1.28090</td>\n",
       "      <td>-1.39880</td>\n",
       "      <td>2.02120</td>\n",
       "      <td>-1.88280</td>\n",
       "      <td>-0.39164</td>\n",
       "      <td>-1.58550</td>\n",
       "      <td>-0.36367</td>\n",
       "      <td>3.765500</td>\n",
       "      <td>0.293570</td>\n",
       "      <td>0.30051</td>\n",
       "      <td>0.080223</td>\n",
       "      <td>-0.98590</td>\n",
       "      <td>-1.920200</td>\n",
       "      <td>2.13860</td>\n",
       "      <td>2.6969</td>\n",
       "      <td>-1.33410</td>\n",
       "      <td>0.95185</td>\n",
       "      <td>-1.263900</td>\n",
       "      <td>0.21003</td>\n",
       "      <td>0.19744</td>\n",
       "      <td>-1.192300</td>\n",
       "      <td>-2.83750</td>\n",
       "      <td>0.101560</td>\n",
       "      <td>0.944520</td>\n",
       "      <td>2.57890</td>\n",
       "      <td>-1.19540</td>\n",
       "      <td>0.80411</td>\n",
       "      <td>-2.12390</td>\n",
       "      <td>0.44031</td>\n",
       "      <td>1.97040</td>\n",
       "      <td>1.08730</td>\n",
       "      <td>-0.117200</td>\n",
       "      <td>-0.14338</td>\n",
       "      <td>-1.22470</td>\n",
       "      <td>-1.87710</td>\n",
       "      <td>1.11770</td>\n",
       "      <td>-0.570940</td>\n",
       "      <td>0.56189</td>\n",
       "      <td>1.11130</td>\n",
       "      <td>-2.205400</td>\n",
       "      <td>-0.06675</td>\n",
       "      <td>1.80260</td>\n",
       "      <td>-1.01180</td>\n",
       "      <td>0.10635</td>\n",
       "      <td>0.579770</td>\n",
       "      <td>-2.48590</td>\n",
       "      <td>-0.53602</td>\n",
       "      <td>-1.30350</td>\n",
       "      <td>2.12540</td>\n",
       "      <td>0.23927</td>\n",
       "      <td>-1.13900</td>\n",
       "      <td>1.39190</td>\n",
       "      <td>1.890500</td>\n",
       "      <td>2.2045</td>\n",
       "      <td>2.44450</td>\n",
       "      <td>-1.82030</td>\n",
       "      <td>-2.8197</td>\n",
       "      <td>-0.630170</td>\n",
       "      <td>-0.11690</td>\n",
       "      <td>-0.36900</td>\n",
       "      <td>0.087937</td>\n",
       "      <td>-1.55890</td>\n",
       "      <td>2.96980</td>\n",
       "      <td>1.29060</td>\n",
       "      <td>0.56415</td>\n",
       "      <td>-3.074000</td>\n",
       "      <td>0.87650</td>\n",
       "      <td>2.27160</td>\n",
       "      <td>0.78658</td>\n",
       "      <td>-1.452400</td>\n",
       "      <td>-1.18910</td>\n",
       "      <td>-0.14552</td>\n",
       "      <td>1.11020</td>\n",
       "      <td>2.8045</td>\n",
       "      <td>2.52440</td>\n",
       "      <td>-0.41811</td>\n",
       "      <td>-0.26705</td>\n",
       "      <td>-5.74630</td>\n",
       "      <td>-0.43291</td>\n",
       "      <td>0.92065</td>\n",
       "      <td>-4.38000</td>\n",
       "      <td>0.34797</td>\n",
       "      <td>0.52697</td>\n",
       "      <td>-0.48560</td>\n",
       "      <td>0.70011</td>\n",
       "      <td>1.14140</td>\n",
       "      <td>3.1286</td>\n",
       "      <td>2.7785</td>\n",
       "      <td>3.20760</td>\n",
       "      <td>0.58293</td>\n",
       "      <td>-0.57667</td>\n",
       "      <td>1.24440</td>\n",
       "      <td>2.48680</td>\n",
       "      <td>-3.89850</td>\n",
       "      <td>1.04800</td>\n",
       "      <td>1.24410</td>\n",
       "      <td>-0.29225</td>\n",
       "      <td>-1.092200</td>\n",
       "      <td>1.07380</td>\n",
       "      <td>-0.55544</td>\n",
       "      <td>-1.909400</td>\n",
       "      <td>1.65140</td>\n",
       "      <td>-1.42600</td>\n",
       "      <td>-1.16200</td>\n",
       "      <td>2.1906</td>\n",
       "      <td>-0.144720</td>\n",
       "      <td>-0.73245</td>\n",
       "      <td>2.31740</td>\n",
       "      <td>-0.25365</td>\n",
       "      <td>5.161100</td>\n",
       "      <td>-1.22130</td>\n",
       "      <td>2.924400</td>\n",
       "      <td>0.74770</td>\n",
       "      <td>-2.9230</td>\n",
       "      <td>1.30990</td>\n",
       "      <td>1.62700</td>\n",
       "      <td>-1.79590</td>\n",
       "      <td>2.008100</td>\n",
       "      <td>-1.23140</td>\n",
       "      <td>-3.08860</td>\n",
       "      <td>-1.1762</td>\n",
       "      <td>3.87150</td>\n",
       "      <td>0.28911</td>\n",
       "      <td>-2.57810</td>\n",
       "      <td>3.099400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweezers</th>\n",
       "      <td>-1.998400</td>\n",
       "      <td>1.01710</td>\n",
       "      <td>1.24380</td>\n",
       "      <td>-0.67552</td>\n",
       "      <td>5.93120</td>\n",
       "      <td>2.095500</td>\n",
       "      <td>9.03150</td>\n",
       "      <td>-3.656900</td>\n",
       "      <td>-1.58780</td>\n",
       "      <td>2.31650</td>\n",
       "      <td>-7.8383</td>\n",
       "      <td>-3.04760</td>\n",
       "      <td>0.53385</td>\n",
       "      <td>-4.658400</td>\n",
       "      <td>-5.50930</td>\n",
       "      <td>-0.144140</td>\n",
       "      <td>-2.957600</td>\n",
       "      <td>3.884200</td>\n",
       "      <td>-0.261430</td>\n",
       "      <td>7.2422</td>\n",
       "      <td>0.80466</td>\n",
       "      <td>6.26090</td>\n",
       "      <td>3.8815</td>\n",
       "      <td>-4.15570</td>\n",
       "      <td>8.75300</td>\n",
       "      <td>-0.36023</td>\n",
       "      <td>3.60130</td>\n",
       "      <td>-1.01360</td>\n",
       "      <td>3.390400</td>\n",
       "      <td>-3.53180</td>\n",
       "      <td>-7.93520</td>\n",
       "      <td>5.759200</td>\n",
       "      <td>-1.64000</td>\n",
       "      <td>6.84850</td>\n",
       "      <td>-1.06040</td>\n",
       "      <td>-0.34016</td>\n",
       "      <td>-1.574700</td>\n",
       "      <td>-1.868700</td>\n",
       "      <td>-2.42510</td>\n",
       "      <td>-5.18620</td>\n",
       "      <td>-1.089400</td>\n",
       "      <td>3.21340</td>\n",
       "      <td>3.45950</td>\n",
       "      <td>-3.49460</td>\n",
       "      <td>1.72360</td>\n",
       "      <td>-3.97270</td>\n",
       "      <td>0.99131</td>\n",
       "      <td>0.69573</td>\n",
       "      <td>-5.59780</td>\n",
       "      <td>3.36330</td>\n",
       "      <td>-5.347700</td>\n",
       "      <td>0.78380</td>\n",
       "      <td>2.169700</td>\n",
       "      <td>0.79255</td>\n",
       "      <td>-3.4373</td>\n",
       "      <td>-7.35500</td>\n",
       "      <td>3.03790</td>\n",
       "      <td>-1.63840</td>\n",
       "      <td>-5.24980</td>\n",
       "      <td>-2.428800</td>\n",
       "      <td>3.4233</td>\n",
       "      <td>5.22310</td>\n",
       "      <td>-4.1671</td>\n",
       "      <td>1.75210</td>\n",
       "      <td>3.43010</td>\n",
       "      <td>-1.3719</td>\n",
       "      <td>3.17720</td>\n",
       "      <td>3.3355</td>\n",
       "      <td>-1.02590</td>\n",
       "      <td>-1.0918</td>\n",
       "      <td>5.74780</td>\n",
       "      <td>-6.17680</td>\n",
       "      <td>-0.90611</td>\n",
       "      <td>-0.340530</td>\n",
       "      <td>-3.73790</td>\n",
       "      <td>2.86700</td>\n",
       "      <td>3.94590</td>\n",
       "      <td>1.07560</td>\n",
       "      <td>1.00450</td>\n",
       "      <td>-1.72910</td>\n",
       "      <td>3.21970</td>\n",
       "      <td>2.09330</td>\n",
       "      <td>0.44786</td>\n",
       "      <td>0.38864</td>\n",
       "      <td>0.092844</td>\n",
       "      <td>-7.526000</td>\n",
       "      <td>-5.14850</td>\n",
       "      <td>-2.6222</td>\n",
       "      <td>-0.66842</td>\n",
       "      <td>-0.401070</td>\n",
       "      <td>-0.63273</td>\n",
       "      <td>0.44273</td>\n",
       "      <td>-3.57870</td>\n",
       "      <td>1.88100</td>\n",
       "      <td>-3.06600</td>\n",
       "      <td>0.96110</td>\n",
       "      <td>-1.738500</td>\n",
       "      <td>2.21080</td>\n",
       "      <td>6.470400</td>\n",
       "      <td>4.43040</td>\n",
       "      <td>0.52488</td>\n",
       "      <td>0.868510</td>\n",
       "      <td>1.09790</td>\n",
       "      <td>3.8364</td>\n",
       "      <td>7.12610</td>\n",
       "      <td>-1.28140</td>\n",
       "      <td>3.61210</td>\n",
       "      <td>2.34360</td>\n",
       "      <td>4.08700</td>\n",
       "      <td>2.74710</td>\n",
       "      <td>-1.38700</td>\n",
       "      <td>3.22070</td>\n",
       "      <td>1.17870</td>\n",
       "      <td>-1.34500</td>\n",
       "      <td>-6.25450</td>\n",
       "      <td>-6.11970</td>\n",
       "      <td>1.24090</td>\n",
       "      <td>0.74903</td>\n",
       "      <td>-7.940300</td>\n",
       "      <td>1.32520</td>\n",
       "      <td>0.12838</td>\n",
       "      <td>-0.97745</td>\n",
       "      <td>5.31560</td>\n",
       "      <td>-2.22900</td>\n",
       "      <td>-1.8447</td>\n",
       "      <td>2.27250</td>\n",
       "      <td>-1.63490</td>\n",
       "      <td>1.89690</td>\n",
       "      <td>-0.38576</td>\n",
       "      <td>-2.04050</td>\n",
       "      <td>-1.6867</td>\n",
       "      <td>2.99530</td>\n",
       "      <td>2.30300</td>\n",
       "      <td>2.58140</td>\n",
       "      <td>-1.50950</td>\n",
       "      <td>-0.96319</td>\n",
       "      <td>2.648400</td>\n",
       "      <td>1.731300</td>\n",
       "      <td>2.2987</td>\n",
       "      <td>-2.23230</td>\n",
       "      <td>-0.28140</td>\n",
       "      <td>-2.49560</td>\n",
       "      <td>-2.53810</td>\n",
       "      <td>-3.74270</td>\n",
       "      <td>-1.87680</td>\n",
       "      <td>-7.723100</td>\n",
       "      <td>-0.64728</td>\n",
       "      <td>9.056800</td>\n",
       "      <td>0.53917</td>\n",
       "      <td>-5.36820</td>\n",
       "      <td>3.61550</td>\n",
       "      <td>-3.54470</td>\n",
       "      <td>-2.368200</td>\n",
       "      <td>3.67690</td>\n",
       "      <td>-0.21525</td>\n",
       "      <td>0.233910</td>\n",
       "      <td>-3.2361</td>\n",
       "      <td>-3.658500</td>\n",
       "      <td>2.16660</td>\n",
       "      <td>0.87207</td>\n",
       "      <td>-2.27130</td>\n",
       "      <td>-1.76050</td>\n",
       "      <td>-0.56142</td>\n",
       "      <td>-3.73920</td>\n",
       "      <td>-3.43280</td>\n",
       "      <td>-1.33920</td>\n",
       "      <td>3.33600</td>\n",
       "      <td>-2.57590</td>\n",
       "      <td>-4.89360</td>\n",
       "      <td>-4.2442</td>\n",
       "      <td>2.35060</td>\n",
       "      <td>-1.33260</td>\n",
       "      <td>-3.76300</td>\n",
       "      <td>-1.551900</td>\n",
       "      <td>2.77840</td>\n",
       "      <td>2.04460</td>\n",
       "      <td>1.96560</td>\n",
       "      <td>-5.09600</td>\n",
       "      <td>1.46480</td>\n",
       "      <td>1.77810</td>\n",
       "      <td>-3.98320</td>\n",
       "      <td>1.86650</td>\n",
       "      <td>-0.296200</td>\n",
       "      <td>-1.429700</td>\n",
       "      <td>4.70510</td>\n",
       "      <td>-3.904300</td>\n",
       "      <td>4.65730</td>\n",
       "      <td>0.013339</td>\n",
       "      <td>4.52800</td>\n",
       "      <td>6.1138</td>\n",
       "      <td>3.76860</td>\n",
       "      <td>0.74584</td>\n",
       "      <td>3.403800</td>\n",
       "      <td>2.45690</td>\n",
       "      <td>6.35240</td>\n",
       "      <td>3.060000</td>\n",
       "      <td>1.42010</td>\n",
       "      <td>0.398030</td>\n",
       "      <td>0.506680</td>\n",
       "      <td>2.47210</td>\n",
       "      <td>10.89100</td>\n",
       "      <td>4.09930</td>\n",
       "      <td>4.29780</td>\n",
       "      <td>-1.71060</td>\n",
       "      <td>-3.51410</td>\n",
       "      <td>-2.06170</td>\n",
       "      <td>2.905400</td>\n",
       "      <td>-3.08590</td>\n",
       "      <td>0.24649</td>\n",
       "      <td>-3.55320</td>\n",
       "      <td>-6.03000</td>\n",
       "      <td>-1.232300</td>\n",
       "      <td>1.48810</td>\n",
       "      <td>6.99350</td>\n",
       "      <td>-1.177600</td>\n",
       "      <td>0.24186</td>\n",
       "      <td>3.12120</td>\n",
       "      <td>3.61290</td>\n",
       "      <td>-2.12400</td>\n",
       "      <td>-4.258800</td>\n",
       "      <td>-4.43620</td>\n",
       "      <td>0.28104</td>\n",
       "      <td>0.56529</td>\n",
       "      <td>3.60660</td>\n",
       "      <td>7.74220</td>\n",
       "      <td>6.49820</td>\n",
       "      <td>2.31770</td>\n",
       "      <td>1.393400</td>\n",
       "      <td>-7.0152</td>\n",
       "      <td>-0.26532</td>\n",
       "      <td>2.96030</td>\n",
       "      <td>-3.0547</td>\n",
       "      <td>-1.392500</td>\n",
       "      <td>-6.36720</td>\n",
       "      <td>-0.10276</td>\n",
       "      <td>-4.742700</td>\n",
       "      <td>0.23440</td>\n",
       "      <td>3.07760</td>\n",
       "      <td>2.63210</td>\n",
       "      <td>-6.00090</td>\n",
       "      <td>-0.035202</td>\n",
       "      <td>0.12049</td>\n",
       "      <td>3.32280</td>\n",
       "      <td>-2.53680</td>\n",
       "      <td>4.885500</td>\n",
       "      <td>-1.19500</td>\n",
       "      <td>4.03170</td>\n",
       "      <td>2.91550</td>\n",
       "      <td>-2.4755</td>\n",
       "      <td>0.94430</td>\n",
       "      <td>-2.74750</td>\n",
       "      <td>0.10769</td>\n",
       "      <td>7.21170</td>\n",
       "      <td>4.77290</td>\n",
       "      <td>-1.17920</td>\n",
       "      <td>5.26350</td>\n",
       "      <td>1.46960</td>\n",
       "      <td>-3.13040</td>\n",
       "      <td>-4.69320</td>\n",
       "      <td>2.81080</td>\n",
       "      <td>-2.16570</td>\n",
       "      <td>-7.2465</td>\n",
       "      <td>-0.4450</td>\n",
       "      <td>-1.33080</td>\n",
       "      <td>0.74278</td>\n",
       "      <td>-0.82304</td>\n",
       "      <td>-2.24190</td>\n",
       "      <td>4.98540</td>\n",
       "      <td>9.51510</td>\n",
       "      <td>-0.96686</td>\n",
       "      <td>-3.95520</td>\n",
       "      <td>-3.31550</td>\n",
       "      <td>-0.251370</td>\n",
       "      <td>7.14600</td>\n",
       "      <td>6.76020</td>\n",
       "      <td>3.751200</td>\n",
       "      <td>3.24980</td>\n",
       "      <td>3.52460</td>\n",
       "      <td>-1.91650</td>\n",
       "      <td>-3.3861</td>\n",
       "      <td>-1.981000</td>\n",
       "      <td>-1.44270</td>\n",
       "      <td>-1.31170</td>\n",
       "      <td>0.33794</td>\n",
       "      <td>0.846070</td>\n",
       "      <td>-0.96828</td>\n",
       "      <td>-1.879400</td>\n",
       "      <td>3.66160</td>\n",
       "      <td>-7.6509</td>\n",
       "      <td>-0.47105</td>\n",
       "      <td>0.36527</td>\n",
       "      <td>0.97179</td>\n",
       "      <td>0.539580</td>\n",
       "      <td>0.42964</td>\n",
       "      <td>-1.24240</td>\n",
       "      <td>-4.2396</td>\n",
       "      <td>3.22420</td>\n",
       "      <td>0.67627</td>\n",
       "      <td>-0.17765</td>\n",
       "      <td>-2.991900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>university</th>\n",
       "      <td>-1.068600</td>\n",
       "      <td>-10.11400</td>\n",
       "      <td>4.03640</td>\n",
       "      <td>-3.13620</td>\n",
       "      <td>6.66330</td>\n",
       "      <td>-1.798900</td>\n",
       "      <td>3.68110</td>\n",
       "      <td>7.327800</td>\n",
       "      <td>-0.94667</td>\n",
       "      <td>-2.11760</td>\n",
       "      <td>3.7071</td>\n",
       "      <td>2.96010</td>\n",
       "      <td>3.89420</td>\n",
       "      <td>-6.757900</td>\n",
       "      <td>-4.48670</td>\n",
       "      <td>2.691700</td>\n",
       "      <td>-4.460400</td>\n",
       "      <td>5.510500</td>\n",
       "      <td>-4.175700</td>\n",
       "      <td>4.4499</td>\n",
       "      <td>-1.04270</td>\n",
       "      <td>-7.46150</td>\n",
       "      <td>-6.4483</td>\n",
       "      <td>-3.93410</td>\n",
       "      <td>-10.33600</td>\n",
       "      <td>3.84610</td>\n",
       "      <td>2.51430</td>\n",
       "      <td>4.78470</td>\n",
       "      <td>-4.129000</td>\n",
       "      <td>6.99120</td>\n",
       "      <td>3.12810</td>\n",
       "      <td>0.614680</td>\n",
       "      <td>7.07690</td>\n",
       "      <td>-2.96670</td>\n",
       "      <td>-2.34340</td>\n",
       "      <td>-9.32910</td>\n",
       "      <td>-1.687600</td>\n",
       "      <td>-1.877200</td>\n",
       "      <td>0.84683</td>\n",
       "      <td>-5.67300</td>\n",
       "      <td>-12.981000</td>\n",
       "      <td>-0.92561</td>\n",
       "      <td>-5.91940</td>\n",
       "      <td>-3.14500</td>\n",
       "      <td>-2.23150</td>\n",
       "      <td>8.87240</td>\n",
       "      <td>6.78720</td>\n",
       "      <td>0.14341</td>\n",
       "      <td>2.92010</td>\n",
       "      <td>4.38660</td>\n",
       "      <td>-3.426200</td>\n",
       "      <td>-5.55780</td>\n",
       "      <td>4.288900</td>\n",
       "      <td>-0.24222</td>\n",
       "      <td>2.9603</td>\n",
       "      <td>-1.88000</td>\n",
       "      <td>-1.71170</td>\n",
       "      <td>-2.73970</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>-4.745400</td>\n",
       "      <td>-7.3338</td>\n",
       "      <td>-1.04920</td>\n",
       "      <td>-7.6544</td>\n",
       "      <td>-11.14300</td>\n",
       "      <td>0.12249</td>\n",
       "      <td>2.8896</td>\n",
       "      <td>2.46180</td>\n",
       "      <td>5.1039</td>\n",
       "      <td>-6.56890</td>\n",
       "      <td>-4.7415</td>\n",
       "      <td>1.11470</td>\n",
       "      <td>-3.74690</td>\n",
       "      <td>2.34610</td>\n",
       "      <td>7.248700</td>\n",
       "      <td>3.33770</td>\n",
       "      <td>7.89670</td>\n",
       "      <td>-0.81971</td>\n",
       "      <td>-5.22830</td>\n",
       "      <td>-1.16860</td>\n",
       "      <td>-0.22470</td>\n",
       "      <td>3.76020</td>\n",
       "      <td>-1.65840</td>\n",
       "      <td>4.54910</td>\n",
       "      <td>1.30720</td>\n",
       "      <td>3.787100</td>\n",
       "      <td>1.252800</td>\n",
       "      <td>-4.13410</td>\n",
       "      <td>3.5882</td>\n",
       "      <td>-4.40810</td>\n",
       "      <td>10.561000</td>\n",
       "      <td>-9.90360</td>\n",
       "      <td>-0.17611</td>\n",
       "      <td>-6.95630</td>\n",
       "      <td>12.21300</td>\n",
       "      <td>-2.07930</td>\n",
       "      <td>10.17100</td>\n",
       "      <td>-0.209550</td>\n",
       "      <td>-7.49150</td>\n",
       "      <td>8.270100</td>\n",
       "      <td>3.48150</td>\n",
       "      <td>9.87260</td>\n",
       "      <td>-5.419800</td>\n",
       "      <td>5.96950</td>\n",
       "      <td>9.9306</td>\n",
       "      <td>10.21500</td>\n",
       "      <td>3.43180</td>\n",
       "      <td>-0.20011</td>\n",
       "      <td>3.76160</td>\n",
       "      <td>-1.01920</td>\n",
       "      <td>-5.30060</td>\n",
       "      <td>-5.32780</td>\n",
       "      <td>-0.96439</td>\n",
       "      <td>0.70093</td>\n",
       "      <td>-2.62770</td>\n",
       "      <td>-10.60600</td>\n",
       "      <td>12.25000</td>\n",
       "      <td>-4.56330</td>\n",
       "      <td>-3.30350</td>\n",
       "      <td>-0.074273</td>\n",
       "      <td>1.79680</td>\n",
       "      <td>6.02050</td>\n",
       "      <td>-5.56530</td>\n",
       "      <td>4.50280</td>\n",
       "      <td>-4.05520</td>\n",
       "      <td>-7.7767</td>\n",
       "      <td>-12.24100</td>\n",
       "      <td>-4.70380</td>\n",
       "      <td>-4.23770</td>\n",
       "      <td>-8.99950</td>\n",
       "      <td>4.39090</td>\n",
       "      <td>4.2466</td>\n",
       "      <td>-4.41830</td>\n",
       "      <td>9.48320</td>\n",
       "      <td>-0.55428</td>\n",
       "      <td>-14.00000</td>\n",
       "      <td>4.89870</td>\n",
       "      <td>0.292040</td>\n",
       "      <td>1.583300</td>\n",
       "      <td>-8.6796</td>\n",
       "      <td>1.77160</td>\n",
       "      <td>5.95060</td>\n",
       "      <td>5.11210</td>\n",
       "      <td>0.83254</td>\n",
       "      <td>3.17340</td>\n",
       "      <td>-0.81617</td>\n",
       "      <td>-7.215200</td>\n",
       "      <td>-4.75200</td>\n",
       "      <td>-2.376700</td>\n",
       "      <td>3.69630</td>\n",
       "      <td>-1.01110</td>\n",
       "      <td>-1.18700</td>\n",
       "      <td>0.39079</td>\n",
       "      <td>-11.364000</td>\n",
       "      <td>0.44649</td>\n",
       "      <td>9.56470</td>\n",
       "      <td>7.098000</td>\n",
       "      <td>1.5688</td>\n",
       "      <td>-2.253900</td>\n",
       "      <td>7.33040</td>\n",
       "      <td>-5.75790</td>\n",
       "      <td>2.47420</td>\n",
       "      <td>8.93480</td>\n",
       "      <td>3.93900</td>\n",
       "      <td>10.37700</td>\n",
       "      <td>-7.73290</td>\n",
       "      <td>7.63050</td>\n",
       "      <td>-2.52470</td>\n",
       "      <td>-2.68520</td>\n",
       "      <td>-3.93670</td>\n",
       "      <td>2.8864</td>\n",
       "      <td>-10.93700</td>\n",
       "      <td>-5.13140</td>\n",
       "      <td>6.06970</td>\n",
       "      <td>-0.217600</td>\n",
       "      <td>6.16230</td>\n",
       "      <td>12.69900</td>\n",
       "      <td>0.69175</td>\n",
       "      <td>6.98680</td>\n",
       "      <td>-6.88360</td>\n",
       "      <td>-2.50140</td>\n",
       "      <td>-4.01530</td>\n",
       "      <td>0.59352</td>\n",
       "      <td>-4.653300</td>\n",
       "      <td>-1.912300</td>\n",
       "      <td>6.85350</td>\n",
       "      <td>3.342700</td>\n",
       "      <td>-0.54042</td>\n",
       "      <td>-1.732900</td>\n",
       "      <td>-1.89180</td>\n",
       "      <td>-6.7632</td>\n",
       "      <td>3.49320</td>\n",
       "      <td>2.39900</td>\n",
       "      <td>-0.591660</td>\n",
       "      <td>-4.17540</td>\n",
       "      <td>-3.53590</td>\n",
       "      <td>5.579200</td>\n",
       "      <td>-3.76200</td>\n",
       "      <td>-7.006300</td>\n",
       "      <td>-8.743500</td>\n",
       "      <td>-0.56694</td>\n",
       "      <td>5.89390</td>\n",
       "      <td>-6.70050</td>\n",
       "      <td>3.39130</td>\n",
       "      <td>-2.17210</td>\n",
       "      <td>6.24640</td>\n",
       "      <td>-1.04130</td>\n",
       "      <td>-6.061900</td>\n",
       "      <td>3.77820</td>\n",
       "      <td>2.46180</td>\n",
       "      <td>0.69879</td>\n",
       "      <td>-3.42900</td>\n",
       "      <td>6.555000</td>\n",
       "      <td>1.16150</td>\n",
       "      <td>-3.84820</td>\n",
       "      <td>-8.639900</td>\n",
       "      <td>6.75660</td>\n",
       "      <td>3.84780</td>\n",
       "      <td>-10.10000</td>\n",
       "      <td>-5.54070</td>\n",
       "      <td>4.452200</td>\n",
       "      <td>-6.06380</td>\n",
       "      <td>-2.28500</td>\n",
       "      <td>0.86318</td>\n",
       "      <td>-0.99399</td>\n",
       "      <td>-3.92160</td>\n",
       "      <td>1.73300</td>\n",
       "      <td>-0.92894</td>\n",
       "      <td>-8.097500</td>\n",
       "      <td>4.3275</td>\n",
       "      <td>2.63300</td>\n",
       "      <td>-7.45580</td>\n",
       "      <td>-3.7734</td>\n",
       "      <td>0.470520</td>\n",
       "      <td>-1.30890</td>\n",
       "      <td>7.80510</td>\n",
       "      <td>3.152300</td>\n",
       "      <td>-3.88340</td>\n",
       "      <td>10.38400</td>\n",
       "      <td>-6.41090</td>\n",
       "      <td>10.06900</td>\n",
       "      <td>-7.518700</td>\n",
       "      <td>-0.93429</td>\n",
       "      <td>-7.32330</td>\n",
       "      <td>1.37650</td>\n",
       "      <td>12.077000</td>\n",
       "      <td>-2.60510</td>\n",
       "      <td>4.08290</td>\n",
       "      <td>7.64380</td>\n",
       "      <td>1.5573</td>\n",
       "      <td>-1.38580</td>\n",
       "      <td>3.00970</td>\n",
       "      <td>2.88590</td>\n",
       "      <td>-6.33230</td>\n",
       "      <td>1.85610</td>\n",
       "      <td>-4.39880</td>\n",
       "      <td>-4.46170</td>\n",
       "      <td>0.73151</td>\n",
       "      <td>-2.63660</td>\n",
       "      <td>9.65110</td>\n",
       "      <td>-1.93300</td>\n",
       "      <td>-5.81710</td>\n",
       "      <td>1.7027</td>\n",
       "      <td>-5.7822</td>\n",
       "      <td>-5.78010</td>\n",
       "      <td>0.99957</td>\n",
       "      <td>-0.93970</td>\n",
       "      <td>-6.58670</td>\n",
       "      <td>4.77580</td>\n",
       "      <td>1.03520</td>\n",
       "      <td>-9.00900</td>\n",
       "      <td>-0.57722</td>\n",
       "      <td>-1.68390</td>\n",
       "      <td>-1.886500</td>\n",
       "      <td>1.09890</td>\n",
       "      <td>-14.13500</td>\n",
       "      <td>-5.768600</td>\n",
       "      <td>2.61770</td>\n",
       "      <td>-9.45430</td>\n",
       "      <td>-0.27378</td>\n",
       "      <td>2.7515</td>\n",
       "      <td>5.076000</td>\n",
       "      <td>3.32590</td>\n",
       "      <td>6.23440</td>\n",
       "      <td>2.19080</td>\n",
       "      <td>-3.097600</td>\n",
       "      <td>-12.63200</td>\n",
       "      <td>8.246700</td>\n",
       "      <td>-0.63342</td>\n",
       "      <td>-14.1170</td>\n",
       "      <td>-9.10750</td>\n",
       "      <td>-1.00250</td>\n",
       "      <td>0.41538</td>\n",
       "      <td>0.093109</td>\n",
       "      <td>-1.35630</td>\n",
       "      <td>-5.99590</td>\n",
       "      <td>2.3063</td>\n",
       "      <td>-3.14430</td>\n",
       "      <td>6.11140</td>\n",
       "      <td>-5.91240</td>\n",
       "      <td>10.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wasteful</th>\n",
       "      <td>-5.898500</td>\n",
       "      <td>-2.82470</td>\n",
       "      <td>0.85307</td>\n",
       "      <td>-1.26600</td>\n",
       "      <td>0.80816</td>\n",
       "      <td>0.217950</td>\n",
       "      <td>5.35130</td>\n",
       "      <td>1.112400</td>\n",
       "      <td>-3.11060</td>\n",
       "      <td>-0.13387</td>\n",
       "      <td>-4.2348</td>\n",
       "      <td>-2.81970</td>\n",
       "      <td>1.05510</td>\n",
       "      <td>-4.293300</td>\n",
       "      <td>-3.84430</td>\n",
       "      <td>-1.019800</td>\n",
       "      <td>-3.657400</td>\n",
       "      <td>0.611180</td>\n",
       "      <td>-1.142200</td>\n",
       "      <td>3.7208</td>\n",
       "      <td>0.53791</td>\n",
       "      <td>-0.23637</td>\n",
       "      <td>5.7244</td>\n",
       "      <td>0.36354</td>\n",
       "      <td>2.95040</td>\n",
       "      <td>2.40210</td>\n",
       "      <td>-0.95108</td>\n",
       "      <td>1.97110</td>\n",
       "      <td>3.564500</td>\n",
       "      <td>-0.24429</td>\n",
       "      <td>-2.21570</td>\n",
       "      <td>3.356400</td>\n",
       "      <td>1.30990</td>\n",
       "      <td>6.35790</td>\n",
       "      <td>-5.97120</td>\n",
       "      <td>-5.17460</td>\n",
       "      <td>0.099442</td>\n",
       "      <td>-2.119100</td>\n",
       "      <td>0.38604</td>\n",
       "      <td>-1.42960</td>\n",
       "      <td>-0.711400</td>\n",
       "      <td>2.46850</td>\n",
       "      <td>5.97340</td>\n",
       "      <td>1.15390</td>\n",
       "      <td>1.39120</td>\n",
       "      <td>-1.00750</td>\n",
       "      <td>-4.77150</td>\n",
       "      <td>1.52450</td>\n",
       "      <td>0.35708</td>\n",
       "      <td>3.62370</td>\n",
       "      <td>-0.152060</td>\n",
       "      <td>-2.22140</td>\n",
       "      <td>0.550530</td>\n",
       "      <td>4.08640</td>\n",
       "      <td>1.8258</td>\n",
       "      <td>-5.79210</td>\n",
       "      <td>1.33070</td>\n",
       "      <td>-1.24280</td>\n",
       "      <td>-4.41500</td>\n",
       "      <td>-2.199900</td>\n",
       "      <td>2.9477</td>\n",
       "      <td>2.73850</td>\n",
       "      <td>3.7307</td>\n",
       "      <td>-0.32139</td>\n",
       "      <td>2.04040</td>\n",
       "      <td>1.9807</td>\n",
       "      <td>0.18090</td>\n",
       "      <td>1.1595</td>\n",
       "      <td>-2.38990</td>\n",
       "      <td>-3.2002</td>\n",
       "      <td>2.90930</td>\n",
       "      <td>-3.01970</td>\n",
       "      <td>-0.32339</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>3.46460</td>\n",
       "      <td>0.45295</td>\n",
       "      <td>1.78530</td>\n",
       "      <td>-2.56340</td>\n",
       "      <td>-1.50400</td>\n",
       "      <td>-4.26990</td>\n",
       "      <td>-0.35531</td>\n",
       "      <td>-0.33360</td>\n",
       "      <td>-1.02870</td>\n",
       "      <td>4.97770</td>\n",
       "      <td>-0.981450</td>\n",
       "      <td>-1.983500</td>\n",
       "      <td>-1.99230</td>\n",
       "      <td>-1.2690</td>\n",
       "      <td>0.21810</td>\n",
       "      <td>-0.945760</td>\n",
       "      <td>-3.61430</td>\n",
       "      <td>-2.41690</td>\n",
       "      <td>-1.14280</td>\n",
       "      <td>0.90399</td>\n",
       "      <td>2.88950</td>\n",
       "      <td>3.15230</td>\n",
       "      <td>-2.135800</td>\n",
       "      <td>1.17070</td>\n",
       "      <td>5.211300</td>\n",
       "      <td>1.02070</td>\n",
       "      <td>2.31400</td>\n",
       "      <td>-2.728000</td>\n",
       "      <td>-1.57210</td>\n",
       "      <td>-1.4642</td>\n",
       "      <td>2.80760</td>\n",
       "      <td>-5.52380</td>\n",
       "      <td>3.75670</td>\n",
       "      <td>-1.01060</td>\n",
       "      <td>3.31980</td>\n",
       "      <td>-0.90565</td>\n",
       "      <td>-3.27050</td>\n",
       "      <td>1.77210</td>\n",
       "      <td>3.12100</td>\n",
       "      <td>0.79535</td>\n",
       "      <td>-2.54770</td>\n",
       "      <td>-5.78040</td>\n",
       "      <td>-0.66670</td>\n",
       "      <td>1.20070</td>\n",
       "      <td>-4.064200</td>\n",
       "      <td>2.23100</td>\n",
       "      <td>-4.14660</td>\n",
       "      <td>-1.45330</td>\n",
       "      <td>1.05910</td>\n",
       "      <td>0.18255</td>\n",
       "      <td>-1.5340</td>\n",
       "      <td>0.48083</td>\n",
       "      <td>0.93602</td>\n",
       "      <td>2.37270</td>\n",
       "      <td>3.23040</td>\n",
       "      <td>-1.36840</td>\n",
       "      <td>-0.6788</td>\n",
       "      <td>0.97002</td>\n",
       "      <td>-0.18370</td>\n",
       "      <td>0.68279</td>\n",
       "      <td>-0.13605</td>\n",
       "      <td>-1.88550</td>\n",
       "      <td>2.468200</td>\n",
       "      <td>-0.010213</td>\n",
       "      <td>2.5421</td>\n",
       "      <td>1.39040</td>\n",
       "      <td>-3.47800</td>\n",
       "      <td>-0.30130</td>\n",
       "      <td>-0.50026</td>\n",
       "      <td>-2.01260</td>\n",
       "      <td>2.67220</td>\n",
       "      <td>-2.829400</td>\n",
       "      <td>-0.76953</td>\n",
       "      <td>0.840990</td>\n",
       "      <td>-4.90710</td>\n",
       "      <td>-3.02280</td>\n",
       "      <td>4.37140</td>\n",
       "      <td>-1.09750</td>\n",
       "      <td>-7.085900</td>\n",
       "      <td>1.63890</td>\n",
       "      <td>-0.96322</td>\n",
       "      <td>-1.326800</td>\n",
       "      <td>-3.6022</td>\n",
       "      <td>0.608130</td>\n",
       "      <td>-0.22319</td>\n",
       "      <td>2.39830</td>\n",
       "      <td>-1.97400</td>\n",
       "      <td>-1.61550</td>\n",
       "      <td>-2.34880</td>\n",
       "      <td>-3.12220</td>\n",
       "      <td>-1.20300</td>\n",
       "      <td>1.61480</td>\n",
       "      <td>-1.86640</td>\n",
       "      <td>-1.29030</td>\n",
       "      <td>-4.41030</td>\n",
       "      <td>-5.3345</td>\n",
       "      <td>1.12620</td>\n",
       "      <td>-2.73770</td>\n",
       "      <td>-3.77910</td>\n",
       "      <td>1.977100</td>\n",
       "      <td>-0.23047</td>\n",
       "      <td>0.82517</td>\n",
       "      <td>0.10275</td>\n",
       "      <td>-0.58393</td>\n",
       "      <td>-0.30369</td>\n",
       "      <td>-0.39137</td>\n",
       "      <td>-1.68450</td>\n",
       "      <td>-2.28840</td>\n",
       "      <td>-2.109200</td>\n",
       "      <td>0.060564</td>\n",
       "      <td>3.07070</td>\n",
       "      <td>-0.128720</td>\n",
       "      <td>5.69100</td>\n",
       "      <td>0.749880</td>\n",
       "      <td>4.24340</td>\n",
       "      <td>1.4342</td>\n",
       "      <td>0.25702</td>\n",
       "      <td>4.37910</td>\n",
       "      <td>4.458300</td>\n",
       "      <td>4.80330</td>\n",
       "      <td>2.09530</td>\n",
       "      <td>-2.330100</td>\n",
       "      <td>4.88700</td>\n",
       "      <td>-0.024999</td>\n",
       "      <td>4.268500</td>\n",
       "      <td>0.65543</td>\n",
       "      <td>2.44770</td>\n",
       "      <td>1.08920</td>\n",
       "      <td>0.14664</td>\n",
       "      <td>-4.61360</td>\n",
       "      <td>0.56488</td>\n",
       "      <td>4.03910</td>\n",
       "      <td>1.034500</td>\n",
       "      <td>-3.25500</td>\n",
       "      <td>2.82740</td>\n",
       "      <td>-3.75810</td>\n",
       "      <td>-1.42250</td>\n",
       "      <td>0.791350</td>\n",
       "      <td>-1.07010</td>\n",
       "      <td>2.13090</td>\n",
       "      <td>-2.069600</td>\n",
       "      <td>-2.34830</td>\n",
       "      <td>0.33561</td>\n",
       "      <td>2.74800</td>\n",
       "      <td>3.54050</td>\n",
       "      <td>-0.421300</td>\n",
       "      <td>-4.19460</td>\n",
       "      <td>0.60109</td>\n",
       "      <td>0.90805</td>\n",
       "      <td>-0.58592</td>\n",
       "      <td>1.81030</td>\n",
       "      <td>3.47700</td>\n",
       "      <td>2.42890</td>\n",
       "      <td>-1.888000</td>\n",
       "      <td>-1.4580</td>\n",
       "      <td>-0.94369</td>\n",
       "      <td>-0.44531</td>\n",
       "      <td>-1.1296</td>\n",
       "      <td>-3.829700</td>\n",
       "      <td>-3.61310</td>\n",
       "      <td>1.15840</td>\n",
       "      <td>-4.380100</td>\n",
       "      <td>-3.03080</td>\n",
       "      <td>1.47220</td>\n",
       "      <td>5.73580</td>\n",
       "      <td>-1.94060</td>\n",
       "      <td>2.842700</td>\n",
       "      <td>-1.19690</td>\n",
       "      <td>4.29830</td>\n",
       "      <td>1.02980</td>\n",
       "      <td>4.770900</td>\n",
       "      <td>-1.95050</td>\n",
       "      <td>5.40530</td>\n",
       "      <td>-5.34150</td>\n",
       "      <td>-6.2761</td>\n",
       "      <td>3.03760</td>\n",
       "      <td>1.78590</td>\n",
       "      <td>2.04100</td>\n",
       "      <td>3.17640</td>\n",
       "      <td>2.22880</td>\n",
       "      <td>0.03576</td>\n",
       "      <td>4.11180</td>\n",
       "      <td>5.24720</td>\n",
       "      <td>-2.28430</td>\n",
       "      <td>1.41040</td>\n",
       "      <td>1.78310</td>\n",
       "      <td>0.30675</td>\n",
       "      <td>-4.1661</td>\n",
       "      <td>3.5212</td>\n",
       "      <td>-2.73180</td>\n",
       "      <td>-5.18410</td>\n",
       "      <td>1.46250</td>\n",
       "      <td>-0.94632</td>\n",
       "      <td>4.03570</td>\n",
       "      <td>0.63492</td>\n",
       "      <td>-0.59014</td>\n",
       "      <td>1.07350</td>\n",
       "      <td>-2.68880</td>\n",
       "      <td>-1.346300</td>\n",
       "      <td>2.78750</td>\n",
       "      <td>2.46090</td>\n",
       "      <td>0.250130</td>\n",
       "      <td>1.58420</td>\n",
       "      <td>-3.46610</td>\n",
       "      <td>1.61160</td>\n",
       "      <td>-3.5738</td>\n",
       "      <td>-2.515900</td>\n",
       "      <td>-2.46640</td>\n",
       "      <td>-3.03200</td>\n",
       "      <td>-1.81210</td>\n",
       "      <td>4.040300</td>\n",
       "      <td>-0.91036</td>\n",
       "      <td>-0.295610</td>\n",
       "      <td>0.46698</td>\n",
       "      <td>-5.7423</td>\n",
       "      <td>-3.85580</td>\n",
       "      <td>-1.89300</td>\n",
       "      <td>-0.19739</td>\n",
       "      <td>-2.204700</td>\n",
       "      <td>1.87600</td>\n",
       "      <td>-3.85170</td>\n",
       "      <td>-2.8258</td>\n",
       "      <td>-1.64500</td>\n",
       "      <td>-0.22011</td>\n",
       "      <td>3.19510</td>\n",
       "      <td>0.082503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>2.527700</td>\n",
       "      <td>2.45850</td>\n",
       "      <td>1.40970</td>\n",
       "      <td>1.26680</td>\n",
       "      <td>3.48150</td>\n",
       "      <td>3.013100</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>3.319400</td>\n",
       "      <td>-4.64910</td>\n",
       "      <td>-0.90818</td>\n",
       "      <td>4.6572</td>\n",
       "      <td>1.81340</td>\n",
       "      <td>-5.20930</td>\n",
       "      <td>-3.046800</td>\n",
       "      <td>0.95889</td>\n",
       "      <td>1.127800</td>\n",
       "      <td>3.766300</td>\n",
       "      <td>-1.172400</td>\n",
       "      <td>-5.236800</td>\n",
       "      <td>-2.7310</td>\n",
       "      <td>0.83627</td>\n",
       "      <td>-0.15671</td>\n",
       "      <td>-3.5574</td>\n",
       "      <td>0.66522</td>\n",
       "      <td>0.76249</td>\n",
       "      <td>-3.11670</td>\n",
       "      <td>-2.33900</td>\n",
       "      <td>-1.10070</td>\n",
       "      <td>-1.936100</td>\n",
       "      <td>-0.37116</td>\n",
       "      <td>2.21150</td>\n",
       "      <td>-0.252560</td>\n",
       "      <td>0.89407</td>\n",
       "      <td>0.42813</td>\n",
       "      <td>5.54970</td>\n",
       "      <td>-4.84510</td>\n",
       "      <td>0.126360</td>\n",
       "      <td>-1.451500</td>\n",
       "      <td>2.44780</td>\n",
       "      <td>2.05710</td>\n",
       "      <td>0.016965</td>\n",
       "      <td>1.09170</td>\n",
       "      <td>0.92943</td>\n",
       "      <td>0.24111</td>\n",
       "      <td>-0.56336</td>\n",
       "      <td>-0.75646</td>\n",
       "      <td>3.87410</td>\n",
       "      <td>-3.15820</td>\n",
       "      <td>1.44900</td>\n",
       "      <td>1.93720</td>\n",
       "      <td>3.320900</td>\n",
       "      <td>2.73640</td>\n",
       "      <td>1.727400</td>\n",
       "      <td>-1.79250</td>\n",
       "      <td>-5.7121</td>\n",
       "      <td>4.06750</td>\n",
       "      <td>-4.08520</td>\n",
       "      <td>3.74580</td>\n",
       "      <td>-0.57559</td>\n",
       "      <td>0.066014</td>\n",
       "      <td>4.5403</td>\n",
       "      <td>1.54670</td>\n",
       "      <td>-1.4521</td>\n",
       "      <td>0.21168</td>\n",
       "      <td>0.56963</td>\n",
       "      <td>4.9667</td>\n",
       "      <td>-1.95350</td>\n",
       "      <td>-4.6255</td>\n",
       "      <td>0.22140</td>\n",
       "      <td>7.8679</td>\n",
       "      <td>0.77221</td>\n",
       "      <td>1.31010</td>\n",
       "      <td>-1.85010</td>\n",
       "      <td>-3.092100</td>\n",
       "      <td>-4.36200</td>\n",
       "      <td>0.72363</td>\n",
       "      <td>-3.80210</td>\n",
       "      <td>3.28420</td>\n",
       "      <td>-3.69840</td>\n",
       "      <td>-0.28394</td>\n",
       "      <td>-3.33220</td>\n",
       "      <td>-2.36460</td>\n",
       "      <td>1.42960</td>\n",
       "      <td>5.31630</td>\n",
       "      <td>-0.601130</td>\n",
       "      <td>-0.026209</td>\n",
       "      <td>-5.24600</td>\n",
       "      <td>-3.9416</td>\n",
       "      <td>2.49890</td>\n",
       "      <td>2.942600</td>\n",
       "      <td>0.26338</td>\n",
       "      <td>4.33080</td>\n",
       "      <td>2.39310</td>\n",
       "      <td>-0.14004</td>\n",
       "      <td>1.33220</td>\n",
       "      <td>-0.42698</td>\n",
       "      <td>-1.429400</td>\n",
       "      <td>2.60150</td>\n",
       "      <td>0.008421</td>\n",
       "      <td>2.03760</td>\n",
       "      <td>4.63190</td>\n",
       "      <td>3.889700</td>\n",
       "      <td>2.15130</td>\n",
       "      <td>-1.3453</td>\n",
       "      <td>1.33320</td>\n",
       "      <td>7.54030</td>\n",
       "      <td>-1.01340</td>\n",
       "      <td>-2.80980</td>\n",
       "      <td>-1.22040</td>\n",
       "      <td>-3.44800</td>\n",
       "      <td>1.83850</td>\n",
       "      <td>0.89519</td>\n",
       "      <td>0.94821</td>\n",
       "      <td>-0.40312</td>\n",
       "      <td>1.30260</td>\n",
       "      <td>4.18140</td>\n",
       "      <td>-5.30060</td>\n",
       "      <td>-0.11834</td>\n",
       "      <td>-0.303420</td>\n",
       "      <td>-0.92647</td>\n",
       "      <td>-2.85580</td>\n",
       "      <td>-3.95380</td>\n",
       "      <td>2.41610</td>\n",
       "      <td>-2.14900</td>\n",
       "      <td>1.4545</td>\n",
       "      <td>-3.81470</td>\n",
       "      <td>2.82180</td>\n",
       "      <td>-0.66691</td>\n",
       "      <td>3.74510</td>\n",
       "      <td>0.33645</td>\n",
       "      <td>-4.4970</td>\n",
       "      <td>0.59448</td>\n",
       "      <td>3.15120</td>\n",
       "      <td>1.72930</td>\n",
       "      <td>1.84960</td>\n",
       "      <td>1.34200</td>\n",
       "      <td>-4.102000</td>\n",
       "      <td>-0.181750</td>\n",
       "      <td>6.2029</td>\n",
       "      <td>-1.10230</td>\n",
       "      <td>-0.19552</td>\n",
       "      <td>0.49945</td>\n",
       "      <td>0.34234</td>\n",
       "      <td>3.47850</td>\n",
       "      <td>-0.23550</td>\n",
       "      <td>-1.715900</td>\n",
       "      <td>-0.41219</td>\n",
       "      <td>-1.004700</td>\n",
       "      <td>0.10796</td>\n",
       "      <td>4.85150</td>\n",
       "      <td>2.79720</td>\n",
       "      <td>4.15440</td>\n",
       "      <td>-0.037735</td>\n",
       "      <td>3.25380</td>\n",
       "      <td>-1.48770</td>\n",
       "      <td>0.781630</td>\n",
       "      <td>2.4206</td>\n",
       "      <td>-2.012000</td>\n",
       "      <td>0.54807</td>\n",
       "      <td>-4.03130</td>\n",
       "      <td>0.76244</td>\n",
       "      <td>0.67017</td>\n",
       "      <td>-0.13130</td>\n",
       "      <td>-0.29379</td>\n",
       "      <td>-2.81050</td>\n",
       "      <td>-2.42140</td>\n",
       "      <td>-6.66470</td>\n",
       "      <td>1.04750</td>\n",
       "      <td>-3.35110</td>\n",
       "      <td>-4.2410</td>\n",
       "      <td>-3.19340</td>\n",
       "      <td>-3.24740</td>\n",
       "      <td>-1.84820</td>\n",
       "      <td>2.741600</td>\n",
       "      <td>3.87340</td>\n",
       "      <td>4.80000</td>\n",
       "      <td>0.34359</td>\n",
       "      <td>2.41030</td>\n",
       "      <td>-4.16780</td>\n",
       "      <td>-1.43790</td>\n",
       "      <td>1.96250</td>\n",
       "      <td>0.14628</td>\n",
       "      <td>2.027600</td>\n",
       "      <td>-0.354440</td>\n",
       "      <td>-0.40565</td>\n",
       "      <td>0.755320</td>\n",
       "      <td>-3.48000</td>\n",
       "      <td>-3.030400</td>\n",
       "      <td>0.60583</td>\n",
       "      <td>3.8898</td>\n",
       "      <td>-7.64840</td>\n",
       "      <td>0.31409</td>\n",
       "      <td>0.366850</td>\n",
       "      <td>0.80175</td>\n",
       "      <td>1.39070</td>\n",
       "      <td>0.188560</td>\n",
       "      <td>-2.45570</td>\n",
       "      <td>0.703980</td>\n",
       "      <td>-1.527700</td>\n",
       "      <td>1.94780</td>\n",
       "      <td>-2.60190</td>\n",
       "      <td>1.90900</td>\n",
       "      <td>-0.62335</td>\n",
       "      <td>-0.75263</td>\n",
       "      <td>7.41110</td>\n",
       "      <td>0.23533</td>\n",
       "      <td>-0.019343</td>\n",
       "      <td>2.04250</td>\n",
       "      <td>0.04966</td>\n",
       "      <td>1.06800</td>\n",
       "      <td>1.26660</td>\n",
       "      <td>-1.186400</td>\n",
       "      <td>1.45170</td>\n",
       "      <td>0.77143</td>\n",
       "      <td>-1.938700</td>\n",
       "      <td>4.85780</td>\n",
       "      <td>5.80520</td>\n",
       "      <td>1.10390</td>\n",
       "      <td>0.29307</td>\n",
       "      <td>3.011000</td>\n",
       "      <td>-0.70216</td>\n",
       "      <td>2.46750</td>\n",
       "      <td>-0.78348</td>\n",
       "      <td>-2.15990</td>\n",
       "      <td>2.64930</td>\n",
       "      <td>3.28510</td>\n",
       "      <td>-0.21426</td>\n",
       "      <td>2.187200</td>\n",
       "      <td>4.9649</td>\n",
       "      <td>2.02410</td>\n",
       "      <td>0.45664</td>\n",
       "      <td>-4.0420</td>\n",
       "      <td>2.593400</td>\n",
       "      <td>-4.95410</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>0.946780</td>\n",
       "      <td>3.00870</td>\n",
       "      <td>0.31703</td>\n",
       "      <td>4.04670</td>\n",
       "      <td>0.68744</td>\n",
       "      <td>-4.032500</td>\n",
       "      <td>-0.28389</td>\n",
       "      <td>3.13890</td>\n",
       "      <td>1.90230</td>\n",
       "      <td>0.095292</td>\n",
       "      <td>2.88020</td>\n",
       "      <td>-3.70710</td>\n",
       "      <td>-1.81070</td>\n",
       "      <td>-2.5392</td>\n",
       "      <td>2.89830</td>\n",
       "      <td>-2.63380</td>\n",
       "      <td>-3.18470</td>\n",
       "      <td>-3.61820</td>\n",
       "      <td>-5.06320</td>\n",
       "      <td>-2.13680</td>\n",
       "      <td>-1.44800</td>\n",
       "      <td>4.36180</td>\n",
       "      <td>-3.05240</td>\n",
       "      <td>-1.76090</td>\n",
       "      <td>1.89270</td>\n",
       "      <td>3.74030</td>\n",
       "      <td>2.9173</td>\n",
       "      <td>0.4139</td>\n",
       "      <td>7.34780</td>\n",
       "      <td>2.93150</td>\n",
       "      <td>2.11600</td>\n",
       "      <td>1.90170</td>\n",
       "      <td>5.08370</td>\n",
       "      <td>-4.89770</td>\n",
       "      <td>1.12480</td>\n",
       "      <td>-4.78600</td>\n",
       "      <td>0.23904</td>\n",
       "      <td>0.038293</td>\n",
       "      <td>-5.76190</td>\n",
       "      <td>3.26870</td>\n",
       "      <td>2.783300</td>\n",
       "      <td>0.12430</td>\n",
       "      <td>-2.69890</td>\n",
       "      <td>-1.37100</td>\n",
       "      <td>2.2128</td>\n",
       "      <td>-0.037228</td>\n",
       "      <td>0.20066</td>\n",
       "      <td>1.74010</td>\n",
       "      <td>-3.01200</td>\n",
       "      <td>2.368200</td>\n",
       "      <td>3.72540</td>\n",
       "      <td>2.608500</td>\n",
       "      <td>-0.53161</td>\n",
       "      <td>-3.1048</td>\n",
       "      <td>-2.72900</td>\n",
       "      <td>4.09020</td>\n",
       "      <td>-5.49070</td>\n",
       "      <td>-1.372500</td>\n",
       "      <td>-3.58540</td>\n",
       "      <td>0.38873</td>\n",
       "      <td>-1.3636</td>\n",
       "      <td>0.53067</td>\n",
       "      <td>-3.34950</td>\n",
       "      <td>-4.26420</td>\n",
       "      <td>0.894910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3288 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1        2        3        4         5        6         7        8        9        10       11       12        13       14        15        16        17        18      19       20       21      22       23        24       25       26       27        28       29       30        31       32       33       34       35        36        37       38       39         40       41       42       43       44       45       46       47       48       49        50       51        52       53      54       55       56       57       58        59      60       61      62        63       64      65       66      67       68      69       70       71       72        73       74       75       76       77       78       79       80       81       82       83        84        85       86      87       88         89       90       91       92        93       94        95        96       97        98       99       100       101      102     103       104      105      106      107      108       109      110      111      112      113       114       115      116      117       118      119      120      121      122      123     124       125      126      127      128      129     130      131      132      133       134      135       136       137     138      139      140      141      142      143      144       145      146       147      148      149      150      151        152      153      154       155     156       157      158      159      160      161      162       163      164      165      166      167      168     169       170      171      172       173      174       175       176      177      178      179      180      181       182       183      184       185      186       187      188     189      190      191       192      193      194       195      196       197       198      199       200      201      202      203      204      205       206      207      208      209      210       211      212      213       214  \\\n",
       "airplane    -3.900300   3.93430  0.65395  1.29990  2.83170  1.508200  6.75800  5.364900 -2.36660 -3.08060   7.3809  0.22831 -2.47630  0.017361 -0.68943 -2.390400 -0.060711 -3.533500  1.810800 -2.0253 -1.97780 -1.41780 -1.9544  0.10393  -2.83050 -3.57070 -2.80240 -0.88663 -3.289400  1.66370  5.91670 -0.091764 -2.84720 -5.14470 -2.39620  1.18960 -3.490000  1.823300  4.96860  2.07140  -2.244400  5.36050 -0.95761  4.29600 -0.21680  0.62048  1.73920 -5.99340 -2.89730  3.93680 -2.401700  1.49590 -0.054549 -6.26560 -4.5234  0.53169  1.63590  0.89828  1.03740  2.017600 -2.9216  1.64230 -3.3777  -0.49631  3.28690  2.7791 -2.59510 -3.8540  1.46620  2.8515  4.42560  3.98090 -0.73355 -0.119020  0.89358  0.70556 -2.02380  2.77660  0.26854  4.13280 -5.96310 -1.10990  1.34010 -1.51770  0.316740 -3.018500 -5.17970 -3.0217 -0.04403   0.049687 -1.47610  4.24500  3.33700  -1.33770  5.05770   1.07830 -0.016471 -2.56510 -1.393600  0.63940  1.57260 -0.011109 -1.69850  4.3501  -5.49180  5.04830 -2.20180 -0.41809 -0.78404  -0.66416  1.15280  1.23260 -1.30860  0.31578  -1.19400   3.92370  0.46197  1.06130 -0.319790 -2.38780  2.12210 -1.80540 -1.42700  0.53254 -3.0410  -2.34490 -1.62040 -2.96710  4.63050  0.16084 -4.8255 -0.29363  3.13940 -1.95800  -1.29290  4.14060 -0.038602  1.524500  5.9246 -2.75440 -2.19690 -0.31086  4.74790 -1.76610 -0.22267 -0.300000 -1.75270 -0.050056 -2.55650  1.28360  0.41696  2.88090   0.355010 -0.87239 -1.04280  0.307970  4.1562 -1.008100 -1.14420 -1.09840 -1.91330 -1.54030 -3.62340   0.42826 -5.00650 -0.49866 -4.22030  2.79070 -0.38192  3.9372  -1.97130  3.24010 -0.78560 -0.079338  2.72100  -2.73960  -4.29080 -1.70190 -2.51120  0.14885 -2.91820 -0.40600  6.545700 -3.012900 -0.27173 -0.104410 -5.43240 -1.326000  3.23230  3.2203  1.94580  1.15240 -1.384000  2.16370 -2.54230  2.771200 -0.78878 -3.597100 -0.001075  2.14810  -2.43480 -8.08430 -3.99480 -3.24140  0.19680  1.93320 -1.234800  3.02840 -3.30660  0.92006  0.59873  0.294280 -1.83340  1.32660  1.281800   \n",
       "coarse       2.042700  -2.06910 -1.59100  0.42295  3.51720 -0.042939  1.57450  5.945900 -7.09320 -3.81480  11.7570  4.35480 -3.72050  4.313600  0.26884 -0.443220  4.132300  1.703300 -3.872900  1.4727 -1.43550  0.94668 -3.8571  1.27040  -4.54170 -2.14030  1.29390 -1.74510 -5.526400  3.00230  2.44820  2.639000 -1.52310  2.31340  1.35940 -0.54864  2.054000 -0.170160  3.40220 -0.78957  -3.454300  0.54014 -0.11914  0.67721 -1.32260  4.33330  6.49880 -1.92460  1.47590 -0.98074  2.269100  2.51920 -0.378430 -6.23930 -1.1834  3.27730 -4.31950  2.05230  0.73059 -4.089200  4.8110  3.82850 -3.8583   0.64311  3.03840  6.5163 -2.40190 -1.0276  0.66792  2.5126 -1.84300  1.45240 -2.50840 -1.587100 -2.47370  1.26340 -2.13820  2.62900 -2.79220  3.31980 -5.65540 -2.47220  2.41710  2.82290  0.674250  1.683500  0.62230 -3.0518  4.01130   3.282600 -4.33350 -0.99384  1.03250  -3.25910  2.63790  -2.88770  4.076400 -1.01440 -3.144600 -2.40730  2.25510  1.203100  1.55070  0.4223   2.40900  8.36280 -2.88400 -6.41140  2.49140  -0.91834  3.68570 -0.40304  0.30373 -1.01040   0.70464   1.45450 -2.50800 -1.52900 -3.525500 -2.80110 -2.42530 -1.66710  0.83456  0.26350  1.4257  -6.30400  2.44460 -5.85960  1.55090 -3.20320 -5.7372  2.77660  2.84770  1.31420  -2.46830  1.96310 -1.667000 -0.841440  1.9242 -3.32250 -2.62450  0.91188 -1.65780 -1.32340  2.59840 -2.458200 -0.38224  1.955800  3.28860  4.03430 -3.19270  3.37620  -1.001400  1.33840 -0.95402  0.051455  4.5192  3.340600 -0.18517 -2.15530 -0.11305 -2.00650 -0.32349   0.58643 -3.69460 -4.56340 -3.93610  0.52761 -1.69340 -4.4783  -4.98760 -5.44350 -0.18109  0.848120  3.82640   1.24350   1.86570  2.38550 -0.98788 -3.53360 -0.92577 -1.11740 -0.008842 -7.676500 -1.09620  0.306180 -2.43420 -2.690900  3.95540 -2.2016 -1.29390 -0.75266 -0.081766 -2.01910  2.97740 -1.234600 -6.57250 -0.105870  0.433400  2.35650  -2.98590 -1.05750 -6.06500 -0.93495  8.60080  0.30004 -3.853300  1.28420  3.86150  0.87080  4.07370 -2.319200 -1.82560  3.78550  0.340980   \n",
       "persecution  0.068316   4.34330 -5.55370  4.75970  2.12330  2.133900  0.55151 -0.290250 -4.60460 -0.51456  -1.3425  2.43150 -4.22010 -2.246000 -2.50050 -0.934730 -2.199000 -2.848000 -3.149100 -3.1937  0.42370 -1.09930 -2.1370 -0.28805  -3.81980 -0.40685  0.65904 -1.16870 -0.849820 -0.84344  5.87940 -4.655900  1.95800 -2.65690 -1.80940 -3.31670  0.962420 -1.334600  1.10600 -2.04600  -2.623400 -5.04220 -5.30670  5.77370 -5.86420  5.34060  1.16000 -7.87760  5.77020  4.13320  1.204400 -4.40440  4.653500 -7.24320  2.7926  4.95930  3.69890 -0.61183 -1.70640  3.727400 -2.3768  2.59290 -1.8523   2.23890  1.48830 -3.0840 -5.29610  1.5135 -2.18440 -1.6817 -1.58140  3.41980 -6.36440  3.120600 -2.55450  4.71060  0.44177 -2.04330 -3.85550 -3.92460 -1.88430 -4.03460  1.80540  0.14297 -3.485000 -0.166340 -1.05400 -3.0761  1.08100   2.862600 -5.40030  1.49940  1.97570  -2.19440  3.90870  -3.35410  1.350700 -7.48700  3.647600  4.34480 -3.60490  0.168820 -0.48981 -6.9565  -3.92430 -0.50639 -5.37260  1.76030  1.07730 -11.20400  0.64015  2.05970  1.30070  0.58045   4.67900   5.39410 -3.78570 -0.56545  0.307490 -2.82010 -6.45040  4.05570 -3.63020 -0.18437  3.5357  -4.07680 -4.38920  2.53090  5.57150  1.08600 -2.9182 -4.27100  0.24768 -3.19250   5.33060  3.33170 -5.574900 -6.309700  1.2430 -3.78240 -3.75980 -6.36870 -0.53144 -3.36840 -0.17049 -2.790100 -1.88460 -2.993200  2.90370  2.04970 -1.10960 -3.32500  -2.308300 -3.02970  5.01520 -2.914600  3.6464 -7.413700  0.99681 -0.11761  0.47407  2.19730 -1.58140   1.71370 -0.44272 -2.57820 -4.72310  1.00800  1.99990  3.8906  -3.29840  0.97767  0.15030  3.272700 -0.83230   4.64120  11.09500  2.71180 -1.70500 -2.94950 -9.65910 -1.84710 -0.169500 -4.341600  0.60770  1.699500 -0.91934  0.583280 -1.21130  4.8081  0.72203  2.58620 -1.344100  2.93530 -4.47850 -3.161000  2.21860 -1.001600  2.202600  7.71550  -7.57370 -4.67440 -0.17288  0.82796 -3.90840 -5.25760 -5.441300  2.54460 -1.38050  0.85349  5.67780  3.000000  6.73630  2.55540  1.909700   \n",
       "moment      -7.688900   0.56799 -2.18350  1.66660  3.30210  4.386700 -1.50380  5.213800 -0.37570 -1.74370  10.0440  5.34510 -4.76740  1.262700 -3.43640  1.718900 -6.290400 -1.052600  0.017089 -4.5076 -6.07950 -0.40140 -3.2510 -1.12350  -0.60938  3.05790  4.26910  2.16110 -0.095159  5.94480 -0.15644 -4.450900  1.51900 -3.21020  0.57536 -0.63007 -0.539930 -3.611300  1.08430  5.00290  -0.922590 -1.74930 -1.78280  2.38270 -2.00990  4.25600  0.96042  2.10830  0.68934  3.80630  0.015108  0.68857 -0.059503 -1.35980 -4.8023  5.69050 -0.26204  2.19090 -4.95260  5.182500  1.4434  1.42350 -3.4782  -4.96180  4.54700  2.3776 -0.75467 -5.8222  2.41730  2.7640  0.95128  1.17240 -2.86990 -1.333300 -1.73670  2.04840 -3.41090  2.23210  0.13952  3.92540 -3.27930 -1.77760  1.81430  3.91730  1.009300  4.215100 -3.18600 -5.0629  0.21069   1.450700 -1.55130  2.18650  0.15176  -4.35780  0.38870   1.04260 -1.201900 -3.75440 -1.983300  4.67910  4.79400 -3.120700  3.17340  4.5507  -4.51150  3.74700  3.84090  0.06178 -1.98630   1.69060  3.45130  1.17290  0.31355  0.77013  -0.25839   1.62780 -2.34050  0.59517 -2.287300 -0.10548 -0.44599 -3.49730 -1.89050 -1.83430 -3.4326  -1.34580  3.00660  2.51650  0.86985  0.53212 -2.3949 -3.80500  5.79310  0.82710  -2.68900  4.96250 -0.829510  3.317300 -4.8832 -1.71710  1.20790  5.58890  5.92850  0.85683 -2.41980  0.036704 -1.18760  1.106500  2.89530  4.41970  0.55039  4.41070  -0.722820  3.24640  2.12640  5.697500  3.6839  0.086178 -4.64510 -5.53280  1.59800 -0.32722 -0.99592   3.54220 -2.15680 -1.35580  0.33573 -1.81460  1.97760 -2.6072  -0.49377  1.00410  1.41860 -1.689600  2.33870   1.64520  -4.03310  2.86770  2.13270 -0.59078  0.11446  1.37830 -1.147000  0.998700 -3.86880 -3.285600  0.99650  3.026800  2.80580  8.1786  1.51190  0.76748 -0.306180 -0.20447  3.19520  0.050764 -3.83280 -4.562900  1.405100  1.20990  -0.46244  0.49520 -2.24960 -2.21270 -2.04830 -0.29449 -2.389000 -0.83991  5.98280  5.04540  0.19258 -0.093833 -5.75530 -3.19570  0.081784   \n",
       "responsible -0.638270  -0.20965  2.43960 -2.95510  8.56760  4.540600  1.55490  0.021014 -4.06440  1.83910   8.6355  4.31000 -2.86120  3.884300  1.95520  0.636720  3.363700  0.241690 -2.137700 -1.2866 -0.29364  1.46590 -6.3379  0.84835  -1.86210 -0.88167  2.04370 -4.66290 -4.722900  0.69482  0.13129  1.476900 -1.69590 -0.66062 -0.18362  3.07470 -3.895000  1.507200  1.97030  2.84680   0.751650 -2.57500 -0.08866  4.10960 -0.57931  0.28668  5.55460 -0.38686  0.33243 -0.70699 -3.365500  5.43010  4.317500 -2.33060 -1.1958  0.72377 -2.97470  4.50990  0.39007 -2.297800  1.7473  0.38184 -1.7837  -1.38820 -1.88730  4.5330 -2.91680 -2.8414  0.28346  6.0842 -1.33780  4.12870 -2.12630  0.218620 -0.47545 -0.28176  0.64357  0.70815 -6.30050  6.88170 -0.81048 -4.49050 -0.05582  5.45360  2.049800 -1.334300  0.39381  1.2033  4.47960  -2.556800 -0.30427 -0.43990  3.43110  -1.51180 -3.44850  -0.14396  0.211030  0.73644 -3.574100  1.00070  0.34926 -0.038084 -0.12147 -1.3263   3.09370  2.05860 -1.07850 -1.44510  1.01360  -2.00260  3.88520 -1.28300 -0.95133 -1.47540  -4.08750  -0.95433 -3.46470 -0.22175 -1.657000 -1.10830 -3.33330 -4.48360  1.83610  3.18210 -4.0156   2.08560 -1.28940 -4.70140  2.06260  0.45006 -2.8907  1.13180 -0.93994  0.73698   1.48790 -2.62120  0.481220 -2.485900  3.8359 -0.87219 -4.23500  0.91940  3.65640  0.15135 -3.91090 -2.474400  1.42920  3.874400 -0.98322 -0.29984  1.44990  2.01320  -0.509520 -3.43370 -0.70837  1.536600  2.8661  4.895800  1.86250 -0.24276 -4.91790 -1.77090 -2.59000   1.83910 -5.19630 -1.25460 -0.20290  4.42930  2.22940 -3.6492  -1.22840  1.29550 -6.56860  4.045000  3.89240   1.56860   1.96810  1.18830 -2.31960 -2.17700  0.13151  1.17640  2.504200 -2.667700  0.87327 -2.128100 -0.63756 -2.291100 -0.18833  2.2716  0.84158 -5.43240 -1.053100 -4.32280  4.74300 -0.157190 -4.26570 -0.702300  3.844900  1.31280  -2.24870 -5.79350 -2.89630 -0.61781  4.56840 -0.97401 -1.033500  0.92388  3.28770 -2.13090 -4.37290  0.651320 -0.22954  6.09210  3.593800   \n",
       "...               ...       ...      ...      ...      ...       ...      ...       ...      ...      ...      ...      ...      ...       ...      ...       ...       ...       ...       ...     ...      ...      ...     ...      ...       ...      ...      ...      ...       ...      ...      ...       ...      ...      ...      ...      ...       ...       ...      ...      ...        ...      ...      ...      ...      ...      ...      ...      ...      ...      ...       ...      ...       ...      ...     ...      ...      ...      ...      ...       ...     ...      ...     ...       ...      ...     ...      ...     ...      ...     ...      ...      ...      ...       ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...       ...       ...      ...     ...      ...        ...      ...      ...      ...       ...      ...       ...       ...      ...       ...      ...      ...       ...      ...     ...       ...      ...      ...      ...      ...       ...      ...      ...      ...      ...       ...       ...      ...      ...       ...      ...      ...      ...      ...      ...     ...       ...      ...      ...      ...      ...     ...      ...      ...      ...       ...      ...       ...       ...     ...      ...      ...      ...      ...      ...      ...       ...      ...       ...      ...      ...      ...      ...        ...      ...      ...       ...     ...       ...      ...      ...      ...      ...      ...       ...      ...      ...      ...      ...      ...     ...       ...      ...      ...       ...      ...       ...       ...      ...      ...      ...      ...      ...       ...       ...      ...       ...      ...       ...      ...     ...      ...      ...       ...      ...      ...       ...      ...       ...       ...      ...       ...      ...      ...      ...      ...      ...       ...      ...      ...      ...      ...       ...      ...      ...       ...   \n",
       "prawn       -0.555210  -1.20940 -1.59380  0.85357  0.11995  0.819640  1.38210  2.358900 -0.45013  0.79720   4.4177  1.49190 -1.38680  1.735400  1.59320 -0.007249  1.506900 -0.086719 -1.357800 -1.3076  1.96040  2.54860 -1.3290 -2.80820   0.19496 -3.13150 -2.24660 -2.50650 -2.861500  0.44785  0.80668 -1.417200 -0.85002  1.04690 -1.22520 -0.21808 -1.013900  0.041965  2.60150  1.55600  -0.070996 -0.57363 -0.28696 -0.12214  0.67195  0.60949  0.32463 -2.32220 -2.49200  1.98890  0.433630  1.35570  0.439420 -4.62640 -2.3616 -0.68795  0.96643  0.50996  1.49600 -0.439710  1.6498  1.11770 -1.8202  -0.37879  0.99955 -1.0961 -3.30240 -2.8575  0.28605  2.1055  0.57166  0.73573 -0.52267  1.183200  0.63967  0.15548 -3.99830  1.29710 -1.14900 -0.65285 -3.27830  0.43801  2.63580  0.41438  3.420500 -1.178200 -1.57040 -3.1601  2.18660  -0.830020 -0.25336  1.41320  2.89940  -2.84560  0.48514  -1.58330  2.266300 -2.54060  0.894110 -0.31395  1.43480  1.501900  1.38260  1.8610  -0.50059  4.21610 -0.22724 -0.32698 -0.61409  -1.12580  0.59901 -1.25530  1.20990 -0.30591   0.97642  -0.47297 -1.06940 -2.06600  1.399000 -3.58810 -1.68080 -1.63680 -2.66290  1.94300 -1.5802  -1.59290  1.22260 -2.00820  0.48073 -0.88187 -1.6929  0.62347  1.05970 -0.60525   0.36383  1.00030 -0.355750 -2.145400  3.5754 -2.42000 -1.10320 -0.56871  1.33020  0.38080 -0.77858 -2.356900 -1.01010 -1.456400 -1.41680 -1.41010 -0.91237  1.19580  -1.330800  1.71620 -2.02410  1.289600  4.7248 -0.483540 -2.54350 -0.54130  0.32934 -1.32690 -0.54886   0.42794 -2.72180 -1.29370 -1.82900  0.41575  1.42500  1.6748   2.44250 -1.09810  1.25560  0.503130  2.19230  -1.28090  -1.39880  2.02120 -1.88280 -0.39164 -1.58550 -0.36367  3.765500  0.293570  0.30051  0.080223 -0.98590 -1.920200  2.13860  2.6969 -1.33410  0.95185 -1.263900  0.21003  0.19744 -1.192300 -2.83750  0.101560  0.944520  2.57890  -1.19540  0.80411 -2.12390  0.44031  1.97040  1.08730 -0.117200 -0.14338 -1.22470 -1.87710  1.11770 -0.570940  0.56189  1.11130 -2.205400   \n",
       "tweezers    -1.998400   1.01710  1.24380 -0.67552  5.93120  2.095500  9.03150 -3.656900 -1.58780  2.31650  -7.8383 -3.04760  0.53385 -4.658400 -5.50930 -0.144140 -2.957600  3.884200 -0.261430  7.2422  0.80466  6.26090  3.8815 -4.15570   8.75300 -0.36023  3.60130 -1.01360  3.390400 -3.53180 -7.93520  5.759200 -1.64000  6.84850 -1.06040 -0.34016 -1.574700 -1.868700 -2.42510 -5.18620  -1.089400  3.21340  3.45950 -3.49460  1.72360 -3.97270  0.99131  0.69573 -5.59780  3.36330 -5.347700  0.78380  2.169700  0.79255 -3.4373 -7.35500  3.03790 -1.63840 -5.24980 -2.428800  3.4233  5.22310 -4.1671   1.75210  3.43010 -1.3719  3.17720  3.3355 -1.02590 -1.0918  5.74780 -6.17680 -0.90611 -0.340530 -3.73790  2.86700  3.94590  1.07560  1.00450 -1.72910  3.21970  2.09330  0.44786  0.38864  0.092844 -7.526000 -5.14850 -2.6222 -0.66842  -0.401070 -0.63273  0.44273 -3.57870   1.88100 -3.06600   0.96110 -1.738500  2.21080  6.470400  4.43040  0.52488  0.868510  1.09790  3.8364   7.12610 -1.28140  3.61210  2.34360  4.08700   2.74710 -1.38700  3.22070  1.17870 -1.34500  -6.25450  -6.11970  1.24090  0.74903 -7.940300  1.32520  0.12838 -0.97745  5.31560 -2.22900 -1.8447   2.27250 -1.63490  1.89690 -0.38576 -2.04050 -1.6867  2.99530  2.30300  2.58140  -1.50950 -0.96319  2.648400  1.731300  2.2987 -2.23230 -0.28140 -2.49560 -2.53810 -3.74270 -1.87680 -7.723100 -0.64728  9.056800  0.53917 -5.36820  3.61550 -3.54470  -2.368200  3.67690 -0.21525  0.233910 -3.2361 -3.658500  2.16660  0.87207 -2.27130 -1.76050 -0.56142  -3.73920 -3.43280 -1.33920  3.33600 -2.57590 -4.89360 -4.2442   2.35060 -1.33260 -3.76300 -1.551900  2.77840   2.04460   1.96560 -5.09600  1.46480  1.77810 -3.98320  1.86650 -0.296200 -1.429700  4.70510 -3.904300  4.65730  0.013339  4.52800  6.1138  3.76860  0.74584  3.403800  2.45690  6.35240  3.060000  1.42010  0.398030  0.506680  2.47210  10.89100  4.09930  4.29780 -1.71060 -3.51410 -2.06170  2.905400 -3.08590  0.24649 -3.55320 -6.03000 -1.232300  1.48810  6.99350 -1.177600   \n",
       "university  -1.068600 -10.11400  4.03640 -3.13620  6.66330 -1.798900  3.68110  7.327800 -0.94667 -2.11760   3.7071  2.96010  3.89420 -6.757900 -4.48670  2.691700 -4.460400  5.510500 -4.175700  4.4499 -1.04270 -7.46150 -6.4483 -3.93410 -10.33600  3.84610  2.51430  4.78470 -4.129000  6.99120  3.12810  0.614680  7.07690 -2.96670 -2.34340 -9.32910 -1.687600 -1.877200  0.84683 -5.67300 -12.981000 -0.92561 -5.91940 -3.14500 -2.23150  8.87240  6.78720  0.14341  2.92010  4.38660 -3.426200 -5.55780  4.288900 -0.24222  2.9603 -1.88000 -1.71170 -2.73970  2.40000 -4.745400 -7.3338 -1.04920 -7.6544 -11.14300  0.12249  2.8896  2.46180  5.1039 -6.56890 -4.7415  1.11470 -3.74690  2.34610  7.248700  3.33770  7.89670 -0.81971 -5.22830 -1.16860 -0.22470  3.76020 -1.65840  4.54910  1.30720  3.787100  1.252800 -4.13410  3.5882 -4.40810  10.561000 -9.90360 -0.17611 -6.95630  12.21300 -2.07930  10.17100 -0.209550 -7.49150  8.270100  3.48150  9.87260 -5.419800  5.96950  9.9306  10.21500  3.43180 -0.20011  3.76160 -1.01920  -5.30060 -5.32780 -0.96439  0.70093 -2.62770 -10.60600  12.25000 -4.56330 -3.30350 -0.074273  1.79680  6.02050 -5.56530  4.50280 -4.05520 -7.7767 -12.24100 -4.70380 -4.23770 -8.99950  4.39090  4.2466 -4.41830  9.48320 -0.55428 -14.00000  4.89870  0.292040  1.583300 -8.6796  1.77160  5.95060  5.11210  0.83254  3.17340 -0.81617 -7.215200 -4.75200 -2.376700  3.69630 -1.01110 -1.18700  0.39079 -11.364000  0.44649  9.56470  7.098000  1.5688 -2.253900  7.33040 -5.75790  2.47420  8.93480  3.93900  10.37700 -7.73290  7.63050 -2.52470 -2.68520 -3.93670  2.8864 -10.93700 -5.13140  6.06970 -0.217600  6.16230  12.69900   0.69175  6.98680 -6.88360 -2.50140 -4.01530  0.59352 -4.653300 -1.912300  6.85350  3.342700 -0.54042 -1.732900 -1.89180 -6.7632  3.49320  2.39900 -0.591660 -4.17540 -3.53590  5.579200 -3.76200 -7.006300 -8.743500 -0.56694   5.89390 -6.70050  3.39130 -2.17210  6.24640 -1.04130 -6.061900  3.77820  2.46180  0.69879 -3.42900  6.555000  1.16150 -3.84820 -8.639900   \n",
       "wasteful    -5.898500  -2.82470  0.85307 -1.26600  0.80816  0.217950  5.35130  1.112400 -3.11060 -0.13387  -4.2348 -2.81970  1.05510 -4.293300 -3.84430 -1.019800 -3.657400  0.611180 -1.142200  3.7208  0.53791 -0.23637  5.7244  0.36354   2.95040  2.40210 -0.95108  1.97110  3.564500 -0.24429 -2.21570  3.356400  1.30990  6.35790 -5.97120 -5.17460  0.099442 -2.119100  0.38604 -1.42960  -0.711400  2.46850  5.97340  1.15390  1.39120 -1.00750 -4.77150  1.52450  0.35708  3.62370 -0.152060 -2.22140  0.550530  4.08640  1.8258 -5.79210  1.33070 -1.24280 -4.41500 -2.199900  2.9477  2.73850  3.7307  -0.32139  2.04040  1.9807  0.18090  1.1595 -2.38990 -3.2002  2.90930 -3.01970 -0.32339  0.006255  3.46460  0.45295  1.78530 -2.56340 -1.50400 -4.26990 -0.35531 -0.33360 -1.02870  4.97770 -0.981450 -1.983500 -1.99230 -1.2690  0.21810  -0.945760 -3.61430 -2.41690 -1.14280   0.90399  2.88950   3.15230 -2.135800  1.17070  5.211300  1.02070  2.31400 -2.728000 -1.57210 -1.4642   2.80760 -5.52380  3.75670 -1.01060  3.31980  -0.90565 -3.27050  1.77210  3.12100  0.79535  -2.54770  -5.78040 -0.66670  1.20070 -4.064200  2.23100 -4.14660 -1.45330  1.05910  0.18255 -1.5340   0.48083  0.93602  2.37270  3.23040 -1.36840 -0.6788  0.97002 -0.18370  0.68279  -0.13605 -1.88550  2.468200 -0.010213  2.5421  1.39040 -3.47800 -0.30130 -0.50026 -2.01260  2.67220 -2.829400 -0.76953  0.840990 -4.90710 -3.02280  4.37140 -1.09750  -7.085900  1.63890 -0.96322 -1.326800 -3.6022  0.608130 -0.22319  2.39830 -1.97400 -1.61550 -2.34880  -3.12220 -1.20300  1.61480 -1.86640 -1.29030 -4.41030 -5.3345   1.12620 -2.73770 -3.77910  1.977100 -0.23047   0.82517   0.10275 -0.58393 -0.30369 -0.39137 -1.68450 -2.28840 -2.109200  0.060564  3.07070 -0.128720  5.69100  0.749880  4.24340  1.4342  0.25702  4.37910  4.458300  4.80330  2.09530 -2.330100  4.88700 -0.024999  4.268500  0.65543   2.44770  1.08920  0.14664 -4.61360  0.56488  4.03910  1.034500 -3.25500  2.82740 -3.75810 -1.42250  0.791350 -1.07010  2.13090 -2.069600   \n",
       "children     2.527700   2.45850  1.40970  1.26680  3.48150  3.013100  0.14440  3.319400 -4.64910 -0.90818   4.6572  1.81340 -5.20930 -3.046800  0.95889  1.127800  3.766300 -1.172400 -5.236800 -2.7310  0.83627 -0.15671 -3.5574  0.66522   0.76249 -3.11670 -2.33900 -1.10070 -1.936100 -0.37116  2.21150 -0.252560  0.89407  0.42813  5.54970 -4.84510  0.126360 -1.451500  2.44780  2.05710   0.016965  1.09170  0.92943  0.24111 -0.56336 -0.75646  3.87410 -3.15820  1.44900  1.93720  3.320900  2.73640  1.727400 -1.79250 -5.7121  4.06750 -4.08520  3.74580 -0.57559  0.066014  4.5403  1.54670 -1.4521   0.21168  0.56963  4.9667 -1.95350 -4.6255  0.22140  7.8679  0.77221  1.31010 -1.85010 -3.092100 -4.36200  0.72363 -3.80210  3.28420 -3.69840 -0.28394 -3.33220 -2.36460  1.42960  5.31630 -0.601130 -0.026209 -5.24600 -3.9416  2.49890   2.942600  0.26338  4.33080  2.39310  -0.14004  1.33220  -0.42698 -1.429400  2.60150  0.008421  2.03760  4.63190  3.889700  2.15130 -1.3453   1.33320  7.54030 -1.01340 -2.80980 -1.22040  -3.44800  1.83850  0.89519  0.94821 -0.40312   1.30260   4.18140 -5.30060 -0.11834 -0.303420 -0.92647 -2.85580 -3.95380  2.41610 -2.14900  1.4545  -3.81470  2.82180 -0.66691  3.74510  0.33645 -4.4970  0.59448  3.15120  1.72930   1.84960  1.34200 -4.102000 -0.181750  6.2029 -1.10230 -0.19552  0.49945  0.34234  3.47850 -0.23550 -1.715900 -0.41219 -1.004700  0.10796  4.85150  2.79720  4.15440  -0.037735  3.25380 -1.48770  0.781630  2.4206 -2.012000  0.54807 -4.03130  0.76244  0.67017 -0.13130  -0.29379 -2.81050 -2.42140 -6.66470  1.04750 -3.35110 -4.2410  -3.19340 -3.24740 -1.84820  2.741600  3.87340   4.80000   0.34359  2.41030 -4.16780 -1.43790  1.96250  0.14628  2.027600 -0.354440 -0.40565  0.755320 -3.48000 -3.030400  0.60583  3.8898 -7.64840  0.31409  0.366850  0.80175  1.39070  0.188560 -2.45570  0.703980 -1.527700  1.94780  -2.60190  1.90900 -0.62335 -0.75263  7.41110  0.23533 -0.019343  2.04250  0.04966  1.06800  1.26660 -1.186400  1.45170  0.77143 -1.938700   \n",
       "\n",
       "                 215      216       217      218       219      220      221      222      223      224      225      226       227     228      229      230     231       232      233      234       235      236       237      238       239       240      241      242      243        244      245      246      247     248      249      250      251      252      253      254      255      256      257      258      259      260     261     262      263      264      265      266      267      268      269      270      271       272      273       274       275       276      277      278     279       280      281      282      283       284       285       286      287      288      289      290      291       292      293      294     295      296      297      298        299  \n",
       "airplane     4.80140  0.95566  -2.15410 -1.82020 -0.559350 -2.19780 -1.86960 -0.83113 -0.29340 -3.46630 -3.49460 -1.11120  1.393900  2.5032  1.39520  0.29229 -2.8486  0.038245  2.59330  0.27597  2.113800  1.97000   5.78300 -7.13120  -1.47090 -1.117400 -0.45468 -1.92740 -1.14920   1.184000 -3.34210 -2.28830  1.93360  3.3205  5.47850  1.66630 -2.19340 -7.69760  1.85860 -0.22897 -2.68230  1.09740  0.35450  0.83341  0.53664 -0.57928  5.3247  1.9213  1.56950 -0.74805 -1.08930  3.24310  4.85570 -7.01540  1.43420  5.40910 -4.71290 -0.548970 -0.41088   0.66925 -2.922000   0.54973 -0.66148 -1.50200  1.3905  2.269300  1.57630 -1.49930  1.29760  3.150300  -3.51840  0.673510  3.10910  -6.3776  2.24180 -0.36937  1.10960  4.207400  1.66340  0.52245  3.5314  0.79304  0.11406 -5.10790   1.122000  \n",
       "coarse       4.11250 -0.72653  -8.58240  0.36828 -0.344450 -2.75520  2.13960  1.99320 -1.99510  0.66178 -4.08820  2.41980  0.577990  3.0488 -0.76900 -1.28570 -3.7659 -2.280100 -0.36999  7.79510  4.220400  4.64980   3.48220  2.90390   2.24390 -1.837500 -5.10100 -0.34775  2.13040   0.525040 -2.94180 -3.59040 -0.61967  1.1622  0.51956  1.90330 -2.51030 -0.48914 -1.99650  1.75590 -0.97327 -0.97464  0.55097  1.86220  0.92131  3.10860  3.0548  1.6227  1.92500  5.10540  1.39620  0.15861  5.90950 -3.23000 -3.91970 -0.68823 -1.85420  1.997700 -1.28010  -2.55400 -0.792680   3.55030  0.47723  2.05990  2.0810  3.945100  1.27120  1.19940  0.56537  7.962800   0.51540  2.638100  1.52530  -1.4806  2.36910  0.48063 -3.19270 -1.133600 -1.53970 -0.97280 -0.2494  8.29990 -3.88090 -5.23350   3.850200  \n",
       "persecution -0.37607  4.09190  -3.40200 -3.55480 -5.484700  2.26840  0.18169 -7.13010 -0.33965 -0.77849  0.25872 -0.85297  0.044621 -1.2597  2.85650 -0.92115 -1.3267  2.274300 -8.91740  2.32480 -4.756500 -0.15451   6.79650  1.67640  -1.32770 -5.398400  2.16090  2.09240 -6.46170   2.970600 -4.02220  3.16400  3.52370  1.8952  4.20700 -4.48830 -0.73258 -9.39030  2.13960  0.69047 -2.87110  0.48702 -1.60770  3.71610  3.44150 -1.35300  6.3550 -3.6564 -2.69790  1.71680  0.37678  1.80010  1.75520 -6.87900 -5.20130  1.84370 -1.49970  0.378760 -8.52430  -3.86360  5.055000 -11.43600  4.33510  2.22680  2.4529 -5.233000 -0.80374 -2.86740 -6.58180  0.022082  -0.13392  0.076618 -5.05190  -5.9940  1.19410 -5.59980  2.51550  1.125900  0.71647 -3.38270 -1.9534  1.18160  2.24510 -1.91380  -0.074928  \n",
       "moment      -1.24730  0.89743  -0.77232 -3.86890  2.352800 -1.65810  3.58610  1.35350 -4.08790 -3.17090 -1.04000 -2.95890  4.319500  3.9136  0.66900  0.80280 -2.5065  3.333600  1.61520 -0.39701  2.602600 -0.31418   4.65460 -6.09340   1.37670  3.186300 -4.23590 -4.46750  5.67720   4.627900  0.75198 -2.02250  4.80130  7.6043 -1.32370  4.34110 -0.29942 -1.99690  1.59420  2.89660 -5.32890 -1.05400  1.28050  3.00150 -1.81870 -0.86083  1.6326  1.3456 -1.65490  1.18600 -0.93019  3.51560 -0.65960 -1.04720 -0.15340  4.06750  1.14690  0.058387 -0.20873  -2.66590 -1.395600   2.50070  3.17950 -2.57530  3.2376  4.661600  0.62102  2.00200  1.12280 -0.578350  -3.03170  3.652800  4.18340  -1.7926 -0.54218 -3.34500  1.48080  2.330200 -5.26970 -0.67720 -1.1638 -2.93030 -0.90046 -3.00530   1.682800  \n",
       "responsible  3.10510  2.59140  -5.04660  1.25310  0.035322 -2.16530  3.26240 -1.23440 -0.94035 -0.30661 -3.95170  3.09280  5.530200  2.3109 -1.47430 -1.96780 -3.5667 -3.994300  3.50250  1.05360  0.966360  2.24550   5.06660 -0.11901   4.78090 -3.363300 -3.40330 -2.98510 -0.45114  -0.232280  3.25600 -2.77960 -2.44590 -1.3946 -0.48330  1.62750 -5.84550 -5.06910 -1.66860  0.95694 -0.27934 -1.47030  0.55012  2.37760  0.87968  1.16200  6.4236 -2.1488  0.36583  2.09410 -1.70460 -0.90162  0.94648 -1.56380 -4.08680  0.49151 -1.37700 -1.525300 -1.87430   1.52430 -0.014179  -2.90690  3.91830 -1.21080  4.1508  4.915100  0.21788 -0.49317 -0.51851  3.933100   1.44520  3.884100  4.73100  -3.1003  1.15710 -1.75900  0.41543  0.014483  1.33840  0.57833  2.7432 -0.39032 -2.44960  1.18580   4.603100  \n",
       "...              ...      ...       ...      ...       ...      ...      ...      ...      ...      ...      ...      ...       ...     ...      ...      ...     ...       ...      ...      ...       ...      ...       ...      ...       ...       ...      ...      ...      ...        ...      ...      ...      ...     ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...     ...     ...      ...      ...      ...      ...      ...      ...      ...      ...      ...       ...      ...       ...       ...       ...      ...      ...     ...       ...      ...      ...      ...       ...       ...       ...      ...      ...      ...      ...      ...       ...      ...      ...     ...      ...      ...      ...        ...  \n",
       "prawn       -0.06675  1.80260  -1.01180  0.10635  0.579770 -2.48590 -0.53602 -1.30350  2.12540  0.23927 -1.13900  1.39190  1.890500  2.2045  2.44450 -1.82030 -2.8197 -0.630170 -0.11690 -0.36900  0.087937 -1.55890   2.96980  1.29060   0.56415 -3.074000  0.87650  2.27160  0.78658  -1.452400 -1.18910 -0.14552  1.11020  2.8045  2.52440 -0.41811 -0.26705 -5.74630 -0.43291  0.92065 -4.38000  0.34797  0.52697 -0.48560  0.70011  1.14140  3.1286  2.7785  3.20760  0.58293 -0.57667  1.24440  2.48680 -3.89850  1.04800  1.24410 -0.29225 -1.092200  1.07380  -0.55544 -1.909400   1.65140 -1.42600 -1.16200  2.1906 -0.144720 -0.73245  2.31740 -0.25365  5.161100  -1.22130  2.924400  0.74770  -2.9230  1.30990  1.62700 -1.79590  2.008100 -1.23140 -3.08860 -1.1762  3.87150  0.28911 -2.57810   3.099400  \n",
       "tweezers     0.24186  3.12120   3.61290 -2.12400 -4.258800 -4.43620  0.28104  0.56529  3.60660  7.74220  6.49820  2.31770  1.393400 -7.0152 -0.26532  2.96030 -3.0547 -1.392500 -6.36720 -0.10276 -4.742700  0.23440   3.07760  2.63210  -6.00090 -0.035202  0.12049  3.32280 -2.53680   4.885500 -1.19500  4.03170  2.91550 -2.4755  0.94430 -2.74750  0.10769  7.21170  4.77290 -1.17920  5.26350  1.46960 -3.13040 -4.69320  2.81080 -2.16570 -7.2465 -0.4450 -1.33080  0.74278 -0.82304 -2.24190  4.98540  9.51510 -0.96686 -3.95520 -3.31550 -0.251370  7.14600   6.76020  3.751200   3.24980  3.52460 -1.91650 -3.3861 -1.981000 -1.44270 -1.31170  0.33794  0.846070  -0.96828 -1.879400  3.66160  -7.6509 -0.47105  0.36527  0.97179  0.539580  0.42964 -1.24240 -4.2396  3.22420  0.67627 -0.17765  -2.991900  \n",
       "university   6.75660  3.84780 -10.10000 -5.54070  4.452200 -6.06380 -2.28500  0.86318 -0.99399 -3.92160  1.73300 -0.92894 -8.097500  4.3275  2.63300 -7.45580 -3.7734  0.470520 -1.30890  7.80510  3.152300 -3.88340  10.38400 -6.41090  10.06900 -7.518700 -0.93429 -7.32330  1.37650  12.077000 -2.60510  4.08290  7.64380  1.5573 -1.38580  3.00970  2.88590 -6.33230  1.85610 -4.39880 -4.46170  0.73151 -2.63660  9.65110 -1.93300 -5.81710  1.7027 -5.7822 -5.78010  0.99957 -0.93970 -6.58670  4.77580  1.03520 -9.00900 -0.57722 -1.68390 -1.886500  1.09890 -14.13500 -5.768600   2.61770 -9.45430 -0.27378  2.7515  5.076000  3.32590  6.23440  2.19080 -3.097600 -12.63200  8.246700 -0.63342 -14.1170 -9.10750 -1.00250  0.41538  0.093109 -1.35630 -5.99590  2.3063 -3.14430  6.11140 -5.91240  10.933000  \n",
       "wasteful    -2.34830  0.33561   2.74800  3.54050 -0.421300 -4.19460  0.60109  0.90805 -0.58592  1.81030  3.47700  2.42890 -1.888000 -1.4580 -0.94369 -0.44531 -1.1296 -3.829700 -3.61310  1.15840 -4.380100 -3.03080   1.47220  5.73580  -1.94060  2.842700 -1.19690  4.29830  1.02980   4.770900 -1.95050  5.40530 -5.34150 -6.2761  3.03760  1.78590  2.04100  3.17640  2.22880  0.03576  4.11180  5.24720 -2.28430  1.41040  1.78310  0.30675 -4.1661  3.5212 -2.73180 -5.18410  1.46250 -0.94632  4.03570  0.63492 -0.59014  1.07350 -2.68880 -1.346300  2.78750   2.46090  0.250130   1.58420 -3.46610  1.61160 -3.5738 -2.515900 -2.46640 -3.03200 -1.81210  4.040300  -0.91036 -0.295610  0.46698  -5.7423 -3.85580 -1.89300 -0.19739 -2.204700  1.87600 -3.85170 -2.8258 -1.64500 -0.22011  3.19510   0.082503  \n",
       "children     4.85780  5.80520   1.10390  0.29307  3.011000 -0.70216  2.46750 -0.78348 -2.15990  2.64930  3.28510 -0.21426  2.187200  4.9649  2.02410  0.45664 -4.0420  2.593400 -4.95410  0.95183  0.946780  3.00870   0.31703  4.04670   0.68744 -4.032500 -0.28389  3.13890  1.90230   0.095292  2.88020 -3.70710 -1.81070 -2.5392  2.89830 -2.63380 -3.18470 -3.61820 -5.06320 -2.13680 -1.44800  4.36180 -3.05240 -1.76090  1.89270  3.74030  2.9173  0.4139  7.34780  2.93150  2.11600  1.90170  5.08370 -4.89770  1.12480 -4.78600  0.23904  0.038293 -5.76190   3.26870  2.783300   0.12430 -2.69890 -1.37100  2.2128 -0.037228  0.20066  1.74010 -3.01200  2.368200   3.72540  2.608500 -0.53161  -3.1048 -2.72900  4.09020 -5.49070 -1.372500 -3.58540  0.38873 -1.3636  0.53067 -3.34950 -4.26420   0.894910  \n",
       "\n",
       "[3288 rows x 300 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_Objectivity</th>\n",
       "      <th>F_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>airplane</th>\n",
       "      <td>0.960395</td>\n",
       "      <td>0.463949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coarse</th>\n",
       "      <td>0.401438</td>\n",
       "      <td>0.265841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persecution</th>\n",
       "      <td>0.319377</td>\n",
       "      <td>0.678163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moment</th>\n",
       "      <td>0.139091</td>\n",
       "      <td>0.413798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responsible</th>\n",
       "      <td>0.289618</td>\n",
       "      <td>0.654414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prawn</th>\n",
       "      <td>0.952891</td>\n",
       "      <td>0.110865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweezers</th>\n",
       "      <td>0.953419</td>\n",
       "      <td>0.193659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>university</th>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.695757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wasteful</th>\n",
       "      <td>0.200742</td>\n",
       "      <td>0.492842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>0.799572</td>\n",
       "      <td>0.389236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3288 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             F_Objectivity  F_Subjectivity\n",
       "airplane          0.960395        0.463949\n",
       "coarse            0.401438        0.265841\n",
       "persecution       0.319377        0.678163\n",
       "moment            0.139091        0.413798\n",
       "responsible       0.289618        0.654414\n",
       "...                    ...             ...\n",
       "prawn             0.952891        0.110865\n",
       "tweezers          0.953419        0.193659\n",
       "university        0.835052        0.695757\n",
       "wasteful          0.200742        0.492842\n",
       "children          0.799572        0.389236\n",
       "\n",
       "[3288 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarizing Y_train and Y_test\n",
    "Once we run the first MLP model, the performance wasn't over 54%. \n",
    "In this Section, we will binarize the semantic factor values following the median values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizing through list comprehension\n",
    "Y_train['F_Objectivity'] = ['high' if f_objectivity >= 0.565 else 'low' for f_objectivity in Y_train['F_Objectivity']]\n",
    "Y_train['F_Subjectivity'] = ['high' if f_subjectivity >= 0.392 else 'low' for f_subjectivity in Y_train['F_Subjectivity']]\n",
    "\n",
    "Y_test['F_Objectivity'] = ['high' if f_objectivity >= 0.565 else 'low' for f_objectivity in Y_test['F_Objectivity']]\n",
    "Y_test['F_Subjectivity'] = ['high' if f_subjectivity >= 0.392 else 'low' for f_subjectivity in Y_test['F_Subjectivity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizing through list comprehension\n",
    "Y_train['F_Objectivity'] = [1 if f_objectivity >= 0.565 else 0 for f_objectivity in Y_train['F_Objectivity']]\n",
    "Y_train['F_Subjectivity'] = [1 if f_subjectivity >= 0.392 else 0 for f_subjectivity in Y_train['F_Subjectivity']]\n",
    "\n",
    "Y_test['F_Objectivity'] = [1 if f_objectivity >= 0.565 else 0 for f_objectivity in Y_test['F_Objectivity']]\n",
    "Y_test['F_Subjectivity'] = [1 if f_subjectivity >= 0.392 else 0 for f_subjectivity in Y_test['F_Subjectivity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_Objectivity</th>\n",
       "      <th>F_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>airplane</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coarse</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persecution</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moment</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responsible</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prawn</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweezers</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>university</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wasteful</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3288 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             F_Objectivity  F_Subjectivity\n",
       "airplane                 1               1\n",
       "coarse                   0               0\n",
       "persecution              0               1\n",
       "moment                   0               1\n",
       "responsible              0               1\n",
       "...                    ...             ...\n",
       "prawn                    1               0\n",
       "tweezers                 1               0\n",
       "university               1               1\n",
       "wasteful                 0               1\n",
       "children                 1               0\n",
       "\n",
       "[3288 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Training a MLP Classifier for word semantic content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new MLP architecture\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(300,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # 2 neurons for binary classification with softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Use categorical_crossentropy for categorical data\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_39 (Dense)            (None, 256)               77056     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120354 (470.13 KB)\n",
      "Trainable params: 120354 (470.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Como converti a saída em dados categóricos, é preciso antes utilizar OneHotEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "## Como já foram transformados anteriormente em [0,1], preciso apenas torná-los como lista:\n",
    "Y_train_array = Y_train.to_numpy()\n",
    "Y_test_array = Y_test.to_numpy()\n",
    "\n",
    "X_train_array = X_train.to_numpy()\n",
    "X_test_array = X_test.to_numpy()\n",
    "\n",
    "# Print the first few elements to verify\n",
    "print(Y_train_array[:5])  # Print the first 5 elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert multilabel categorical labels to binary vectors\n",
    "multi_label_binarizer = MultiLabelBinarizer()\n",
    "Y_train_encoded = multi_label_binarizer.fit_transform(Y_train)\n",
    "Y_test_encoded = multi_label_binarizer.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1],\n",
       "       [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_Objectivity</th>\n",
       "      <th>F_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>airplane</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coarse</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persecution</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moment</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responsible</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prawn</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweezers</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>university</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wasteful</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3288 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             F_Objectivity  F_Subjectivity\n",
       "airplane                 1               1\n",
       "coarse                   0               0\n",
       "persecution              0               1\n",
       "moment                   0               1\n",
       "responsible              0               1\n",
       "...                    ...             ...\n",
       "prawn                    1               0\n",
       "tweezers                 1               0\n",
       "university               1               1\n",
       "wasteful                 0               1\n",
       "children                 1               0\n",
       "\n",
       "[3288 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.9003  ,   3.9343  ,   0.65395 , ...,   0.11406 ,  -5.1079  ,\n",
       "          1.122   ],\n",
       "       [  2.0427  ,  -2.0691  ,  -1.591   , ...,  -3.8809  ,  -5.2335  ,\n",
       "          3.8502  ],\n",
       "       [  0.068316,   4.3433  ,  -5.5537  , ...,   2.2451  ,  -1.9138  ,\n",
       "         -0.074928],\n",
       "       ...,\n",
       "       [ -1.0686  , -10.114   ,   4.0364  , ...,   6.1114  ,  -5.9124  ,\n",
       "         10.933   ],\n",
       "       [ -5.8985  ,  -2.8247  ,   0.85307 , ...,  -0.22011 ,   3.1951  ,\n",
       "          0.082503],\n",
       "       [  2.5277  ,   2.4585  ,   1.4097  , ...,  -3.3495  ,  -4.2642  ,\n",
       "          0.89491 ]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.1686 - accuracy: 0.7859 - val_loss: 2.5079 - val_accuracy: 0.4818\n",
      "Epoch 2/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.7875 - val_loss: 2.3956 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.7806 - val_loss: 2.9911 - val_accuracy: 0.5410\n",
      "Epoch 4/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.7844 - val_loss: 2.7022 - val_accuracy: 0.5486\n",
      "Epoch 5/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.7890 - val_loss: 3.3800 - val_accuracy: 0.4924\n",
      "Epoch 6/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.7684 - val_loss: 3.4306 - val_accuracy: 0.5228\n",
      "Epoch 7/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.7897 - val_loss: 3.4110 - val_accuracy: 0.5334\n",
      "Epoch 8/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.7863 - val_loss: 3.5888 - val_accuracy: 0.5350\n",
      "Epoch 9/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.7760 - val_loss: 3.4282 - val_accuracy: 0.5319\n",
      "Epoch 10/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.8034 - val_loss: 3.6358 - val_accuracy: 0.5167\n",
      "Epoch 11/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.7856 - val_loss: 3.1337 - val_accuracy: 0.5289\n",
      "Epoch 12/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.7970 - val_loss: 3.1745 - val_accuracy: 0.5350\n",
      "Epoch 13/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.7981 - val_loss: 3.2133 - val_accuracy: 0.5319\n",
      "Epoch 14/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.7977 - val_loss: 3.2801 - val_accuracy: 0.5380\n",
      "Epoch 15/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.7985 - val_loss: 3.2443 - val_accuracy: 0.5334\n",
      "Epoch 16/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.7897 - val_loss: 3.6302 - val_accuracy: 0.5106\n",
      "Epoch 17/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.7882 - val_loss: 3.6531 - val_accuracy: 0.5182\n",
      "Epoch 18/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.7719 - val_loss: 3.7630 - val_accuracy: 0.4954\n",
      "Epoch 19/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.7688 - val_loss: 4.0073 - val_accuracy: 0.5030\n",
      "Epoch 20/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.7806 - val_loss: 3.8813 - val_accuracy: 0.5122\n",
      "Epoch 21/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.7856 - val_loss: 3.8866 - val_accuracy: 0.5137\n",
      "Epoch 22/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.7753 - val_loss: 3.8025 - val_accuracy: 0.5106\n",
      "Epoch 23/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.7985 - val_loss: 3.8094 - val_accuracy: 0.5395\n",
      "Epoch 24/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.7970 - val_loss: 3.5112 - val_accuracy: 0.5198\n",
      "Epoch 25/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.7783 - val_loss: 2.9830 - val_accuracy: 0.5091\n",
      "Epoch 26/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.7658 - val_loss: 3.1752 - val_accuracy: 0.5517\n",
      "Epoch 27/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.7346 - val_loss: 3.1374 - val_accuracy: 0.5182\n",
      "Epoch 28/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.7460 - val_loss: 3.0971 - val_accuracy: 0.5365\n",
      "Epoch 29/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.7464 - val_loss: 3.4572 - val_accuracy: 0.5198\n",
      "Epoch 30/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.7658 - val_loss: 3.6814 - val_accuracy: 0.5471\n",
      "Epoch 31/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.7772 - val_loss: 3.9334 - val_accuracy: 0.5486\n",
      "Epoch 32/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.7882 - val_loss: 3.9804 - val_accuracy: 0.5578\n",
      "Epoch 33/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.7802 - val_loss: 3.6119 - val_accuracy: 0.5213\n",
      "Epoch 34/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.7913 - val_loss: 3.5848 - val_accuracy: 0.5198\n",
      "Epoch 35/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.7745 - val_loss: 3.8572 - val_accuracy: 0.5380\n",
      "Epoch 36/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.7696 - val_loss: 3.8472 - val_accuracy: 0.5228\n",
      "Epoch 37/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.7821 - val_loss: 2.9944 - val_accuracy: 0.5410\n",
      "Epoch 38/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.7859 - val_loss: 3.0823 - val_accuracy: 0.5380\n",
      "Epoch 39/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.7985 - val_loss: 3.2275 - val_accuracy: 0.4818\n",
      "Epoch 40/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.7749 - val_loss: 2.9429 - val_accuracy: 0.5213\n",
      "Epoch 41/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.7795 - val_loss: 3.0876 - val_accuracy: 0.5122\n",
      "Epoch 42/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.8099 - val_loss: 3.3943 - val_accuracy: 0.5410\n",
      "Epoch 43/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.7772 - val_loss: 3.1574 - val_accuracy: 0.5258\n",
      "Epoch 44/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.7935 - val_loss: 3.4924 - val_accuracy: 0.5274\n",
      "Epoch 45/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.7757 - val_loss: 3.3834 - val_accuracy: 0.5350\n",
      "Epoch 46/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.7992 - val_loss: 3.0115 - val_accuracy: 0.5426\n",
      "Epoch 47/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.7863 - val_loss: 3.4161 - val_accuracy: 0.5669\n",
      "Epoch 48/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.8076 - val_loss: 3.2980 - val_accuracy: 0.5395\n",
      "Epoch 49/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.8281 - val_loss: 3.4308 - val_accuracy: 0.5198\n",
      "Epoch 50/50\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.8103 - val_loss: 3.3285 - val_accuracy: 0.5182\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_array, Y_train_array, epochs=50, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 1ms/step - loss: 3.9207 - accuracy: 0.4504\n",
      "Test Accuracy: 45.04%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_array, Y_test_array)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node categorical_crossentropy/Cast defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\tiago\\AppData\\Local\\Temp\\ipykernel_30152\\650847344.py\", line 2, in <module>\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 2198, in categorical_crossentropy\n\nCast string to float is not supported\n\t [[{{node categorical_crossentropy/Cast}}]] [Op:__inference_train_function_62846]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Treina o modelo\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Usamos parte dos dados de treino como validação\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Avalia o modelo com os dados de teste\u001b[39;00m\n\u001b[0;32m      8\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test\u001b[38;5;241m.\u001b[39mvalues, Y_test\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[1;32mc:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node categorical_crossentropy/Cast defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\tiago\\AppData\\Local\\Temp\\ipykernel_30152\\650847344.py\", line 2, in <module>\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\losses.py\", line 2198, in categorical_crossentropy\n\nCast string to float is not supported\n\t [[{{node categorical_crossentropy/Cast}}]] [Op:__inference_train_function_62846]"
     ]
    }
   ],
   "source": [
    "# Treina o modelo\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1)  # Usamos parte dos dados de treino como validação\n",
    "\n",
    "# Avalia o modelo com os dados de teste\n",
    "loss, accuracy = model.evaluate(X_test.values, Y_test.values)\n",
    "print(f\"Acurácia do modelo nos dados de teste: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando XGBoosting for multilabel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando PyCaret:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_PredictScorer' from 'sklearn.metrics._scorer' (c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\pycaret\\classification\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     add_metric,\n\u001b[0;32m      3\u001b[0m     automl,\n\u001b[0;32m      4\u001b[0m     blend_models,\n\u001b[0;32m      5\u001b[0m     calibrate_model,\n\u001b[0;32m      6\u001b[0m     check_drift,\n\u001b[0;32m      7\u001b[0m     check_fairness,\n\u001b[0;32m      8\u001b[0m     compare_models,\n\u001b[0;32m      9\u001b[0m     convert_model,\n\u001b[0;32m     10\u001b[0m     create_api,\n\u001b[0;32m     11\u001b[0m     create_app,\n\u001b[0;32m     12\u001b[0m     create_docker,\n\u001b[0;32m     13\u001b[0m     create_model,\n\u001b[0;32m     14\u001b[0m     dashboard,\n\u001b[0;32m     15\u001b[0m     deploy_model,\n\u001b[0;32m     16\u001b[0m     ensemble_model,\n\u001b[0;32m     17\u001b[0m     evaluate_model,\n\u001b[0;32m     18\u001b[0m     finalize_model,\n\u001b[0;32m     19\u001b[0m     get_allowed_engines,\n\u001b[0;32m     20\u001b[0m     get_config,\n\u001b[0;32m     21\u001b[0m     get_current_experiment,\n\u001b[0;32m     22\u001b[0m     get_engine,\n\u001b[0;32m     23\u001b[0m     get_leaderboard,\n\u001b[0;32m     24\u001b[0m     get_logs,\n\u001b[0;32m     25\u001b[0m     get_metrics,\n\u001b[0;32m     26\u001b[0m     interpret_model,\n\u001b[0;32m     27\u001b[0m     load_experiment,\n\u001b[0;32m     28\u001b[0m     load_model,\n\u001b[0;32m     29\u001b[0m     models,\n\u001b[0;32m     30\u001b[0m     optimize_threshold,\n\u001b[0;32m     31\u001b[0m     plot_model,\n\u001b[0;32m     32\u001b[0m     predict_model,\n\u001b[0;32m     33\u001b[0m     pull,\n\u001b[0;32m     34\u001b[0m     remove_metric,\n\u001b[0;32m     35\u001b[0m     save_experiment,\n\u001b[0;32m     36\u001b[0m     save_model,\n\u001b[0;32m     37\u001b[0m     set_config,\n\u001b[0;32m     38\u001b[0m     set_current_experiment,\n\u001b[0;32m     39\u001b[0m     setup,\n\u001b[0;32m     40\u001b[0m     stack_models,\n\u001b[0;32m     41\u001b[0m     tune_model,\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassificationExperiment\n\u001b[0;32m     45\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassificationExperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_drift\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\pycaret\\classification\\functional.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Memory\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassificationExperiment\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelBackend\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_logger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLogger\n",
      "File \u001b[1;32mc:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\pycaret\\classification\\oop.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Memory\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shgo\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_all_metric_containers\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     ALL_ALLOWED_ENGINES,\n\u001b[0;32m     19\u001b[0m     get_all_model_containers,\n\u001b[0;32m     20\u001b[0m     get_container_default_engines,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CommonDisplay\n",
      "File \u001b[1;32mc:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\pycaret\\containers\\metrics\\classification.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_scorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _BaseScorer\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_container\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_metric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetricContainer\n",
      "File \u001b[1;32mc:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\pycaret\\containers\\base_container.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Optional\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBaseContainer\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    Base container class, for easier definition of containers. Ensures consistent format\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    before being turned into a dataframe row.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\pycaret\\utils\\generic.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_scorer\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_scorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _PredictScorer\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseCrossValidator, KFold, StratifiedKFold\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_split\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _BaseKFold\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_PredictScorer' from 'sklearn.metrics._scorer' (c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py)"
     ]
    }
   ],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Summary",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300.15px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "498.85px",
    "left": "651.8px",
    "right": "20px",
    "top": "56px",
    "width": "715px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
