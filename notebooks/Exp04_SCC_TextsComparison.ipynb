{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Content Classifier (SCC)\n",
    "In this Jupyter Notebook, we delve into practical applications of the SCA_utils.py library, which stands at the forefront of Semantic Content Analysis (SCA).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../source\")  # Add the directory 'source' to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sca_utils import TextClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SCA_utils methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Instantiating the SCA Text Classifier:\n",
    "classifier = TextClassifier(model_multiclass_path='../models/model_02_E.h5',\n",
    "                            encoder_multiclass_path='../models/encoder_oneHot_E.pickle',\n",
    "                            model_regression_path='../models/model_01_D2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the embedded vector for a given word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[-0.0562946  -0.00365345]..\n"
     ]
    }
   ],
   "source": [
    "## Experimenting with an existent word\n",
    "word_text, word_vector = classifier.nlp_getVector(word='None')\n",
    "print(word_text)\n",
    "print(f'{word_vector[:2]}..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: word vector not available for None due to:\n",
      "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "## Trying a none word to check how exceptions are being raised:\n",
    "classifier.nlp_getVector(word=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding similar words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Similar words for: \"technology\":\n",
      "\"technologic\", similarity of 0.95%\n",
      "\"technologies\", similarity of 0.94%\n",
      "\"technologie\", similarity of 0.93%\n",
      "\"technological\", similarity of 0.90%\n",
      "\"technoscience\", similarity of 0.89%\n"
     ]
    }
   ],
   "source": [
    "## Replace keyword for the word of interest:\n",
    "keyword = \"technology\"\n",
    "\n",
    "similar_words = classifier.similarity_findWords(keyword, n=5)\n",
    "\n",
    "print(f'--- Similar words for: \"{keyword}\":')\n",
    "for word, similarity in similar_words:\n",
    "    print(f'\"{word}\", similarity of {similarity:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing similarity between words or sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define an input word or sentence to be compared:\n",
    "input_text = 'Last things for last!'\n",
    "\n",
    "## Define a set of reference words or sentences to which input_word will be compared with:\n",
    "reference_texts = [\"First things first\",\n",
    "                   \"another example\",\n",
    "                   \"universal sentence encoder\", \n",
    "                   \"natural language processing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: First things first, Similarity: 0.40%\n",
      "Text: another example, Similarity: 0.08%\n",
      "Text: universal sentence encoder, Similarity: 0.06%\n",
      "Text: natural language processing, Similarity: 0.01%\n"
     ]
    }
   ],
   "source": [
    "## Find the closest embeddings\n",
    "closest_embeddings = classifier.similarity_compareSentences(input_text, reference_texts)\n",
    "\n",
    "## Show the results\n",
    "for text, similarity in closest_embeddings:\n",
    "    print(f\"Text: {text}, Similarity: {similarity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating subjective and objective load for a given sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "--- happyness:\n",
      "20.03 of objectivity\n",
      "78.65 of subjectivity\n"
     ]
    }
   ],
   "source": [
    "## Regression inference for a given word:\n",
    "classifier.textClassifier_regression('happyness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "--- SCA: \"happyness\" has Latent content.\n",
      "Model used: Model_02_E_regularized\n"
     ]
    }
   ],
   "source": [
    "## Multiclass classification for a given word:\n",
    "classifier.textClassifier_multiclass('happyness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "--- Your sample sentence:\n",
      "38.72 of objectivity\n",
      "15.49 of subjectivity\n"
     ]
    }
   ],
   "source": [
    "## Regression inference for a given sentence:\n",
    "classifier.textClassifier_regression('Your sample sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
