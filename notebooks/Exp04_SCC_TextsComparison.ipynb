{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Content Classifier (SCC)\n",
    "In this Jupyter Notebook, we delve into practical applications of the SCA_utils.py library, which stands at the forefront of Semantic Content Analysis (SCA).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../source\")  # Add the directory 'source' to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sca_utils import TextClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SCA_utils methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tiago\\OneDrive - UNIVALI\\PhD\\atividades de pesquisa\\semantic_similarity\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Instantiating the SCA Text Classifier:\n",
    "classifier = TextClassifier(model_multiclass_path='../models/model_02_E.h5',\n",
    "                            encoder_multiclass_path='../models/encoder_oneHot_E.pickle',\n",
    "                            model_regression_path='../models/model_01_D2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the embedded vector for a given word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[-0.0562946  -0.00365345]..\n"
     ]
    }
   ],
   "source": [
    "## Experimenting with an existent word\n",
    "word_text, word_vector = classifier.nlp_getVector(word='None')\n",
    "print(word_text)\n",
    "print(f'{word_vector[:2]}..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: word vector not available for None due to:\n",
      "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "## Trying a none word to check how exceptions are being raised:\n",
    "classifier.nlp_getVector(word=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding similar words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Similar words for: \"technology\":\n",
      "\"technologic\", similarity of 0.95%\n",
      "\"technologies\", similarity of 0.94%\n",
      "\"technologie\", similarity of 0.93%\n",
      "\"technological\", similarity of 0.90%\n",
      "\"technoscience\", similarity of 0.89%\n"
     ]
    }
   ],
   "source": [
    "## Replace keyword for the word of interest:\n",
    "keyword = \"technology\"\n",
    "\n",
    "similar_words = classifier.similarity_findWords(keyword, n=5)\n",
    "\n",
    "print(f'--- Similar words for: \"{keyword}\":')\n",
    "for word, similarity in similar_words:\n",
    "    print(f'\"{word}\", similarity of {similarity:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating objectivity and subjectivity in long texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_objective = '''\n",
    "Geodimensioning, a critical component within the geospatial field, entails the measurement and quantification of Earth's dimensions and geographical features. This intricate process involves various metrics, each serving a unique purpose in enhancing the accuracy and reliability of geospatial data. Scale, a fundamental metric, denotes the ratio of distance on a map to the corresponding distance on the ground. It's pivotal in ensuring that geospatial representations are proportionally accurate to real-world dimensions. Scale accuracy is paramount, as even minor discrepancies can lead to significant errors in distance and area measurements, affecting planning and decision-making processes.\n",
    "Precision refers to the level of detail and exactness in the measurement of geospatial data. High precision is essential in applications requiring fine-grained data, such as urban planning and cadastral mapping. Precision is often limited by the measurement tools and technology employed, necessitating ongoing advancements in geospatial instrumentation and methodologies.\n",
    "Resolution pertains to the smallest detectable feature within geospatial data. In digital mapping and satellite imagery, resolution is a key determinant of the quality and usability of geospatial information. High-resolution data captures minute details, crucial for applications like environmental monitoring and infrastructure development.\n",
    "Accuracy, distinct from precision, measures the closeness of a given measurement to its true value. In geodimensioning, accuracy is affected by factors such as instrument calibration, measurement techniques, and environmental conditions. Ensuring high accuracy is imperative for reliable geospatial analysis and modeling.\n",
    "Georeferencing accuracy is another vital metric, ensuring that geospatial data aligns correctly with real-world coordinates. This is critical for integrating and comparing data from diverse sources, enabling accurate mapping and analysis across multiple scales and geographies.\n",
    "Datum and projection consistency are essential for maintaining the integrity of geospatial data. Datum refers to the reference frame used for measuring locations on Earth's surface, while projection involves the method of translating three-dimensional Earth onto a two-dimensional map. Consistency in these metrics ensures that geospatial data from different sources can be accurately integrated and compared.\n",
    "In conclusion, the metrics of geodimensioning play a crucial role in the fidelity and utility of geospatial data. As technology advances, continuous refinement of these metrics is essential to meet the growing demands of diverse applications in fields such as environmental science, urban planning, and global navigation systems.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_subjective = '''\n",
    "In the realm of Earth's vast embrace, where landscapes whisper ancient tales, geodimensioning becomes an art, a poetic dance with space and time. It's here, amidst the cartographer's dream, that maps unfurl like canvases, painting the world in strokes of truth and mystery combined.\n",
    "\n",
    "Scale, the cartographer's muse, weaves tales of distances vast and small, where a single line can span mountains, and a dot encloses cities' sprawl. It's a delicate balance, a harmony sought, between the expanse of the world and the parchment's thought.\n",
    "\n",
    "Precision, the sculptor of detail, carves the world with a fine-edged tool, where every measurement is a verse, and every data point a jewel. It's the pursuit of perfection, a never-ending quest, to capture the Earth's essence, at its very best.\n",
    "\n",
    "Resolution, the seer's gift, reveals the world in grains of sand, where hidden stories come to light, and nothing is too small to stand. It's the clarity of vision, the ability to see, the intricate patterns of nature, and the world's underlying symmetry.\n",
    "\n",
    "Accuracy, the anchor of truth, holds firm in the shifting tides, where measurements speak of reality, and the truth no longer hides. It's the cornerstone of trust, in the maps we chart, guiding explorers and dreamers, as they embark.\n",
    "\n",
    "Georeferencing, the dancer's grace, aligns the stars with the earthly plane, where each point is a heartbeat, in the universe's refrain. It's the cosmic connection, the thread that binds, the world's vast wonders, in the maps we find.\n",
    "\n",
    "In the whisper of leaves, and the rush of streams, in the shadows of mountains, and the sunlight's beams, geodimensioning captures the world, in lines and numbers, yet tells a story, of a universe unfurled.\n",
    "\n",
    "So let us wander, with maps in hand, through this poetic landscape, vast and grand, where every measurement, and every line, is a verse in the Earth's grand design.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "--- \n",
      "In the realm of Earth's vast embrace, where landscapes whisper ancient tales, geodimensioning becomes an art, a poetic dance with space and time. It's here, amidst the cartographer's dream, that maps unfurl like canvases, painting the world in strokes of truth and mystery combined.\n",
      "\n",
      "Scale, the cartographer's muse, weaves tales of distances vast and small, where a single line can span mountains, and a dot encloses cities' sprawl. It's a delicate balance, a harmony sought, between the expanse of the world and the parchment's thought.\n",
      "\n",
      "Precision, the sculptor of detail, carves the world with a fine-edged tool, where every measurement is a verse, and every data point a jewel. It's the pursuit of perfection, a never-ending quest, to capture the Earth's essence, at its very best.\n",
      "\n",
      "Resolution, the seer's gift, reveals the world in grains of sand, where hidden stories come to light, and nothing is too small to stand. It's the clarity of vision, the ability to see, the intricate patterns of nature, and the world's underlying symmetry.\n",
      "\n",
      "Accuracy, the anchor of truth, holds firm in the shifting tides, where measurements speak of reality, and the truth no longer hides. It's the cornerstone of trust, in the maps we chart, guiding explorers and dreamers, as they embark.\n",
      "\n",
      "Georeferencing, the dancer's grace, aligns the stars with the earthly plane, where each point is a heartbeat, in the universe's refrain. It's the cosmic connection, the thread that binds, the world's vast wonders, in the maps we find.\n",
      "\n",
      "In the whisper of leaves, and the rush of streams, in the shadows of mountains, and the sunlight's beams, geodimensioning captures the world, in lines and numbers, yet tells a story, of a universe unfurled.\n",
      "\n",
      "So let us wander, with maps in hand, through this poetic landscape, vast and grand, where every measurement, and every line, is a verse in the Earth's grand design.\n",
      ":\n",
      "27.58 of objectivity\n",
      "52.42 of subjectivity\n"
     ]
    }
   ],
   "source": [
    "## Regression inference for a given word:\n",
    "classifier.textClassifier_regression(input_subjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "--- SCA: \"happyness\" has Latent content.\n",
      "Model used: Model_02_E_regularized\n"
     ]
    }
   ],
   "source": [
    "## Multiclass classification for a given word:\n",
    "classifier.textClassifier_multiclass('happyness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "--- Your sample sentence:\n",
      "38.72 of objectivity\n",
      "15.49 of subjectivity\n"
     ]
    }
   ],
   "source": [
    "## Regression inference for a given sentence:\n",
    "classifier.textClassifier_regression('Your sample sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "--- I am working:\n",
      "83.07 of objectivity\n",
      "56.62 of subjectivity\n"
     ]
    }
   ],
   "source": [
    "classifier.textClassifier_regression('I am working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
