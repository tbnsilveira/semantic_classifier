{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity - Experiment 03\n",
    "Employing the models trained in the previous notebooks to evaluate semantic similarity in the SICK dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../source\")  # Add the directory 'source' to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sca_utils import TextClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SCA_utils methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiating the SCA Text Classifier:\n",
    "classifier = TextClassifier(model_multiclass_path='../models/model_02_E.h5',\n",
    "                            encoder_multiclass_path='../models/encoder_oneHot_E.pickle',\n",
    "                            model_regression_path='../models/model_01_D2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding similar words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Similar words for: \"technology\":\n",
      "\"technologic\", similarity of 0.95%\n",
      "\"technologies\", similarity of 0.94%\n",
      "\"technologie\", similarity of 0.93%\n",
      "\"technological\", similarity of 0.90%\n",
      "\"technoscience\", similarity of 0.89%\n"
     ]
    }
   ],
   "source": [
    "## Replace keyword for the word of interest:\n",
    "keyword = \"technology\"\n",
    "\n",
    "similar_words = classifier.similarity_findWords(keyword, n=5)\n",
    "\n",
    "print(f'--- Similar words for: \"{keyword}\":')\n",
    "for word, similarity in similar_words:\n",
    "    print(f'\"{word}\", similarity of {similarity:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing similarity between words or sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define an input word or sentence to be compared:\n",
    "input_text = 'Last things for last!'\n",
    "\n",
    "## Define a set of reference words or sentences to which input_word will be compared with:\n",
    "reference_texts = [\"First things first\",\n",
    "                   \"another example\",\n",
    "                   \"universal sentence encoder\", \n",
    "                   \"natural language processing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: First things first, Similarity: 0.40%\n",
      "Text: another example, Similarity: 0.08%\n",
      "Text: universal sentence encoder, Similarity: 0.06%\n",
      "Text: natural language processing, Similarity: 0.01%\n"
     ]
    }
   ],
   "source": [
    "## Find the closest embeddings\n",
    "closest_embeddings = classifier.similarity_compareSentences(input_text, reference_texts)\n",
    "\n",
    "## Show the results\n",
    "for text, similarity in closest_embeddings:\n",
    "    print(f\"Text: {text}, Similarity: {similarity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating subjective and objective load for a given sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "--- happyness:\n",
      "20.03 of objectivity\n",
      "78.65 of subjectivity\n"
     ]
    }
   ],
   "source": [
    "## Regression inference for a given word:\n",
    "classifier.textClassifier_regression('happyness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 117ms/step\n",
      "--- SCA: \"happyness\" has Latent content.\n",
      "Model used: Model_02_E_regularized\n"
     ]
    }
   ],
   "source": [
    "## Multiclass classification for a given word:\n",
    "classifier.textClassifier_multiclass('happyness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
